{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/r7qn2m9n1zb6y_0q191gdqth0000gn/T/ipykernel_13654/1916853760.py:27: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  tpxData = pd.read_csv('TPX_prices.csv', index_col=0, parse_dates=True, date_parser=custom_date_parser)\n"
     ]
    }
   ],
   "source": [
    "## anaconda3 (Python 3.12.0) Kernel\n",
    "# pair trade packages\n",
    "import csv\n",
    "import gym\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "# nn packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "def custom_date_parser(date_str):\n",
    "    return datetime.strptime(date_str, '%d/%m/%Y')\n",
    "# Load the dictionary from the pickle file\n",
    "with open('pairsOutcome.pkl', 'rb') as file:\n",
    "    pairsOutcome = pickle.load(file)\n",
    "# Load stock data and get return \n",
    "tpxData = pd.read_csv('TPX_prices.csv', index_col=0, parse_dates=True, date_parser=custom_date_parser)\n",
    "tpxData = tpxData.dropna(axis='columns')\n",
    "return_df = (tpxData / tpxData.shift(1)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pairs Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Pair Trade Portfolio\n",
    "`pairsOutcome` already have TOPIX stocks with highest liquidity and are tested for stationarity over a 1 year window\n",
    "\n",
    "Choose top 10 known pair trades by returns in the total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 clustered trades:\n",
      "1. Key: 6503 JP Equity 7269 JP Equity, Return: 1.33\n",
      "2. Key: 6326 JP Equity 6954 JP Equity, Return: 1.19\n",
      "3. Key: 8053 JP Equity 8058 JP Equity, Return: 0.52\n",
      "4. Key: 4901 JP Equity 9613 JP Equity, Return: 1.10\n",
      "5. Key: 6988 JP Equity 7267 JP Equity, Return: 0.65\n",
      "6. Key: 4901 JP Equity 6702 JP Equity, Return: -0.34\n",
      "7. Key: 4684 JP Equity 7832 JP Equity, Return: 0.89\n",
      "8. Key: 7267 JP Equity 8306 JP Equity, Return: 1.16\n",
      "9. Key: 7267 JP Equity 8801 JP Equity, Return: 0.64\n",
      "10. Key: 4519 JP Equity 7532 JP Equity, Return: 1.14\n"
     ]
    }
   ],
   "source": [
    "with open(\"output_clustering.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    # Skip the header row\n",
    "    next(reader)\n",
    "    working_pairs = [tuple(row) for row in reader]\n",
    "\n",
    "top_keys = [f\"{pair[0]} {pair[1]}\" for pair in working_pairs]\n",
    "print(\"Top 10 clustered trades:\")\n",
    "for i, key in enumerate(top_keys, 1):\n",
    "    print(f\"{i}. Key: {key}, Return: {pairsOutcome[key].cumpnl.iloc[-2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/r7qn2m9n1zb6y_0q191gdqth0000gn/T/ipykernel_13654/4194707529.py:1: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  valid = pd.read_csv('validPairs5.csv',\n"
     ]
    }
   ],
   "source": [
    "valid = pd.read_csv('validPairs5.csv', \n",
    "                    index_col=0, \n",
    "                    parse_dates=True, \n",
    "                    date_parser=custom_date_parser)\n",
    "## get list of pair stocks\n",
    "validPairsList = [\n",
    "    [item.strip() + ' Equity' for item in pair.split('Equity') if item.strip()]\n",
    "    for pair in top_keys\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Challenge\n",
    "\n",
    "## Background\n",
    "Initial evaluation of the baseline portfolio shows that draw downs are small. Originally team had the idea of using Machine Learning to optimise for sizing of these pair trades. However since there was no significant drawdowns the returns are linearly increasing with investment sizing i.e. greater nominal investment in the the pair trade the proportionate increase in returns without realising significant drawdown risk.\n",
    "\n",
    "Instead of optimising for sizing, we can explore Machine Learning in terms of strategy on this stationary dataset. Whereas our prescribed strategy is to enter at +/- 1 std dev, exit at 0 with +/- 2 std dev stop loss. These are only suggestions and arbitrary levels.\n",
    "\n",
    "With Machine Learning, we can discover if it will uncover the mean reverting nature and recommend another threshhold. We use Q Learner to understand state space with the same spread, mid, std dev parameters as the baseline.\n",
    "\n",
    "### Steps\n",
    "#### Environment:\n",
    "- State Space: A set of all possible states the agent can be in.  \n",
    "  - [spread, mid, 2 sd low, 1 sd low, 1 sd high, 2 sd high]\n",
    "- Action Space: A set of all possible actions the agent can take in each state.   \n",
    "  - [-1, # short\\\n",
    "      0, # uninvested\\\n",
    "      1  # long]   \n",
    "- Reward Function: A function that assigns a numerical reward to each state-action pair, indicating the immediate consequence of taking a particular action in a specific state.\n",
    "  - dailypnl\n",
    "- Transition Function: A function that determines the probability of transitioning from one state to another when a particular action is taken.\n",
    "  - deterministic based on historical performance\n",
    "#### Agent:\n",
    "\n",
    "- Q-Table: A matrix that stores the estimated Q-values for each state-action pair. Q-values represent the expected future reward for taking a specific action in a given state.   \n",
    "  - continuous Q table?\n",
    "- Learning Rate (α): A parameter that controls how much the Q-values are updated with each new experience.   \n",
    "- Discount Factor (γ): A parameter that determines the importance of future rewards. A higher discount factor gives more weight to future rewards.   \n",
    "- Exploration Rate (ε): A parameter that controls the balance between exploration (trying new actions) and exploitation (choosing the action with the highest Q-value).   \n",
    "- Q-Learning Algorithm:\n",
    "\n",
    "  - Initialization: Initialize the Q-table with random values or zeros.   \n",
    "  - Exploration and Exploitation: Use an exploration strategy (e.g., ε-greedy) to choose an action:\n",
    "    - With probability ε, choose a random action.   \n",
    "    - With probability 1-ε, choose the action with the highest Q-value for the current state.   \n",
    "  \n",
    "  - Take Action: Execute the chosen action in the environment.   \n",
    "  - Observe Reward and Next State: Observe the immediate reward and the next state resulting from the action.\n",
    "- Update Q-Value: Update the Q-value of the current state-action pair using the following formula:\n",
    "\n",
    "## Make indicators and spread stationary around 0\n",
    "Deduct the mean from all values to translate to 0 axis\n",
    "\n",
    "#### Training and Test set\n",
    "\n",
    "2013 is used for warm start\\\n",
    "2014 - 2023 train data since NN need a lot of training data {end 2023 idx == 2868}\\\n",
    "2024 onwards (5 months) test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9241356 , 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [1.98850523, 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [1.43802272, 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [1.04480167, 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [1.55025067, 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollingWindow = 262\n",
    "cutLossSd = 2\n",
    "\n",
    "for pair in validPairsList:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    #Calculate Standard Deviations\n",
    "    df['spread'] = valid[f'spread_{pair[0]}_{pair[1]}']\n",
    "    df['mid'] =  df['spread'].rolling(rollingWindow).mean()\n",
    "    df['1sd high'] = df['spread'].rolling(rollingWindow).mean() + df['spread'].rolling(rollingWindow).std()\n",
    "    df['1sd low'] = df['spread'].rolling(rollingWindow).mean() - df['spread'].rolling(rollingWindow).std()\n",
    "    df['2sd high'] = df['spread'].rolling(rollingWindow).mean() + df['spread'].rolling(rollingWindow).std() * cutLossSd\n",
    "    df['2sd low'] = df['spread'].rolling(rollingWindow).mean() - df['spread'].rolling(rollingWindow).std() * cutLossSd\n",
    "    df['position'] = 0\n",
    "\n",
    "    df.loc[(df['spread'] > df['1sd high']) & (df['spread'] < df['2sd high']), 'position'] = -1\n",
    "    df.loc[(df['spread']< df['1sd low']) & (df['spread'] > df['2sd low']), 'position'] = 1\n",
    "\n",
    "    #Calculate PnL\n",
    "    df[f'{pair[0]} position'] = df['position']\n",
    "    df[f'{pair[1]} position'] = df['position'] * -1\n",
    "    df['dailypnl'] = df[f'{pair[1]} position']*return_df[f'{pair[1]}'].shift(-1) + df[f'{pair[0]} position']*return_df[f'{pair[0]}'].shift(-1)\n",
    "    df['cumpnl'] = df['dailypnl'].cumsum()\n",
    "\n",
    "    pairsOutcome[f'{pair[0]} {pair[1]}'] = df\n",
    "\n",
    "workingPairOutcome = {}\n",
    "\n",
    "for pair in top_keys:\n",
    "    dummy_df = pairsOutcome[top_keys[0]].iloc[::,:6]\n",
    "    dummy_df = dummy_df.subtract(dummy_df['mid'], axis=0).drop(columns=['mid']) # centre spread and SD\n",
    "    dummy_df = dummy_df.div(dummy_df['2sd high']-dummy_df['1sd high'],axis=0)   # express SD as integers, give spread as propotionate\n",
    "    dummy_df['2sd_high_boolean'] = (dummy_df['spread']>dummy_df['2sd high']).astype(int)\n",
    "    dummy_df['1sd_high_boolean'] = (dummy_df['spread']>dummy_df['1sd high']).astype(int)\n",
    "    dummy_df['0sd_high_boolean'] = (dummy_df['spread']>0).astype(int)\n",
    "    dummy_df['0sd_low_boolean']  = (dummy_df['spread']<0).astype(int)\n",
    "    dummy_df['1sd_low_boolean']  = (dummy_df['spread']<dummy_df['1sd low'] ).astype(int)\n",
    "    dummy_df['2sd_low_boolean']  = (dummy_df['spread']<dummy_df['2sd low'] ).astype(int)\n",
    "    dummy_df = dummy_df.drop(columns=['1sd high', '1sd low', '2sd high', '2sd low'])\n",
    "    workingPairOutcome[pair] = dummy_df.to_numpy()\n",
    "\n",
    "workingPairOutcome[top_keys[5]][-5:]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test one timestep at a time (even though we can test all at the same time)\n",
    "- give state\n",
    "- Trading should be path dependent due to stop loss. in this case I can only give last position as one of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairTradeEnv(gym.Env):\n",
    "    # ... (define your environment's state space, action space, etc.)\n",
    "    def __init__(self, workingPairOutcome, top_keys, validPairsList, return_df):\n",
    "        # ... (initialize other parameters)\n",
    "        self.earliest_step = 261  # hot start\n",
    "        self.last_step = 2868\n",
    "        # self.current_step = random.randint(self.earliest_step, self.last_step - 1)\n",
    "        self.current_step = self.earliest_step\n",
    "\n",
    "\n",
    "    def step(self, action, pair_idx):\n",
    "        \"\"\"\n",
    "        Input\n",
    "            action: single value e.g. -1 (short)\n",
    "            pair_idx: index of pair trade\n",
    "        Output:\n",
    "            next_state: next state \n",
    "            reward: reward for last timestep\n",
    "            done: boolean for if end of dataset\n",
    "            info: optional\n",
    "        \"\"\"\n",
    "        # Advance the time step\n",
    "        self.current_step += 1\n",
    "        # Get the next state\n",
    "        next_state = workingPairOutcome[top_keys[pair_idx]][self.current_step]\n",
    "        # Calculate reward (implement your reward function here)\n",
    "        reward = self.calculate_reward(action, self.current_step, validPairsList[pair_idx])\n",
    "        # Check for termination (implement your termination condition here)\n",
    "        done = self.current_step >= self.last_step\n",
    "\n",
    "        # Provide additional information (optional)\n",
    "        info = {}\n",
    "\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def reset(self, pair_idx):\n",
    "        # ... (implement the reset function to initialize the environment)\n",
    "        # reset to start of 2014 every time\n",
    "        # self.current_step = random.randint(self.earliest_step, self.last_step - 1)\n",
    "        self.current_step = self.earliest_step\n",
    "        initial_state = workingPairOutcome[top_keys[pair_idx]][self.current_step]\n",
    "        return initial_state\n",
    "    \n",
    "    def calculate_reward(self, position, idx, pair):\n",
    "        \"\"\"\n",
    "        Give one _previous_ day's return\n",
    "        Input:\n",
    "            position: position for idx (current step)\n",
    "            idx: usually current timestp \n",
    "            pair: tuple of tpx stock\n",
    "        Output:\n",
    "            dailypnl\n",
    "        \"\"\"\n",
    "        # position = position_vector @ np.array([-1,0,1])\n",
    "        position_0 = position\n",
    "        position_1 = position * -1\n",
    "        ## return_df gives the return for the previous day for the given idx\n",
    "        dailypnl = position_0*return_df[f'{pair[0]}'].iloc[idx] + position_1*return_df[f'{pair[1]}'].iloc[idx] \n",
    "\n",
    "        return dailypnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_priorities(replay_buffer, alpha=0.6):\n",
    "    \"\"\"\n",
    "    Compute priorities for sampling based on temporal difference (TD) error or recency.\n",
    "    \"\"\"\n",
    "    priorities = []\n",
    "    for experience in replay_buffer:\n",
    "        _, _, reward, _, _ = experience\n",
    "        td_error = abs(reward)  # Simplified proxy for TD error\n",
    "        priority = (td_error + 1e-5) ** alpha\n",
    "        priorities.append(priority)\n",
    "    return priorities\n",
    "\n",
    "def evaluate_agent_train(agent, env, number_of_pairs):\n",
    "    \"\"\"\n",
    "    Evaluates the agent's train performance over one episode without epsilon exploration.\n",
    "    \"\"\"\n",
    "    total_rewards = np.zeros(number_of_pairs)\n",
    "\n",
    "    for pair_idx in range(number_of_pairs):\n",
    "        state = env.reset(pair_idx)\n",
    "        pair_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                # Select action based purely on Q-network (greedy action)\n",
    "                q_values = agent.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0))\n",
    "                action_index = torch.argmax(q_values, dim=1).item()\n",
    "                action = agent.index_to_action[action_index]\n",
    "            \n",
    "            # Take the selected action\n",
    "            next_state, reward, done, _ = env.step(action, pair_idx)\n",
    "            pair_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "        total_rewards[pair_idx] = pair_reward\n",
    "\n",
    "    # Return the average reward across all pairs\n",
    "    return total_rewards.mean()\n",
    "\n",
    "def evaluate_agent_test(agent, env, number_of_pairs):\n",
    "    \"\"\"\n",
    "    Evaluates the agent's test performance over one episode without epsilon exploration.\n",
    "    \"\"\"\n",
    "    total_rewards = np.zeros(number_of_pairs)\n",
    "\n",
    "    for pair_idx in range(number_of_pairs):\n",
    "        state = env.reset(pair_idx)\n",
    "        env.earliest_step = 2868\n",
    "        env.current_step = env.earliest_step\n",
    "        env.last_step = 2978\n",
    "        pair_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                # Select action based purely on Q-network (greedy action)\n",
    "                q_values = agent.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0))\n",
    "                action_index = torch.argmax(q_values, dim=1).item()\n",
    "                action = agent.index_to_action[action_index]\n",
    "            \n",
    "            # Take the selected action\n",
    "            next_state, reward, done, _ = env.step(action, pair_idx)\n",
    "            pair_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "        total_rewards[pair_idx] = pair_reward\n",
    "\n",
    "    # Return the average reward across all pairs\n",
    "    return total_rewards.mean()\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate=0.2):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 8)\n",
    "        # self.dropout1 = nn.Dropout(p=dropout_rate) \n",
    "        self.fc2 = nn.Linear(8, 8)\n",
    "        # self.dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        self.fc3 = nn.Linear(8, output_size)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        # x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, input_size, output_size, learning_rate, discount_factor, epsilon, epsilon_decay, batch_size=1000, replay_buffer_size=10000):\n",
    "        self.q_network = QNetwork(input_size, output_size)\n",
    "        self.target_network = QNetwork(input_size, output_size)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=learning_rate) \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learn_count = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.replay_buffer = deque(maxlen=replay_buffer_size)\n",
    "        \n",
    "        # Action to index mapping\n",
    "        self.action_to_index = {-1: 0, 0: 1, 1: 2}\n",
    "        self.index_to_action = {0: -1, 1: 0, 2: 1}\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.choice([-1, 0, 1])  # Explore\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0))\n",
    "                action_index = torch.argmax(q_values, dim=1).item()  # Choose best action\n",
    "            action = self.index_to_action[action_index] \n",
    "        return action\n",
    "\n",
    "    def store_experience(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def learn(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        # Compute priorities for sampling and sampler\n",
    "        priorities = compute_priorities(self.replay_buffer)\n",
    "        weights = np.array(priorities) / sum(priorities)\n",
    "        sampler = WeightedRandomSampler(weights, self.batch_size, replacement=True)\n",
    "        dataloader = DataLoader(list(self.replay_buffer), batch_size=self.batch_size, sampler=sampler)\n",
    "\n",
    "        batch_count = 0\n",
    "        for batch in dataloader:\n",
    "            if batch_count >=1:\n",
    "                break\n",
    "            states, actions, rewards, next_states, dones = batch\n",
    "            states = states.clone().detach().float()\n",
    "            next_states = next_states.clone().detach().float()\n",
    "            actions = torch.tensor([self.action_to_index[action.item()] for action in actions]).view(-1, 1)\n",
    "            rewards = rewards.clone().detach().float().view(-1, 1)\n",
    "            q_values = self.q_network(states).gather(1, actions)\n",
    "            dones = dones.float()\n",
    "\n",
    "            next_q_values = self.target_network(next_states).max(1, keepdim=True)[0].detach().view(-1, 1)\n",
    "            target_q_values = rewards + self.discount_factor * next_q_values * (1 - dones).view(-1,1)\n",
    "\n",
    "            loss = self.loss_fn(q_values, target_q_values)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if self.learn_count%10000==0:\n",
    "                for name, param in agent.q_network.named_parameters():\n",
    "                    if 'fc2.weight' in name and param.requires_grad:\n",
    "                        print(f\"{name} grad: {param.grad}\")\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.learn_count += 1\n",
    "            # Update target network every few episodes\n",
    "            if self.learn_count % 1 == 0:\n",
    "                self.update_target_network()\n",
    "            if self.learn_count % 100 == 0:\n",
    "                self.epsilon = max(0.3, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "            batch_count += 1\n",
    "        \n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2.weight grad: tensor([[ 1.6290e-02,  8.7172e-03,  2.1620e-03,  3.1770e-03,  2.0897e-02,\n",
      "         -1.4109e-04,  6.1629e-04,  1.3227e-02],\n",
      "        [-1.9149e-04, -1.0329e-04, -3.4899e-05, -3.3670e-05, -2.7846e-04,\n",
      "          1.8155e-06, -1.3696e-05, -1.7269e-04],\n",
      "        [ 1.2183e-02,  6.3386e-03,  1.6039e-03,  2.4128e-03,  1.5412e-02,\n",
      "         -1.0807e-04,  3.4424e-04,  9.7440e-03],\n",
      "        [-3.0968e-02, -1.6669e-02, -5.6662e-03, -5.4456e-03, -4.5016e-02,\n",
      "          2.9459e-04, -2.1945e-03, -2.7903e-02],\n",
      "        [ 8.0436e-05,  4.3044e-05,  7.3408e-06,  9.5143e-06,  2.0019e-04,\n",
      "         -3.9590e-06, -5.5824e-06,  6.9772e-05],\n",
      "        [ 2.4116e-03,  1.3232e-03,  4.2058e-04,  4.2458e-04,  3.5171e-03,\n",
      "         -2.2123e-05,  1.8780e-04,  2.1930e-03],\n",
      "        [ 2.6125e-04,  1.4054e-04,  4.7912e-05,  4.5931e-05,  3.7972e-04,\n",
      "         -2.4889e-06,  1.8434e-05,  2.3530e-04],\n",
      "        [ 3.7746e-04,  2.0226e-04,  6.9930e-05,  6.6337e-05,  5.4827e-04,\n",
      "         -3.6231e-06,  2.6076e-05,  3.3930e-04]])\n",
      "fc2.weight grad: tensor([[-2.1790e+01,  4.3836e-01, -1.5737e+01, -2.3204e+01,  2.9091e-01,\n",
      "          2.3361e-01, -2.1732e+01, -2.6845e+01],\n",
      "        [-9.7254e-01,  2.1573e-02, -7.0473e-01, -1.0293e+00,  1.2889e-02,\n",
      "          1.0359e-02, -9.7460e-01, -1.1937e+00],\n",
      "        [-3.1981e-01,  6.3873e-03, -2.3070e-01, -3.4053e-01,  4.2721e-03,\n",
      "          3.4291e-03, -3.1902e-01, -3.9421e-01],\n",
      "        [-1.5456e+01,  3.3039e-01, -1.1150e+01, -1.6371e+01,  2.0547e-01,\n",
      "          1.6487e-01, -1.5486e+01, -1.9015e+01],\n",
      "        [-3.6721e-01,  6.9266e-03, -2.6365e-01, -3.9168e-01,  4.9249e-03,\n",
      "          3.9469e-03, -3.6590e-01, -4.5388e-01],\n",
      "        [-3.0483e-01,  5.8644e-03, -2.1997e-01, -3.2554e-01,  4.0822e-03,\n",
      "          3.2776e-03, -3.0331e-01, -3.7608e-01],\n",
      "        [-6.7596e-01,  1.4748e-02, -4.8678e-01, -7.1408e-01,  8.9725e-03,\n",
      "          7.1943e-03, -6.7880e-01, -8.3148e-01],\n",
      "        [ 1.9930e-01, -4.4183e-03,  1.4388e-01,  2.1053e-01, -2.6419e-03,\n",
      "         -2.1202e-03,  2.0010e-01,  2.4487e-01]])\n",
      "fc2.weight grad: tensor([[ 5.0801e+05, -5.2930e+03,  5.1761e+05,  5.3196e+05, -5.3631e+03,\n",
      "         -5.2058e+03,  5.1383e+05,  5.2861e+05],\n",
      "        [-1.5223e+05,  1.5966e+03, -1.6031e+05, -1.6311e+05,  1.6136e+03,\n",
      "          1.5792e+03, -1.4578e+05, -1.5377e+05],\n",
      "        [-1.1507e+05,  1.1950e+03, -1.1526e+05, -1.1908e+05,  1.2126e+03,\n",
      "          1.1718e+03, -1.1951e+05, -1.2151e+05],\n",
      "        [ 7.8129e+05, -8.1391e+03,  7.9544e+05,  8.1769e+05, -8.2475e+03,\n",
      "         -8.0040e+03,  7.9119e+05,  8.1351e+05],\n",
      "        [-6.8876e+03,  7.1735e+01, -7.0041e+03, -7.2027e+03,  7.2698e+01,\n",
      "          7.0530e+01, -6.9878e+03, -7.1790e+03],\n",
      "        [ 1.0872e+05, -1.1352e+03,  1.1204e+05,  1.1474e+05, -1.1492e+03,\n",
      "         -1.1188e+03,  1.0798e+05,  1.1200e+05],\n",
      "        [-9.5028e+03,  9.9021e+01, -9.6883e+03, -9.9551e+03,  1.0033e+02,\n",
      "          9.7402e+01, -9.6025e+03, -9.8830e+03],\n",
      "        [-8.0849e+03,  8.4219e+01, -8.2283e+03, -8.4594e+03,  8.5343e+01,\n",
      "          8.2816e+01, -8.1923e+03, -8.4212e+03]])\n",
      "Episode 1: Total Return: 0.509, Epsilon: 0.88\n",
      "fc2.weight grad: tensor([[ 1.3514e+03, -1.3320e+01,  1.6500e+03,  1.6142e+03, -1.2814e+01,\n",
      "         -1.5174e+01,  3.4042e+02,  8.4972e+02],\n",
      "        [ 1.2860e+02, -1.3505e+00,  1.3336e+02,  1.3862e+02, -1.3793e+00,\n",
      "         -1.3404e+00,  1.1782e+02,  1.2992e+02],\n",
      "        [ 1.5403e+02, -1.6160e+00,  1.6064e+02,  1.6654e+02, -1.6450e+00,\n",
      "         -1.6084e+00,  1.3975e+02,  1.5456e+02],\n",
      "        [ 1.7363e+03, -1.8222e+01,  1.8075e+03,  1.8755e+03, -1.8569e+01,\n",
      "         -1.8120e+01,  1.5805e+03,  1.7462e+03],\n",
      "        [-4.8202e+01,  5.0599e-01, -5.0114e+01, -5.2030e+01,  5.1600e-01,\n",
      "          5.0281e-01, -4.3981e+01, -4.8554e+01],\n",
      "        [ 1.3861e+02, -1.4543e+00,  1.4452e+02,  1.4985e+02, -1.4806e+00,\n",
      "         -1.4473e+00,  1.2583e+02,  1.3913e+02],\n",
      "        [ 3.6191e+01, -3.8004e-01,  3.7557e+01,  3.9026e+01, -3.8796e-01,\n",
      "         -3.7729e-01,  3.3141e+01,  3.6543e+01],\n",
      "        [-1.6361e+01,  1.7176e-01, -1.6996e+01, -1.7652e+01,  1.7524e-01,\n",
      "          1.7062e-01, -1.4947e+01, -1.6495e+01]])\n",
      "fc2.weight grad: tensor([[-1.4207e+06,  1.6058e+04, -1.6069e+06, -1.6700e+06,  1.6572e+04,\n",
      "          1.5471e+04, -1.3857e+06, -1.5474e+06],\n",
      "        [ 5.4622e+06, -6.1716e+04,  6.1769e+06,  6.4184e+06, -6.3683e+04,\n",
      "         -5.9468e+04,  5.3262e+06,  5.9468e+06],\n",
      "        [-2.3591e+06,  2.6601e+04, -2.6617e+06, -2.7643e+06,  2.7437e+04,\n",
      "          2.5643e+04, -2.3017e+06, -2.5648e+06],\n",
      "        [-1.6587e+06,  1.8762e+04, -1.8776e+06, -1.9518e+06,  1.9365e+04,\n",
      "          1.8072e+04, -1.6174e+06, -1.8075e+06],\n",
      "        [ 1.5796e+04, -1.7897e+02,  1.7913e+04,  1.8628e+04, -1.8479e+02,\n",
      "         -1.7232e+02,  1.5398e+04,  1.7235e+04],\n",
      "        [ 4.5576e+05, -5.1269e+03,  5.1191e+05,  5.3177e+05, -5.2882e+03,\n",
      "         -4.9419e+03,  4.4596e+05,  4.9534e+05],\n",
      "        [ 1.6888e+04, -1.9105e+02,  1.9135e+04,  1.9884e+04, -1.9716e+02,\n",
      "         -1.8407e+02,  1.6451e+04,  1.8395e+04],\n",
      "        [ 1.6711e+04, -1.8907e+02,  1.8922e+04,  1.9670e+04, -1.9516e+02,\n",
      "         -1.8211e+02,  1.6293e+04,  1.8213e+04]])\n",
      "fc2.weight grad: tensor([[ 2.8657e+02, -7.4308e+00,  1.1215e+03,  1.1290e+03, -8.3211e+00,\n",
      "         -6.7619e+00, -1.9263e+02,  3.6483e+02],\n",
      "        [-2.8941e+01,  7.2114e-01, -1.0768e+02, -1.0847e+02,  8.0579e-01,\n",
      "          6.5721e-01,  1.6178e+01, -3.6469e+01],\n",
      "        [-1.7951e+03,  4.3011e+01, -6.3431e+03, -6.3987e+03,  4.7974e+01,\n",
      "          3.9232e+01,  8.0605e+02, -2.2439e+03],\n",
      "        [-6.7874e+02,  7.6809e+00, -7.3894e+02, -7.8302e+02,  8.0826e+00,\n",
      "          7.2367e+00, -6.7017e+02, -7.5015e+02],\n",
      "        [ 8.0280e+00, -3.5215e-02, -2.0189e+00, -1.3474e+00, -3.0405e-02,\n",
      "         -3.6339e-02,  1.4248e+01,  8.2360e+00],\n",
      "        [ 3.8818e+03, -7.6345e+01,  1.0495e+04,  1.0660e+04, -8.4213e+01,\n",
      "         -7.0087e+01,  1.4968e+02,  4.6612e+03],\n",
      "        [ 9.1643e+00, -9.8000e-02,  8.8486e+00,  9.4700e+00, -1.0251e-01,\n",
      "         -9.2578e-02,  9.7138e+00,  1.0076e+01],\n",
      "        [ 7.9218e+00, -8.8295e-02,  8.3621e+00,  8.8807e+00, -9.2755e-02,\n",
      "         -8.3262e-02,  7.9761e+00,  8.7404e+00]])\n",
      "Episode 2: Total Return: 0.383, Epsilon: 0.77\n",
      "fc2.weight grad: tensor([[-3.2912e+02,  4.0232e+00, -4.6183e+02, -4.5782e+02,  4.0424e+00,\n",
      "          3.8762e+00, -2.4611e+02, -3.2931e+02],\n",
      "        [-1.4246e+02,  1.4049e+00, -1.4295e+02, -1.4058e+02,  1.3598e+00,\n",
      "          1.4275e+00, -1.3179e+02, -1.3385e+02],\n",
      "        [-1.3939e+04,  1.4405e+02, -1.5318e+04, -1.5009e+04,  1.3996e+02,\n",
      "          1.4546e+02, -1.2105e+04, -1.3108e+04],\n",
      "        [-2.6498e+02,  2.9961e+00, -3.3124e+02, -3.2817e+02,  2.9807e+00,\n",
      "          2.9508e+00, -2.1273e+02, -2.5843e+02],\n",
      "        [ 2.3744e+02, -2.5152e+00,  2.7312e+02,  2.6727e+02, -2.4502e+00,\n",
      "         -2.5311e+00,  1.9930e+02,  2.2370e+02],\n",
      "        [-3.9936e+02,  4.1552e+00, -4.4456e+02, -4.3537e+02,  4.0397e+00,\n",
      "          4.1923e+00, -3.4347e+02, -3.7561e+02],\n",
      "        [ 1.8531e+02, -1.9747e+00,  2.1567e+02,  2.1088e+02, -1.9237e+00,\n",
      "         -1.9862e+00,  1.5387e+02,  1.7443e+02],\n",
      "        [ 2.0448e+02, -2.1466e+00,  2.3139e+02,  2.2652e+02, -2.0891e+00,\n",
      "         -2.1630e+00,  1.7375e+02,  1.9248e+02]])\n",
      "fc2.weight grad: tensor([[ 6.4517e+04, -6.3396e+02,  6.9645e+04,  6.8436e+04, -6.2702e+02,\n",
      "         -6.6934e+02,  5.8173e+04,  6.2464e+04],\n",
      "        [ 4.0527e+02, -3.5092e+00,  3.9751e+02,  3.7199e+02, -3.2676e+00,\n",
      "         -3.9572e+00,  3.7146e+02,  3.6021e+02],\n",
      "        [ 1.9774e+05, -1.8518e+03,  2.0594e+05,  1.9873e+05, -1.7924e+03,\n",
      "         -2.0043e+03,  1.7930e+05,  1.8519e+05],\n",
      "        [-1.5516e+05,  1.4734e+03, -1.6325e+05, -1.5839e+05,  1.4354e+03,\n",
      "          1.5832e+03, -1.4048e+05, -1.4672e+05],\n",
      "        [-3.7176e+03,  3.5073e+01, -3.8925e+03, -3.7670e+03,  3.4064e+01,\n",
      "          3.7814e+01, -3.3685e+03, -3.4995e+03],\n",
      "        [-3.0661e+05,  2.8811e+03, -3.2017e+05, -3.0936e+05,  2.7931e+03,\n",
      "          3.1129e+03, -2.7787e+05, -2.8781e+05],\n",
      "        [-2.6740e+03,  2.5339e+01, -2.8095e+03, -2.7234e+03,  2.4660e+01,\n",
      "          2.7257e+01, -2.4212e+03, -2.5246e+03],\n",
      "        [-2.7858e+03,  2.6254e+01, -2.9148e+03, -2.8197e+03,  2.5487e+01,\n",
      "          2.8322e+01, -2.5243e+03, -2.6204e+03]])\n",
      "Episode 3: Total Return: 0.117, Epsilon: 0.68\n",
      "fc2.weight grad: tensor([[-6.6885e+04,  7.2606e+02, -8.5542e+04, -8.5529e+04,  7.4378e+02,\n",
      "          7.6361e+02, -5.3215e+04, -6.8227e+04],\n",
      "        [-1.6565e+03,  1.7483e+01, -1.7898e+03, -1.8186e+03,  1.7734e+01,\n",
      "          1.7372e+01, -1.5928e+03, -1.7104e+03],\n",
      "        [-6.9851e+03,  7.7770e+01, -1.0214e+04, -1.0100e+04,  8.0355e+01,\n",
      "          8.5747e+01, -4.4871e+03, -7.0451e+03],\n",
      "        [-8.9380e+02,  9.8681e+00, -1.2515e+03, -1.2418e+03,  1.0167e+01,\n",
      "          1.0712e+01, -6.2049e+02, -9.0497e+02],\n",
      "        [ 4.1906e+02, -4.5523e+00,  5.3816e+02,  5.3788e+02, -4.6646e+00,\n",
      "         -4.7946e+00,  3.3158e+02,  4.2733e+02],\n",
      "        [-1.4415e+03,  1.5806e+01, -1.9468e+03, -1.9374e+03,  1.6248e+01,\n",
      "          1.6941e+01, -1.0605e+03, -1.4640e+03],\n",
      "        [ 2.2684e+02, -2.3747e+00,  2.3299e+02,  2.3796e+02, -2.4018e+00,\n",
      "         -2.3220e+00,  2.2826e+02,  2.3495e+02],\n",
      "        [ 2.1981e+02, -2.3750e+00,  2.7395e+02,  2.7453e+02, -2.4290e+00,\n",
      "         -2.4759e+00,  1.8091e+02,  2.2467e+02]])\n",
      "fc2.weight grad: tensor([[ 2.0281e+06, -2.3116e+04,  2.2027e+06,  2.3134e+06, -2.3969e+04,\n",
      "         -2.1621e+04,  2.1148e+06,  2.2611e+06],\n",
      "        [-5.0759e+06,  5.7864e+04, -5.5053e+06, -5.7844e+06,  6.0000e+04,\n",
      "          5.4080e+04, -5.3006e+06, -5.6613e+06],\n",
      "        [ 3.8666e+06, -4.4080e+04,  4.1926e+06,  4.4054e+06, -4.5707e+04,\n",
      "         -4.1191e+04,  4.0390e+06,  4.3129e+06],\n",
      "        [-1.8272e+03,  2.1441e+01, -1.7146e+03, -1.8930e+03,  2.2403e+01,\n",
      "          1.8347e+01, -2.2083e+03, -2.1436e+03],\n",
      "        [-4.2434e+04,  4.8394e+02, -4.5730e+04, -4.8125e+04,  5.0184e+02,\n",
      "          4.5080e+02, -4.4607e+04, -4.7404e+04],\n",
      "        [ 1.9456e+03, -2.1526e+01,  2.7531e+03,  2.7120e+03, -2.2168e+01,\n",
      "         -2.3552e+01,  1.3734e+03,  1.9860e+03],\n",
      "        [-3.8406e+04,  4.3803e+02, -4.1408e+04, -4.3574e+04,  4.5424e+02,\n",
      "          4.0810e+02, -4.0357e+04, -4.2903e+04],\n",
      "        [-4.0131e+04,  4.5761e+02, -4.3362e+04, -4.5604e+04,  4.7452e+02,\n",
      "          4.2684e+02, -4.2073e+04, -4.4803e+04]])\n",
      "fc2.weight grad: tensor([[ 1.8947e+09, -2.1423e+07,  2.0763e+09,  2.1541e+09, -2.2047e+07,\n",
      "         -2.0202e+07,  1.9647e+09,  2.0990e+09],\n",
      "        [-2.4650e+07,  2.7936e+05, -2.7083e+07, -2.8110e+07,  2.8766e+05,\n",
      "          2.6322e+05, -2.5550e+07, -2.7351e+07],\n",
      "        [ 6.9956e+09, -7.9103e+07,  7.6666e+09,  7.9543e+09, -8.1411e+07,\n",
      "         -7.4592e+07,  7.2538e+09,  7.7501e+09],\n",
      "        [-2.2374e+07,  2.5315e+05, -2.4537e+07, -2.5460e+07,  2.6057e+05,\n",
      "          2.3866e+05, -2.3197e+07, -2.4798e+07],\n",
      "        [-7.1692e+07,  8.1068e+05, -7.8571e+07, -8.1519e+07,  8.3434e+05,\n",
      "          7.6444e+05, -7.4337e+07, -7.9425e+07],\n",
      "        [-2.3219e+07,  2.6282e+05, -2.5476e+07, -2.6437e+07,  2.7056e+05,\n",
      "          2.4774e+05, -2.4071e+07, -2.5741e+07],\n",
      "        [-6.8396e+07,  7.7347e+05, -7.4966e+07, -7.7780e+07,  7.9606e+05,\n",
      "          7.2934e+05, -7.0919e+07, -7.5778e+07],\n",
      "        [-7.0436e+07,  7.9648e+05, -7.7195e+07, -8.0091e+07,  8.1972e+05,\n",
      "          7.5105e+05, -7.3035e+07, -7.8034e+07]])\n",
      "Episode 4: Total Return: 0.366, Epsilon: 0.60\n",
      "fc2.weight grad: tensor([[-2.0217e+03,  5.9313e+01, -6.2699e+03, -7.2330e+03,  7.3426e+01,\n",
      "          4.3078e+01, -1.7912e+03, -4.8064e+03],\n",
      "        [ 1.5571e+02, -7.9865e+00,  9.3322e+02,  1.0713e+03, -1.0487e+01,\n",
      "         -5.5463e+00,  1.0612e+02,  6.2033e+02],\n",
      "        [ 1.3013e+04, -1.2028e+02,  1.1090e+04,  1.1090e+04, -1.1482e+02,\n",
      "         -1.2196e+02,  1.3690e+04,  1.2517e+04],\n",
      "        [ 2.3888e+03, -2.5269e+01,  2.4254e+03,  2.4927e+03, -2.5516e+01,\n",
      "         -2.4377e+01,  2.4850e+03,  2.5268e+03],\n",
      "        [-1.7421e+02,  1.4487e+00, -1.2893e+02, -1.2547e+02,  1.3127e+00,\n",
      "          1.5322e+00, -1.8465e+02, -1.5598e+02],\n",
      "        [ 1.9360e+03, -1.7186e+01,  1.5631e+03,  1.5482e+03, -1.6096e+01,\n",
      "         -1.7701e+01,  2.0429e+03,  1.8112e+03],\n",
      "        [ 1.8335e+02, -2.6183e+00,  2.6906e+02,  2.8857e+02, -2.9031e+00,\n",
      "         -2.2946e+00,  1.8478e+02,  2.4272e+02],\n",
      "        [-9.5711e+01,  6.2526e-01, -4.9946e+01, -4.4452e+01,  4.8365e-01,\n",
      "          7.3524e-01, -1.0296e+02, -7.3425e+01]])\n",
      "fc2.weight grad: tensor([[ 2.3428e+03, -5.2377e+01,  4.8210e+03,  5.4468e+03, -5.8102e+01,\n",
      "         -4.4404e+01,  2.7625e+03,  4.8049e+03],\n",
      "        [-6.1373e+03,  1.4265e+02, -1.3543e+04, -1.4987e+04,  1.5693e+02,\n",
      "          1.2803e+02, -6.9533e+03, -1.3187e+04],\n",
      "        [ 6.8329e+04, -1.6526e+03,  1.5758e+05,  1.7420e+05, -1.8203e+03,\n",
      "         -1.4922e+03,  7.7301e+04,  1.5258e+05],\n",
      "        [-7.3201e+03,  1.9825e+02, -1.9925e+04, -2.1311e+04,  2.1565e+02,\n",
      "          1.9621e+02, -7.5965e+03, -1.8510e+04],\n",
      "        [ 1.5325e+02,  1.8137e+00, -2.9839e+02, -2.5897e+02,  1.8934e+00,\n",
      "          3.6069e+00,  2.3829e+02, -1.7464e+02],\n",
      "        [-1.5832e+05,  3.6822e+03, -3.4659e+05, -3.8600e+05,  4.0638e+03,\n",
      "          3.2511e+03, -1.8181e+05, -3.3937e+05],\n",
      "        [-1.6879e+02,  2.6003e+00, -1.8625e+02, -2.4792e+02,  3.0127e+00,\n",
      "          1.3179e+00, -2.3106e+02, -2.2881e+02],\n",
      "        [-3.1610e+02,  9.3578e+00, -9.2643e+02, -1.0061e+03,  1.0296e+01,\n",
      "          8.9743e+00, -3.4138e+02, -8.6460e+02]])\n",
      "Episode 5: Total Return: 0.090, Epsilon: 0.52\n",
      "fc2.weight grad: tensor([[-6.4350e+06,  8.1931e+04, -7.9516e+06, -8.2377e+06,  8.3978e+04,\n",
      "          7.8579e+04, -6.8937e+06, -8.0509e+06],\n",
      "        [-7.8483e+06,  1.0170e+05, -9.8290e+06, -1.0229e+07,  1.0462e+05,\n",
      "          9.6644e+04, -8.4693e+06, -9.9614e+06],\n",
      "        [ 9.0766e+08, -1.1669e+07,  1.1299e+09,  1.1735e+09, -1.1985e+07,\n",
      "         -1.1135e+07,  9.7625e+08,  1.1446e+09],\n",
      "        [-1.3825e+07,  1.7333e+05, -1.6869e+07, -1.7417e+07,  1.7715e+05,\n",
      "          1.6729e+05, -1.4730e+07, -1.7074e+07],\n",
      "        [-1.0095e+07,  1.2924e+05, -1.2526e+07, -1.2996e+07,  1.3262e+05,\n",
      "          1.2359e+05, -1.0839e+07, -1.2687e+07],\n",
      "        [ 2.2676e+08, -2.9236e+06,  2.8296e+08,  2.9405e+08, -3.0043e+06,\n",
      "         -2.7867e+06,  2.4414e+08,  2.8665e+08],\n",
      "        [-7.8805e+06,  1.0153e+05, -9.8271e+06, -1.0211e+07,  1.0433e+05,\n",
      "          9.6790e+04, -8.4832e+06, -9.9559e+06],\n",
      "        [-9.3216e+06,  1.1969e+05, -1.1593e+07, -1.2037e+07,  1.2290e+05,\n",
      "          1.1429e+05, -1.0021e+07, -1.1744e+07]])\n",
      "fc2.weight grad: tensor([[-2.2907e+05,  3.1811e+03, -2.9635e+05, -3.1803e+05,  3.3330e+03,\n",
      "          2.8188e+03, -2.6163e+05, -3.0657e+05],\n",
      "        [-3.6754e+05,  5.3547e+03, -5.0697e+05, -5.4063e+05,  5.6133e+03,\n",
      "          4.8850e+03, -4.1144e+05, -5.1641e+05],\n",
      "        [ 5.5190e+07, -7.8848e+05,  7.4173e+07,  7.9296e+07, -8.2637e+05,\n",
      "         -7.1106e+05,  6.2296e+07,  7.6021e+07],\n",
      "        [-1.3046e+06,  1.8087e+04, -1.6897e+06, -1.8097e+06,  1.8931e+04,\n",
      "          1.6118e+04, -1.4822e+06, -1.7447e+06],\n",
      "        [-6.8628e+05,  9.7575e+03, -9.1633e+05, -9.8029e+05,  1.0226e+04,\n",
      "          8.7723e+03, -7.7634e+05, -9.4067e+05],\n",
      "        [-1.4829e+07,  2.1054e+05, -1.9780e+07, -2.1152e+07,  2.2058e+05,\n",
      "          1.8946e+05, -1.6756e+07, -2.0302e+07],\n",
      "        [-3.9109e+05,  5.6109e+03, -5.2837e+05, -5.6469e+05,  5.8815e+03,\n",
      "          5.0691e+03, -4.4097e+05, -5.4095e+05],\n",
      "        [-5.8188e+05,  8.3023e+03, -7.8058e+05, -8.3469e+05,  8.7014e+03,\n",
      "          7.4796e+03, -6.5729e+05, -8.0042e+05]])\n",
      "fc2.weight grad: tensor([[-5.5499e+01,  6.7530e-01, -6.8246e+01, -6.8637e+01,  6.7768e-01,\n",
      "          7.3616e-01, -5.3722e+01, -6.7950e+01],\n",
      "        [ 8.6163e+01, -1.0426e+00,  1.0487e+02,  1.0580e+02, -1.0482e+00,\n",
      "         -1.1240e+00,  8.4146e+01,  1.0477e+02],\n",
      "        [-1.5572e+03,  1.8225e+01, -1.7936e+03, -1.8300e+03,  1.8410e+01,\n",
      "          1.8726e+01, -1.5732e+03, -1.8209e+03],\n",
      "        [ 2.0653e+02, -2.2965e+00,  2.1651e+02,  2.2684e+02, -2.3517e+00,\n",
      "         -2.1249e+00,  2.2197e+02,  2.2682e+02],\n",
      "        [ 2.2104e+02, -2.5623e+00,  2.5044e+02,  2.5651e+02, -2.5930e+00,\n",
      "         -2.5915e+00,  2.2561e+02,  2.5555e+02],\n",
      "        [-3.0647e+02,  3.5668e+00, -3.4955e+02, -3.5754e+02,  3.6076e+00,\n",
      "          3.6290e+00, -3.1165e+02, -3.5597e+02],\n",
      "        [-7.7043e+02,  8.9665e+00, -8.7864e+02, -8.9880e+02,  9.0699e+00,\n",
      "          9.1199e+00, -7.8360e+02, -8.9483e+02],\n",
      "        [ 7.3173e+01, -8.4967e-01,  8.3167e+01,  8.5106e+01, -8.5944e-01,\n",
      "         -8.6233e-01,  7.4518e+01,  8.4774e+01]])\n",
      "Episode 6: Total Return: 0.014, Epsilon: 0.46\n",
      "fc2.weight grad: tensor([[-3.7922e+02,  1.7156e+01, -1.6667e+03, -1.7807e+03,  1.8245e+01,\n",
      "          1.6519e+01, -8.8599e+02, -1.6279e+03],\n",
      "        [-1.7041e+03,  2.4854e+01, -2.2143e+03, -2.4793e+03,  2.6868e+01,\n",
      "          1.9591e+01, -2.1809e+03, -2.3595e+03],\n",
      "        [ 2.7059e+04, -5.3452e+02,  4.9381e+04,  5.4165e+04, -5.7352e+02,\n",
      "         -4.5958e+02,  3.9350e+04,  5.0773e+04],\n",
      "        [-1.9780e+03,  9.7072e+01, -9.3960e+03, -1.0085e+04,  1.0363e+02,\n",
      "          9.2644e+01, -4.9490e+03, -9.1865e+03],\n",
      "        [-2.2664e+03,  5.2097e+01, -4.8744e+03, -5.3111e+03,  5.5778e+01,\n",
      "          4.6123e+01, -3.5500e+03, -4.9472e+03],\n",
      "        [-9.3612e+04,  1.9612e+03, -1.8202e+05, -1.9922e+05,  2.1032e+03,\n",
      "          1.7043e+03, -1.4012e+05, -1.8623e+05],\n",
      "        [ 2.7984e+02,  2.1997e-01, -6.3453e+01, -4.6927e+01,  1.7928e-01,\n",
      "          1.1153e+00,  2.0230e+02, -1.7767e+01],\n",
      "        [-9.3965e+02,  2.0604e+01, -1.9213e+03, -2.0968e+03,  2.2068e+01,\n",
      "          1.8102e+01, -1.4365e+03, -1.9570e+03]])\n",
      "fc2.weight grad: tensor([[ 2.3349e+03,  9.5694e+01, -8.7632e+03, -1.0169e+04,  1.0885e+02,\n",
      "          8.3724e+01, -2.1525e+03, -8.6793e+03],\n",
      "        [-2.1269e+03,  3.7573e+01, -9.6352e+02, -3.1138e+03,  5.2414e+01,\n",
      "         -3.3431e+01, -1.2113e+04, -3.1152e+03],\n",
      "        [-1.8110e+04, -1.1474e+04,  1.1070e+06,  1.2008e+06, -1.2356e+04,\n",
      "         -1.1340e+04,  4.5545e+05,  1.0903e+06],\n",
      "        [ 1.1212e+04,  1.7237e+03, -1.7606e+05, -1.7896e+05,  1.7583e+03,\n",
      "          2.0011e+03, -4.6018e+04, -1.6810e+05],\n",
      "        [ 1.1700e+03,  1.2484e+02, -1.1838e+04, -1.3133e+04,  1.3699e+02,\n",
      "          1.1860e+02, -4.2233e+03, -1.1680e+04],\n",
      "        [-2.0916e+03, -2.1707e+02,  2.0585e+04,  2.2840e+04, -2.3823e+02,\n",
      "         -2.0629e+02,  7.3084e+03,  2.0307e+04],\n",
      "        [ 4.7711e+02,  1.2268e+02, -1.1778e+04, -1.2859e+04,  1.3284e+02,\n",
      "          1.1990e+02, -4.6576e+03, -1.1606e+04],\n",
      "        [ 4.8406e+02,  9.7814e+01, -9.3667e+03, -1.0260e+04,  1.0620e+02,\n",
      "          9.5044e+01, -3.6344e+03, -9.2326e+03]])\n",
      "fc2.weight grad: tensor([[-7.5415e+00,  1.3150e-01, -1.8850e+01, -1.2852e+01,  8.2978e-02,\n",
      "          2.7127e-01, -1.3095e+01, -1.5123e+01],\n",
      "        [ 3.8072e+01, -3.9032e-01,  1.1615e+01,  3.6369e+01, -5.6500e-01,\n",
      "          1.5260e-01,  2.1077e+01,  3.0967e+01],\n",
      "        [ 6.0106e+02, -7.8388e+00,  8.4946e+02,  7.5194e+02, -6.8795e+00,\n",
      "         -1.0230e+01,  7.0232e+02,  8.1785e+02],\n",
      "        [-1.2048e+02,  1.4542e+00, -1.2741e+02, -1.3818e+02,  1.4919e+00,\n",
      "          1.2513e+00, -1.1631e+02, -1.4217e+02],\n",
      "        [ 4.9541e+01, -4.1883e-01, -7.6371e-01,  3.8161e+01, -6.9736e-01,\n",
      "          4.4844e-01,  1.9223e+01,  2.9252e+01],\n",
      "        [ 1.1438e+02, -1.4162e+00,  1.2834e+02,  1.3486e+02, -1.4237e+00,\n",
      "         -1.3102e+00,  1.1429e+02,  1.3973e+02],\n",
      "        [-3.1998e+00,  4.7203e-02, -5.7274e+00, -4.5612e+00,  3.7129e-02,\n",
      "          7.4964e-02, -4.3434e+00, -5.1079e+00],\n",
      "        [ 1.7178e+01, -1.4872e-01,  1.0283e+00,  1.3598e+01, -2.3823e-01,\n",
      "          1.3115e-01,  7.3699e+00,  1.0797e+01]])\n",
      "Episode 7: Total Return: 0.159, Epsilon: 0.40\n",
      "fc2.weight grad: tensor([[-5.1073e+03,  7.0268e+01, -6.9355e+03, -7.0060e+03,  7.0368e+01,\n",
      "          7.0829e+01, -6.3944e+03, -7.0172e+03],\n",
      "        [-8.7087e+03,  1.2710e+02, -1.2538e+04, -1.2705e+04,  1.2777e+02,\n",
      "          1.2796e+02, -1.1296e+04, -1.2659e+04],\n",
      "        [-6.8119e+04,  9.2779e+02, -9.1564e+04, -9.2466e+04,  9.2866e+02,\n",
      "          9.3496e+02, -8.4753e+04, -9.2689e+04],\n",
      "        [-2.0956e+04,  2.5362e+02, -2.5041e+04, -2.5138e+04,  2.5191e+02,\n",
      "          2.5578e+02, -2.4332e+04, -2.5479e+04],\n",
      "        [-1.6357e+04,  2.3086e+02, -2.2783e+04, -2.3043e+04,  2.3155e+02,\n",
      "          2.3264e+02, -2.0796e+04, -2.3028e+04],\n",
      "        [-1.4601e+04,  2.1636e+02, -2.1346e+04, -2.1640e+04,  2.1764e+02,\n",
      "          2.1790e+02, -1.9123e+04, -2.1537e+04],\n",
      "        [-2.0297e+03,  2.7424e+01, -2.7068e+03, -2.7321e+03,  2.7434e+01,\n",
      "          2.7642e+01, -2.5136e+03, -2.7408e+03],\n",
      "        [-4.3508e+03,  6.2253e+01, -6.1435e+03, -6.2172e+03,  6.2488e+01,\n",
      "          6.2732e+01, -5.5781e+03, -6.2062e+03]])\n",
      "fc2.weight grad: tensor([[  1447.8402,     52.4040,  -5919.2705,  -5438.4219,     49.1874,\n",
      "             71.1520,  -3082.0374,  -5438.3496],\n",
      "        [  1851.8328,     56.0110,  -6354.2637,  -5822.0698,     52.4768,\n",
      "             76.8681,  -3152.9756,  -5812.6294],\n",
      "        [ -1616.9310,   -355.4199,  39175.3086,  36605.9648,   -337.2335,\n",
      "           -468.1583,  18017.5469,  36443.9219],\n",
      "        [  2003.7100,    112.9278, -12654.5830, -11685.2861,    106.3489,\n",
      "            150.3252,  -7159.5308, -11719.4893],\n",
      "        [  2163.4407,     65.9377,  -7478.9209,  -6853.4209,     61.7825,\n",
      "             90.4468,  -3719.4719,  -6842.7974],\n",
      "        [  2976.0679,     85.4968,  -9712.8672,  -8891.5752,     80.0551,\n",
      "            117.7358,  -4743.5034,  -8872.5566],\n",
      "        [  1401.5057,     52.8410,  -5963.3462,  -5481.9839,     49.6161,\n",
      "             71.5883,  -3134.8386,  -5483.7075],\n",
      "        [  1474.6044,     50.3707,  -5697.1147,  -5229.9512,     47.2527,\n",
      "             68.6144,  -2923.9705,  -5227.3242]])\n",
      "Episode 8: Total Return: 0.197, Epsilon: 0.35\n",
      "fc2.weight grad: tensor([[-2.3384e+03,  2.8331e+01, -2.7587e+03, -2.7867e+03,  2.8091e+01,\n",
      "          2.8128e+01, -2.6972e+03, -2.8586e+03],\n",
      "        [-2.1695e+03,  2.6330e+01, -2.5472e+03, -2.5897e+03,  2.6231e+01,\n",
      "          2.5789e+01, -2.4855e+03, -2.6487e+03],\n",
      "        [ 2.5945e+03, -3.1440e+01,  3.0639e+03,  3.0927e+03, -3.1158e+01,\n",
      "         -3.1265e+01,  2.9958e+03,  3.1735e+03],\n",
      "        [-4.2602e+03,  5.1700e+01, -5.0996e+03, -5.0882e+03,  5.0800e+01,\n",
      "          5.2702e+01, -4.9953e+03, -5.2471e+03],\n",
      "        [-1.1964e+02,  1.4301e+00, -1.2792e+02, -1.4017e+02,  1.4980e+00,\n",
      "          1.1816e+00, -1.2358e+02, -1.3905e+02],\n",
      "        [-1.9647e+03,  2.3778e+01, -2.2764e+03, -2.3374e+03,  2.3855e+01,\n",
      "          2.2788e+01, -2.2190e+03, -2.3810e+03],\n",
      "        [-2.2173e+03,  2.6865e+01, -2.6193e+03, -2.6427e+03,  2.6614e+01,\n",
      "          2.6742e+01, -2.5615e+03, -2.7123e+03],\n",
      "        [-1.9522e+03,  2.3636e+01, -2.2952e+03, -2.3246e+03,  2.3480e+01,\n",
      "          2.3333e+01, -2.2434e+03, -2.3820e+03]])\n",
      "fc2.weight grad: tensor([[ -803.3630,    20.6880, -2109.3035, -2073.8372,    20.1129,    21.8509,\n",
      "         -1635.4937, -2083.2139],\n",
      "        [ -823.1326,    23.2264, -2392.5051, -2331.7507,    22.4260,    24.9193,\n",
      "         -1849.4473, -2344.9900],\n",
      "        [  160.2280,    -4.1739,   426.1618,   418.4707,    -4.0538,    -4.4185,\n",
      "           330.2268,   420.4538],\n",
      "        [-1618.5482,    35.4349, -3532.2070, -3543.5815,    34.9987,    36.0689,\n",
      "         -2769.2261, -3546.4133],\n",
      "        [ -179.6388,     4.9132,  -504.5576,  -492.9365,     4.7524,     5.2492,\n",
      "          -390.0194,  -495.6974],\n",
      "        [ -804.3726,    25.1209, -2617.6936, -2524.4092,    24.0416,    27.4766,\n",
      "         -2009.3423, -2544.7034],\n",
      "        [ -804.7957,    20.3311, -2067.8767, -2037.5017,    19.7998,    21.3898,\n",
      "         -1605.1749, -2045.9266],\n",
      "        [ -651.0796,    17.2394, -1764.0259, -1728.6987,    16.7156,    18.3180,\n",
      "         -1364.9346, -1737.7128]])\n",
      "fc2.weight grad: tensor([[-192675.3438,    2400.7549, -234290.5000, -236712.4219,    2368.4895,\n",
      "            2335.4268, -227681.9688, -242688.6406],\n",
      "        [-223330.3906,    2736.9287, -266321.3125, -269821.6875,    2705.6265,\n",
      "            2650.1328, -259922.4062, -276475.5938],\n",
      "        [ -93041.4531,   -9153.0938, 1007339.6875,  918450.5625,   -8326.7021,\n",
      "          -10587.1309,  694912.5000,  943623.6875],\n",
      "        [-278153.5938,    3638.1736, -357783.5312, -358865.0000,    3570.0684,\n",
      "            3582.4326, -343428.3750, -368430.2188],\n",
      "        [-136198.9375,    1673.1830, -162937.1094, -164954.2812,    1653.1454,\n",
      "            1622.1372, -158942.1719, -169062.0000],\n",
      "        [-253712.8750,    3028.3191, -293394.5312, -298479.6562,    3002.6873,\n",
      "            2912.0159, -288394.7812, -305609.9688],\n",
      "        [-205643.3594,    2565.0986, -250369.0781, -252918.7500,    2530.3420,\n",
      "            2495.9316, -243237.0938, -259310.2344],\n",
      "        [-188310.3125,    2324.7126, -226536.0781, -229196.7656,    2295.8125,\n",
      "            2256.1807, -220685.3750, -234923.9531]])\n",
      "Episode 9: Total Return: 0.079, Epsilon: 0.31\n",
      "fc2.weight grad: tensor([[ 5.9575e+02, -1.5008e+00,  2.1591e+02,  1.1982e+02, -6.7380e-01,\n",
      "         -3.0279e+00,  4.3250e+02,  1.9957e+02],\n",
      "        [ 3.5952e+02,  2.8783e+00, -6.4331e+01, -3.2974e+02,  4.8980e+00,\n",
      "         -1.3176e+00,  2.9146e+02, -1.8150e+02],\n",
      "        [-2.2929e+02,  4.1217e-01, -7.2208e+01, -2.8898e+01,  4.9081e-02,\n",
      "          1.0984e+00, -1.6434e+02, -6.2574e+01],\n",
      "        [ 2.2423e+03, -1.4383e+01,  1.3003e+03,  1.3732e+03, -1.4431e+01,\n",
      "         -1.3293e+01,  1.6133e+03,  1.4648e+03],\n",
      "        [ 1.9845e+02,  1.9577e-01,  2.5286e+01, -3.2351e+01,  6.5197e-01,\n",
      "         -7.1139e-01,  1.3393e+02,  6.2551e+00],\n",
      "        [ 8.3566e+01,  7.4843e+00, -4.0605e+02, -7.9457e+02,  1.0323e+01,\n",
      "          1.3723e+00,  6.3787e+01, -6.0361e+02],\n",
      "        [ 6.8653e+02, -1.9479e+00,  2.5974e+02,  1.6133e+02, -1.0854e+00,\n",
      "         -3.5130e+00,  4.9621e+02,  2.4728e+02],\n",
      "        [ 4.6663e+02, -2.7768e-01,  1.1290e+02, -1.6904e-02,  6.3946e-01,\n",
      "         -2.0625e+00,  3.3143e+02,  8.0316e+01]])\n",
      "fc2.weight grad: tensor([[ 1.4394e+04, -1.3143e+02,  1.1754e+04,  1.2891e+04, -1.3622e+02,\n",
      "         -1.0995e+02,  1.2484e+04,  1.3051e+04],\n",
      "        [-1.6993e+04,  1.5180e+02, -1.3491e+04, -1.4882e+04,  1.5793e+02,\n",
      "          1.2614e+02, -1.4449e+04, -1.5059e+04],\n",
      "        [ 5.8037e+05, -5.6236e+03,  5.1087e+05,  5.5232e+05, -5.7717e+03,\n",
      "         -4.7825e+03,  5.3091e+05,  5.5985e+05],\n",
      "        [-7.0069e+04,  7.3842e+02, -6.8440e+04, -7.2649e+04,  7.4817e+02,\n",
      "          6.4128e+02, -6.9139e+04, -7.3750e+04],\n",
      "        [-7.9079e+03,  4.9612e+01, -3.8928e+03, -4.8150e+03,  5.5292e+01,\n",
      "          3.6211e+01, -4.9494e+03, -4.8318e+03],\n",
      "        [-8.9571e+04,  7.7874e+02, -6.8703e+04, -7.6294e+04,  8.1380e+02,\n",
      "          6.4230e+02, -7.4379e+04, -7.7167e+04],\n",
      "        [ 8.9261e+03, -7.5727e+01,  6.6329e+03,  7.4147e+03, -7.9479e+01,\n",
      "         -6.1989e+01,  7.2528e+03,  7.4956e+03],\n",
      "        [-8.1921e+03,  6.4652e+01, -5.5345e+03, -6.3186e+03,  6.8771e+01,\n",
      "          5.1654e+01, -6.2432e+03, -6.3764e+03]])\n",
      "Episode 10: Total Return: -0.282, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 1560.6244,   -20.4007,  1819.8059,  2029.0487,   -21.3639,   -15.8249,\n",
      "          1654.9272,  1993.5956],\n",
      "        [  390.0771,    -5.1419,   473.7438,   510.3286,    -5.2604,    -4.2409,\n",
      "           436.1062,   507.9338],\n",
      "        [-2353.3848,    30.8984, -2694.0449, -3078.0662,    32.8695,    22.8992,\n",
      "         -2417.8267, -2996.1384],\n",
      "        [-2534.6316,    32.9981, -3061.3706, -3272.8347,    33.5854,    27.6113,\n",
      "         -2840.9092, -3268.5066],\n",
      "        [  774.7794,   -10.0197,   934.1552,   993.3353,   -10.1604,    -8.4680,\n",
      "           871.0728,   994.3304],\n",
      "        [-2133.3120,    28.0454, -2421.0503, -2795.7393,    30.0340,    20.3697,\n",
      "         -2160.5515, -2710.4402],\n",
      "        [ 1307.2482,   -17.1302,  1511.4159,  1705.0884,   -18.0761,   -13.0013,\n",
      "          1365.6888,  1667.7367],\n",
      "        [  843.2015,   -11.0183,  1007.5985,  1093.9872,   -11.3347,    -8.9677,\n",
      "           927.4523,  1085.8716]])\n",
      "fc2.weight grad: tensor([[ 2.4189e+03, -3.0607e+01,  2.7283e+03,  3.0458e+03, -3.2154e+01,\n",
      "         -2.3643e+01,  2.4876e+03,  2.9768e+03],\n",
      "        [-4.3591e+02,  6.3208e+00, -5.1684e+02, -6.3476e+02,  7.0398e+00,\n",
      "          3.9869e+00, -4.2107e+02, -5.9418e+02],\n",
      "        [-1.6371e+04,  2.0639e+02, -1.8469e+04, -2.0531e+04,  2.1622e+02,\n",
      "          1.6075e+02, -1.6904e+04, -2.0103e+04],\n",
      "        [-7.0993e+03,  8.3153e+01, -7.6620e+03, -8.2361e+03,  8.5154e+01,\n",
      "          6.9354e+01, -7.3218e+03, -8.2067e+03],\n",
      "        [ 5.7630e+02, -5.9974e+00,  5.6052e+02,  5.9080e+02, -6.0574e+00,\n",
      "         -5.2444e+00,  5.6277e+02,  5.9799e+02],\n",
      "        [-8.3280e+03,  1.1037e+02, -9.6950e+03, -1.1010e+04,  1.1724e+02,\n",
      "          8.2167e+01, -8.6150e+03, -1.0662e+04],\n",
      "        [ 1.6099e+03, -2.1248e+01,  1.8702e+03,  2.1190e+03, -2.2538e+01,\n",
      "         -1.5894e+01,  1.6666e+03,  2.0543e+03],\n",
      "        [-8.0639e+02,  1.1693e+01, -9.8712e+02, -1.1722e+03,  1.2770e+01,\n",
      "          7.9003e+00, -8.2561e+02, -1.1108e+03]])\n",
      "fc2.weight grad: tensor([[-8.4987e+02,  6.2552e+00, -2.0927e+03, -4.2066e+02, -7.8536e+00,\n",
      "          3.2517e+01, -2.6978e+03, -1.3641e+03],\n",
      "        [ 1.0303e+03, -1.0292e+01,  1.7099e+03,  9.1929e+02, -3.3472e+00,\n",
      "         -2.2220e+01,  1.9835e+03,  1.3939e+03],\n",
      "        [-4.1110e+02,  6.7484e+00, -1.4356e+03, -5.6871e+02, -8.3065e-01,\n",
      "          1.9664e+01, -1.5629e+03, -1.0617e+03],\n",
      "        [ 4.3673e+02, -6.5508e+00,  1.6458e+03,  5.1781e+02,  3.1406e+00,\n",
      "         -2.3942e+01,  1.8941e+03,  1.1555e+03],\n",
      "        [-2.4798e+02,  5.9116e+00,  1.7684e+02, -6.8157e+02,  1.2790e+01,\n",
      "         -8.2303e+00,  5.4823e+02, -2.3039e+02],\n",
      "        [ 8.0536e+02, -2.1300e+00,  1.3232e+03,  5.6654e+01,  8.3610e+00,\n",
      "         -2.2393e+01,  1.9645e+03,  7.7016e+02],\n",
      "        [ 2.7569e+02, -2.8335e+00,  9.1078e+02,  1.9714e+02,  3.2205e+00,\n",
      "         -1.3980e+01,  1.1219e+03,  5.9811e+02],\n",
      "        [ 6.5961e+02, -4.9373e+00,  1.2366e+03,  3.8514e+02,  2.2929e+00,\n",
      "         -1.8233e+01,  1.5773e+03,  8.7418e+02]])\n",
      "Episode 11: Total Return: 0.365, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 1.5010e+02,  1.5187e+01, -1.0782e+03, -1.5463e+03,  1.6419e+01,\n",
      "          2.2357e+00, -5.3552e+01, -1.2848e+03],\n",
      "        [-1.9867e+01, -2.2189e+00,  1.5614e+02,  2.2584e+02, -2.4173e+00,\n",
      "         -3.2568e-01,  9.5678e+00,  1.8780e+02],\n",
      "        [ 2.8524e+01,  5.1550e+00, -3.7325e+02, -5.2396e+02,  5.5200e+00,\n",
      "          9.2280e-01, -3.6479e+01, -4.3952e+02],\n",
      "        [-3.9180e+02, -4.4252e+00,  2.3485e+02,  4.6437e+02, -5.2289e+00,\n",
      "          1.6332e+00, -2.6948e+02,  3.2506e+02],\n",
      "        [-5.8001e+00, -3.1718e+00,  2.3387e+02,  3.2191e+02, -3.3639e+00,\n",
      "         -6.5688e-01,  3.2024e+01,  2.7227e+02],\n",
      "        [ 3.1830e+02, -1.1096e+01,  8.8578e+02,  1.1127e+03, -1.1443e+01,\n",
      "         -4.4463e+00,  3.8962e+02,  9.9935e+02],\n",
      "        [-1.7123e+02, -3.6678e-01, -1.1589e+01,  4.3993e+01, -6.0437e-01,\n",
      "          1.0417e+00, -1.3599e+02,  7.3519e+00],\n",
      "        [ 3.0917e+01, -3.2099e+00,  2.4174e+02,  3.2433e+02, -3.3949e+00,\n",
      "         -8.8041e-01,  6.2636e+01,  2.8038e+02]])\n",
      "fc2.weight grad: tensor([[-2.0717e+05,  4.3251e+03, -3.2943e+05, -4.3107e+05,  4.8586e+03,\n",
      "          2.2641e+03, -2.5076e+05, -4.0142e+05],\n",
      "        [-6.0818e+03,  1.2082e+02, -9.4132e+03, -1.2021e+04,  1.3398e+02,\n",
      "          6.7295e+01, -7.3930e+03, -1.1294e+04],\n",
      "        [-1.1643e+05,  2.4727e+03, -1.8831e+05, -2.4641e+05,  2.7770e+03,\n",
      "          1.2945e+03, -1.4273e+05, -2.2949e+05],\n",
      "        [-3.1770e+04,  7.2181e+02, -5.4523e+04, -7.1939e+04,  8.1349e+02,\n",
      "          3.6990e+02, -4.0373e+04, -6.6820e+04],\n",
      "        [-8.7754e+03,  1.9343e+02, -1.4483e+04, -1.9300e+04,  2.1929e+02,\n",
      "          9.6503e+01, -1.0713e+04, -1.7857e+04],\n",
      "        [-3.4449e+04,  6.5809e+02, -5.0733e+04, -6.5575e+04,  7.3531e+02,\n",
      "          3.5540e+02, -3.9886e+04, -6.1309e+04],\n",
      "        [-2.9120e+03,  9.2563e+01, -6.7268e+03, -9.2344e+03,  1.0611e+02,\n",
      "          4.2633e+01, -4.4562e+03, -8.4681e+03],\n",
      "        [-8.7489e+03,  1.7358e+02, -1.3362e+04, -1.7291e+04,  1.9394e+02,\n",
      "          9.3486e+01, -1.0394e+04, -1.6164e+04]])\n",
      "fc2.weight grad: tensor([[-1.3191e+02,  1.7793e+00, -1.5464e+02, -1.7405e+02,  1.8177e+00,\n",
      "          1.3001e+00, -1.4602e+02, -1.7358e+02],\n",
      "        [-8.1741e+02,  1.0921e+01, -9.4909e+02, -1.0686e+03,  1.1168e+01,\n",
      "          7.9905e+00, -8.9839e+02, -1.0657e+03],\n",
      "        [-2.4120e+02,  1.2310e+01, -9.9769e+02, -1.2063e+03,  1.2808e+01,\n",
      "          7.0978e+00, -7.0804e+02, -1.1642e+03],\n",
      "        [ 1.3510e+03, -1.7146e+01,  1.4932e+03,  1.6782e+03, -1.7569e+01,\n",
      "         -1.2726e+01,  1.4369e+03,  1.6774e+03],\n",
      "        [-8.1489e+02,  1.0619e+01, -9.2470e+02, -1.0388e+03,  1.0856e+01,\n",
      "          7.8443e+00, -8.8319e+02, -1.0381e+03],\n",
      "        [ 2.3480e+02, -3.9313e+00,  3.3989e+02,  3.8364e+02, -3.9729e+00,\n",
      "         -2.7404e+00,  3.0217e+02,  3.8040e+02],\n",
      "        [-6.7280e+02,  9.1385e+00, -7.9452e+02, -8.9364e+02,  9.3259e+00,\n",
      "          6.6762e+00, -7.4908e+02, -8.9153e+02],\n",
      "        [-9.1718e+02,  1.2071e+01, -1.0499e+03, -1.1811e+03,  1.2347e+01,\n",
      "          8.8736e+00, -9.9877e+02, -1.1789e+03]])\n",
      "Episode 12: Total Return: 0.382, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-8.5557e+02,  9.3475e+00, -8.4535e+02, -8.9854e+02,  9.1321e+00,\n",
      "          7.8086e+00, -8.6856e+02, -9.3973e+02],\n",
      "        [ 1.9125e+01, -2.0462e-01,  1.7929e+01,  1.9899e+01, -2.0861e-01,\n",
      "         -1.6100e-01,  1.8494e+01,  2.0359e+01],\n",
      "        [-1.9299e+02,  2.1622e+00, -1.9629e+02, -2.0742e+02,  2.0940e+00,\n",
      "          1.8077e+00, -1.9989e+02, -2.1741e+02],\n",
      "        [ 4.5660e+02, -5.2545e+00,  4.7853e+02,  5.0314e+02, -5.0480e+00,\n",
      "         -4.3895e+00,  4.8278e+02,  5.2828e+02],\n",
      "        [ 8.5903e+01, -8.7680e-01,  7.8768e+01,  8.4645e+01, -8.7297e-01,\n",
      "         -7.3714e-01,  8.3026e+01,  8.8240e+01],\n",
      "        [ 4.1059e+02, -4.1756e+00,  3.7389e+02,  4.0361e+02, -4.1769e+00,\n",
      "         -3.4910e+00,  3.9454e+02,  4.1980e+02],\n",
      "        [ 7.5338e+01, -8.8682e-01,  8.1120e+01,  8.4731e+01, -8.4421e-01,\n",
      "         -7.4314e-01,  8.1235e+01,  8.9212e+01],\n",
      "        [ 1.0789e+02, -1.1284e+00,  1.0106e+02,  1.0897e+02, -1.1235e+00,\n",
      "         -9.3588e-01,  1.0547e+02,  1.1329e+02]])\n",
      "fc2.weight grad: tensor([[-9.2443e+01, -7.4861e+00,  4.2839e+02,  7.5539e+02, -9.1928e+00,\n",
      "         -6.1276e-01,  1.1896e+02,  6.3770e+02],\n",
      "        [-4.6290e+01, -2.5219e+00,  1.4469e+02,  2.5305e+02, -3.0557e+00,\n",
      "         -1.6605e-01,  3.6044e+01,  2.1393e+02],\n",
      "        [-5.0027e+02, -2.4332e+01,  1.3869e+03,  2.4408e+03, -2.9495e+01,\n",
      "         -1.3277e+00,  3.1883e+02,  2.0584e+03],\n",
      "        [-5.2323e+02, -8.1490e+00,  4.5238e+02,  7.9278e+02, -9.2325e+00,\n",
      "          7.6855e-01, -1.7459e+01,  6.6327e+02],\n",
      "        [-5.5877e+02, -2.5413e+01,  1.4451e+03,  2.5477e+03, -3.0774e+01,\n",
      "         -1.2347e+00,  3.1718e+02,  2.1466e+03],\n",
      "        [ 2.6971e+02, -1.0026e+01,  5.9267e+02,  1.0366e+03, -1.2940e+01,\n",
      "         -2.2333e+00,  3.0463e+02,  8.8425e+02],\n",
      "        [-7.1136e+02, -2.5295e+01,  1.4340e+03,  2.5247e+03, -3.0336e+01,\n",
      "         -7.1071e-01,  2.6273e+02,  2.1255e+03],\n",
      "        [-4.0248e+02, -2.1626e+01,  1.2408e+03,  2.1694e+03, -2.6189e+01,\n",
      "         -1.4086e+00,  3.0756e+02,  1.8342e+03]])\n",
      "Episode 13: Total Return: 0.029, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-2.4446e+01,  6.3740e-01, -5.6330e+01, -5.7727e+01,  5.5037e-01,\n",
      "          4.0382e-01, -4.9414e+01, -5.9072e+01],\n",
      "        [ 2.0775e+02, -3.6954e+00,  3.1930e+02,  3.4605e+02, -3.4655e+00,\n",
      "         -2.4057e+00,  2.9294e+02,  3.4984e+02],\n",
      "        [-1.2129e+01,  2.0891e-01, -1.8180e+01, -1.9533e+01,  1.9474e-01,\n",
      "          1.3871e-01, -1.6852e+01, -1.9828e+01],\n",
      "        [ 3.9489e+01, -1.3995e+00,  1.2660e+02,  1.2354e+02, -1.1274e+00,\n",
      "         -8.9128e-01,  1.0911e+02,  1.2817e+02],\n",
      "        [-3.6827e+01,  6.1877e-01, -5.3027e+01, -5.8417e+01,  5.9223e-01,\n",
      "          4.0189e-01, -4.8934e+01, -5.8798e+01],\n",
      "        [-1.6485e+02,  4.0388e+00, -3.5790e+02, -3.6632e+02,  3.4951e+00,\n",
      "          2.5968e+00, -3.1715e+02, -3.7550e+02],\n",
      "        [-2.7575e+01,  1.9921e-02,  2.0817e+00, -6.9254e+00,  1.4313e-01,\n",
      "          2.6687e-02, -2.8520e+00, -4.7994e+00],\n",
      "        [-6.4405e+01,  1.3302e+00, -1.1662e+02, -1.2247e+02,  1.1956e+00,\n",
      "          8.6313e-01, -1.0523e+02, -1.2479e+02]])\n",
      "fc2.weight grad: tensor([[-8.8619e+00,  1.8904e-01, -1.3458e+01, -1.8959e+01,  2.1633e-01,\n",
      "          7.5278e-02, -1.0316e+01, -1.7368e+01],\n",
      "        [-2.0152e+02,  2.9469e+00, -2.3636e+02, -2.9058e+02,  3.1468e+00,\n",
      "          1.7566e+00, -2.1429e+02, -2.8232e+02],\n",
      "        [ 9.9008e+01, -1.4462e+00,  1.1601e+02,  1.4261e+02, -1.5443e+00,\n",
      "         -8.6273e-01,  1.0522e+02,  1.3856e+02],\n",
      "        [ 2.1317e+01, -4.6030e-01,  3.1306e+01,  4.6909e+01, -5.4900e-01,\n",
      "         -1.6258e-01,  2.2992e+01,  4.2161e+01],\n",
      "        [ 1.3651e+02, -1.9763e+00,  1.5865e+02,  1.9500e+02, -2.1124e+00,\n",
      "         -1.1847e+00,  1.4425e+02,  1.8955e+02],\n",
      "        [ 2.7684e+02, -3.7777e+00,  3.1279e+02,  3.6996e+02, -3.9360e+00,\n",
      "         -2.4497e+00,  2.9318e+02,  3.6540e+02],\n",
      "        [ 9.0967e+01, -1.4377e+00,  1.1122e+02,  1.4288e+02, -1.5773e+00,\n",
      "         -7.7566e-01,  9.6914e+01,  1.3633e+02],\n",
      "        [ 1.1947e+02, -1.7130e+00,  1.3875e+02,  1.6853e+02, -1.8150e+00,\n",
      "         -1.0476e+00,  1.2706e+02,  1.6455e+02]])\n",
      "fc2.weight grad: tensor([[-2.5234e+02,  4.5301e+00, -3.5061e+02, -4.4743e+02,  4.9136e+00,\n",
      "          2.4481e+00, -3.0028e+02, -4.2927e+02],\n",
      "        [ 1.9588e+03, -3.4856e+01,  2.8454e+03,  3.3815e+03, -3.5864e+01,\n",
      "         -2.1177e+01,  2.5293e+03,  3.3196e+03],\n",
      "        [-8.4316e+02,  1.4980e+01, -1.2281e+03, -1.4511e+03,  1.5344e+01,\n",
      "          9.1866e+00, -1.0951e+03, -1.4273e+03],\n",
      "        [-7.0430e+02,  1.2168e+01, -1.0324e+03, -1.1657e+03,  1.2036e+01,\n",
      "          8.0500e+00, -9.4616e+02, -1.1650e+03],\n",
      "        [-9.0427e+02,  1.5991e+01, -1.3096e+03, -1.5500e+03,  1.6406e+01,\n",
      "          9.7952e+00, -1.1684e+03, -1.5239e+03],\n",
      "        [-1.9367e+03,  3.5059e+01, -2.8020e+03, -3.4236e+03,  3.6810e+01,\n",
      "          2.0288e+01, -2.4466e+03, -3.3293e+03],\n",
      "        [-2.9161e+02,  4.9742e+00, -4.3361e+02, -4.7194e+02,  4.7723e+00,\n",
      "          3.4797e+00, -4.0470e+02, -4.7778e+02],\n",
      "        [-7.7545e+02,  1.3886e+01, -1.1255e+03, -1.3501e+03,  1.4385e+01,\n",
      "          8.3001e+00, -9.9445e+02, -1.3211e+03]])\n",
      "Episode 14: Total Return: -0.097, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 1.2504e+03, -3.1898e+00,  4.1571e+02,  3.7226e+02, -3.7168e+00,\n",
      "         -6.4371e+00,  6.6958e+02,  4.4605e+02],\n",
      "        [-6.9721e+03, -1.0559e+03,  6.7902e+04,  1.0188e+05, -1.1645e+03,\n",
      "         -2.2316e+02,  4.0441e+04,  9.0566e+04],\n",
      "        [-5.0804e+02,  3.3360e+02, -2.1851e+04, -3.2358e+04,  3.6920e+02,\n",
      "          8.2291e+01, -1.3872e+04, -2.8991e+04],\n",
      "        [-7.7638e+02,  4.6819e+02, -3.0675e+04, -4.5417e+04,  5.1820e+02,\n",
      "          1.1576e+02, -1.9492e+04, -4.0697e+04],\n",
      "        [-8.2734e+02,  3.5702e+02, -2.3417e+04, -3.4653e+04,  3.9543e+02,\n",
      "          8.9201e+01, -1.4946e+04, -3.1068e+04],\n",
      "        [ 1.9626e+04,  1.8446e+02, -9.1759e+03, -1.6623e+04,  1.9414e+02,\n",
      "         -4.0832e+01,  3.3745e+02, -1.3241e+04],\n",
      "        [-5.4913e+03,  3.2184e+02, -2.1814e+04, -3.1535e+04,  3.5866e+02,\n",
      "          1.0110e+02, -1.5398e+04, -2.8670e+04],\n",
      "        [ 2.9332e+03,  2.3356e+02, -1.4815e+04, -2.2446e+04,  2.5688e+02,\n",
      "          4.3321e+01, -8.3847e+03, -1.9837e+04]])\n",
      "fc2.weight grad: tensor([[ 3.6993e+03, -7.2139e+01,  5.2830e+03,  7.1338e+03, -8.0548e+01,\n",
      "         -7.0145e+01,  4.5767e+03,  6.7464e+03],\n",
      "        [ 1.7186e+02, -2.9899e+00,  2.2045e+02,  2.9651e+02, -3.3375e+00,\n",
      "         -4.4428e+00,  1.9754e+02,  2.8219e+02],\n",
      "        [ 2.8452e+03, -5.4618e+01,  4.0036e+03,  5.4032e+03, -6.0982e+01,\n",
      "         -5.6802e+01,  3.4841e+03,  5.1141e+03],\n",
      "        [ 1.2077e+04, -2.3351e+02,  1.7107e+04,  2.3098e+04, -2.6075e+02,\n",
      "         -2.3525e+02,  1.4855e+04,  2.1853e+04],\n",
      "        [ 4.6271e+03, -8.9383e+01,  6.5477e+03,  8.8417e+03, -9.9817e+01,\n",
      "         -9.0292e+01,  5.6869e+03,  8.3654e+03],\n",
      "        [ 1.1372e+04, -2.3053e+02,  1.6829e+04,  2.2783e+04, -2.5761e+02,\n",
      "         -1.8440e+02,  1.4410e+04,  2.1499e+04],\n",
      "        [-1.0905e+03,  2.1741e+01, -1.5902e+03, -2.1488e+03,  2.4276e+01,\n",
      "          1.9121e+01, -1.3690e+03, -2.0298e+03],\n",
      "        [-2.2994e+02,  4.3800e+00, -3.2243e+02, -4.3293e+02,  4.8771e+00,\n",
      "          4.8728e+00, -2.8183e+02, -4.1019e+02]])\n",
      "fc2.weight grad: tensor([[-1.9036e+03,  5.8766e+01, -2.7817e+03, -6.6627e+03,  7.9717e+01,\n",
      "          2.4218e-01, -3.4769e+03, -4.6886e+03],\n",
      "        [ 1.1414e+03, -3.5219e+01,  1.6636e+03,  3.9958e+03, -4.7823e+01,\n",
      "          1.2540e-02,  2.0789e+03,  2.8153e+03],\n",
      "        [-2.0431e+03,  6.3376e+01, -3.0096e+03, -7.1759e+03,  8.5815e+01,\n",
      "          4.4670e-01, -3.7639e+03, -5.0313e+03],\n",
      "        [ 3.7089e+03, -1.1424e+02,  5.5823e+03,  1.2821e+04, -1.5267e+02,\n",
      "         -9.4827e+00,  6.9956e+03,  8.8922e+03],\n",
      "        [ 6.4048e+00, -2.5508e-01,  4.6031e+01,  2.7329e+00,  1.0994e-01,\n",
      "         -1.6468e+00,  6.1431e+01, -2.7126e+01],\n",
      "        [ 4.1444e+03, -1.2826e+02,  6.0063e+03,  1.4589e+04, -1.7482e+02,\n",
      "          3.0390e+00,  7.5014e+03,  1.0307e+04],\n",
      "        [-3.4376e+03,  1.0588e+02, -5.1573e+03, -1.1895e+04,  1.4172e+02,\n",
      "          7.9723e+00, -6.4612e+03, -8.2633e+03],\n",
      "        [-1.3708e+03,  4.2425e+01, -1.9832e+03, -4.8283e+03,  5.7874e+01,\n",
      "         -1.1854e+00, -2.4765e+03, -3.4139e+03]])\n",
      "Episode 15: Total Return: 0.164, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 1.8920e+01,  3.9458e+02, -1.2125e+04, -4.4868e+04,  5.6442e+02,\n",
      "          6.7179e+02, -1.0867e+04, -3.0040e+04],\n",
      "        [-2.0854e+01, -4.4523e+02,  1.3838e+04,  5.0167e+04, -6.2962e+02,\n",
      "         -6.1867e+02,  1.2209e+04,  3.3519e+04],\n",
      "        [ 1.3070e+02,  2.1658e+03, -6.6742e+04, -2.4437e+05,  3.0698e+03,\n",
      "          2.9365e+03, -5.8848e+04, -1.6339e+05],\n",
      "        [-8.4371e+01, -1.6852e+03,  5.2056e+04,  1.9062e+05, -2.3949e+03,\n",
      "         -2.5344e+03,  4.6201e+04,  1.2748e+05],\n",
      "        [ 2.2837e+02,  4.7448e+03, -1.4647e+05, -5.3743e+05,  6.7542e+03,\n",
      "          7.4220e+03, -1.3037e+05, -3.5951e+05],\n",
      "        [-2.6488e+01, -1.0174e+03,  3.1555e+04,  1.1589e+05, -1.4570e+03,\n",
      "         -1.9274e+03,  2.8493e+04,  7.7571e+04],\n",
      "        [-2.4506e+01, -9.1485e+01,  2.7633e+03,  9.5603e+03, -1.1888e+02,\n",
      "          2.2624e+02,  2.0008e+03,  6.3176e+03],\n",
      "        [ 1.0872e+03,  2.1037e+04, -6.4872e+05, -2.3812e+06,  2.9925e+04,\n",
      "          3.1965e+04, -5.7628e+05, -1.5928e+06]])\n",
      "fc2.weight grad: tensor([[-5.2435e+01, -8.7387e+01,  6.5028e+02,  1.0893e+04, -1.4828e+02,\n",
      "          1.2016e+01,  5.5486e+02,  7.1360e+03],\n",
      "        [ 4.0288e+01,  6.7734e+01, -5.2401e+02, -8.4354e+03,  1.1485e+02,\n",
      "         -1.0498e+01, -4.4222e+02, -5.4717e+03],\n",
      "        [-1.4911e+02, -2.5325e+02,  2.0448e+03,  3.1504e+04, -4.2907e+02,\n",
      "          4.4327e+01,  1.7054e+03,  2.0203e+04],\n",
      "        [ 1.8050e+02,  3.0561e+02, -2.4359e+03, -3.8031e+04,  5.1791e+02,\n",
      "         -5.1612e+01, -2.0388e+03, -2.4475e+04],\n",
      "        [-3.5970e+02, -6.0770e+02,  4.8003e+03,  7.5642e+04, -1.0300e+03,\n",
      "          1.0006e+02,  4.0277e+03,  4.8797e+04],\n",
      "        [ 8.9991e+01,  1.5013e+02, -1.1225e+03, -1.8713e+04,  2.5472e+02,\n",
      "         -2.0958e+01, -9.5650e+02, -1.2244e+04],\n",
      "        [ 1.0620e+01,  1.9917e+01, -2.2310e+02, -2.4529e+03,  3.3498e+01,\n",
      "         -7.1793e+00, -1.7199e+02, -1.4036e+03],\n",
      "        [-2.0067e+03, -3.3945e+03,  2.6958e+04,  4.2247e+05, -5.7531e+03,\n",
      "          5.6742e+02,  2.2586e+04,  2.7215e+05]])\n",
      "Episode 16: Total Return: -0.188, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 7.6128e+03,  2.7869e+03,  6.3721e+04, -4.4956e+05,  6.4925e+03,\n",
      "          1.2637e+02,  7.7409e+04, -3.2536e+05],\n",
      "        [ 2.2990e+02,  8.7627e+01,  1.9461e+03, -1.3770e+04,  2.0055e+02,\n",
      "         -9.9857e+00,  2.4376e+03, -9.0841e+03],\n",
      "        [-2.1483e+02, -8.6043e+01, -1.9010e+03,  1.3026e+04, -1.9262e+02,\n",
      "          3.2227e+01, -2.4789e+03,  7.2252e+03],\n",
      "        [ 4.5211e+02,  1.7831e+02,  3.7917e+03, -2.7513e+04,  4.0239e+02,\n",
      "         -3.5196e+01,  4.8609e+03, -1.7072e+04],\n",
      "        [-2.4046e+02, -9.8746e+01, -2.0167e+03,  1.4885e+04, -2.1916e+02,\n",
      "          3.1489e+01, -2.6625e+03,  8.4089e+03],\n",
      "        [ 2.4960e+02,  8.8009e+01,  2.0235e+03, -1.4611e+04,  2.0866e+02,\n",
      "          2.2556e+01,  2.3768e+03, -1.1683e+04],\n",
      "        [ 1.7723e+02,  7.1463e+01,  1.5459e+03, -1.0807e+04,  1.5960e+02,\n",
      "         -2.5631e+01,  2.0222e+03, -6.0270e+03],\n",
      "        [-1.4097e+04, -5.0746e+03, -1.1805e+05,  8.2688e+05, -1.1909e+04,\n",
      "         -5.0966e+02, -1.4172e+05,  6.1697e+05]])\n",
      "fc2.weight grad: tensor([[-8.1406e+01, -7.8208e+01,  1.5258e+03,  9.9218e+03, -1.3558e+02,\n",
      "         -3.9360e+01,  1.9180e+03,  5.4804e+03],\n",
      "        [ 3.8940e+01,  3.7060e+01, -7.0116e+02, -4.7039e+03,  6.4396e+01,\n",
      "          1.8417e+01, -8.7689e+02, -2.5982e+03],\n",
      "        [-2.5758e+01, -2.5965e+01,  5.8730e+02,  3.2866e+03, -4.4489e+01,\n",
      "         -1.3883e+01,  7.5491e+02,  1.8139e+03],\n",
      "        [ 6.0676e+01,  6.3507e+01, -1.4605e+03, -8.0080e+03,  1.0805e+02,\n",
      "          3.5509e+01, -1.8780e+03, -4.4670e+03],\n",
      "        [-1.9449e+01, -2.0577e+01,  5.0213e+02,  2.5956e+03, -3.4899e+01,\n",
      "         -1.1633e+01,  6.5124e+02,  1.4413e+03],\n",
      "        [ 6.2551e+01,  5.2550e+01, -7.0980e+02, -6.7377e+03,  9.4046e+01,\n",
      "          2.1311e+01, -8.3247e+02, -3.6564e+03],\n",
      "        [ 2.3288e+01,  2.2101e+01, -4.3072e+02, -2.8078e+03,  3.8402e+01,\n",
      "          1.0932e+01, -5.4184e+02, -1.5441e+03],\n",
      "        [-1.9987e+01, -1.3943e+01,  1.1207e+02,  1.8263e+03, -2.6128e+01,\n",
      "         -3.4066e+00,  1.1333e+02,  9.3905e+02]])\n",
      "fc2.weight grad: tensor([[ 2.1872e+04,  8.7409e+03,  7.1647e+04, -8.7913e+05,  1.1544e+04,\n",
      "         -7.3377e+02,  1.2010e+05, -2.5202e+05],\n",
      "        [-3.9130e+03, -1.3244e+03, -2.0958e+04,  1.3507e+05, -1.8469e+03,\n",
      "          4.4960e+02, -3.8054e+04,  3.0503e+04],\n",
      "        [ 2.4046e+05,  8.4786e+04,  1.2078e+06, -8.6551e+06,  1.1780e+05,\n",
      "         -2.3834e+04,  2.2451e+06, -2.1867e+06],\n",
      "        [-7.0634e+03, -2.4415e+03, -3.6998e+04,  2.4952e+05, -3.4104e+03,\n",
      "          7.6233e+02, -6.8742e+04,  6.0793e+04],\n",
      "        [ 1.2888e+05,  4.7953e+04,  5.7500e+05, -4.8863e+06,  6.5863e+04,\n",
      "         -9.7026e+03,  1.0816e+06, -1.3635e+06],\n",
      "        [-4.9448e+03, -2.0214e+03, -1.2284e+04,  2.0031e+05, -2.5709e+03,\n",
      "          5.7069e+01, -1.4532e+04,  5.2713e+04],\n",
      "        [-2.0732e+03, -7.6194e+02, -8.5311e+03,  7.6566e+04, -1.0157e+03,\n",
      "          1.4738e+02, -1.3894e+04,  1.8274e+04],\n",
      "        [ 3.3758e+04,  2.6001e+04, -3.5141e+05, -2.4771e+06,  2.7991e+04,\n",
      "          1.6253e+04, -8.2648e+05, -1.0433e+06]])\n",
      "Episode 17: Total Return: -0.211, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.7484e+04, -9.1536e+04,  1.0746e+06,  1.0570e+07, -1.3131e+05,\n",
      "         -8.1255e+04,  3.6015e+06,  7.2074e+06],\n",
      "        [ 2.7286e+03,  1.4480e+04, -1.6895e+05, -1.6743e+06,  2.0808e+04,\n",
      "          1.2845e+04, -5.7207e+05, -1.1360e+06],\n",
      "        [-1.6184e+05, -8.5494e+05,  9.9961e+06,  9.8813e+07, -1.2279e+06,\n",
      "         -7.5858e+05,  3.3731e+07,  6.7156e+07],\n",
      "        [ 4.7092e+03,  2.4889e+04, -2.9094e+05, -2.8768e+06,  3.5748e+04,\n",
      "          2.2083e+04, -9.8212e+05, -1.9548e+06],\n",
      "        [-7.8646e+04, -4.1201e+05,  4.8353e+06,  4.7582e+07, -5.9111e+05,\n",
      "         -3.6573e+05,  1.6214e+07,  3.2436e+07],\n",
      "        [ 3.9678e+03,  2.0489e+04, -2.4203e+05, -2.3629e+06,  2.9340e+04,\n",
      "          1.8201e+04, -8.0271e+05, -1.6193e+06],\n",
      "        [ 1.6698e+03,  8.7063e+03, -1.0240e+05, -1.0050e+06,  1.2483e+04,\n",
      "          7.7301e+03, -3.4212e+05, -6.8627e+05],\n",
      "        [-6.0783e+04, -3.0960e+05,  3.6801e+06,  3.5656e+07, -4.4255e+05,\n",
      "         -2.7522e+05,  1.2077e+07,  2.4559e+07]])\n",
      "fc2.weight grad: tensor([[-1.4257e+03,  2.6723e+01,  6.6672e+03,  5.1968e+04, -1.0589e+03,\n",
      "          5.6960e+04,  4.8318e+04, -2.3692e+04],\n",
      "        [ 2.0344e+02, -8.7982e+00, -1.0016e+03, -7.1530e+03,  1.4948e+02,\n",
      "         -8.7514e+03, -7.4647e+03,  3.8078e+03],\n",
      "        [-1.2327e+04, -3.3522e+02,  6.2736e+04,  5.1127e+05, -9.8867e+03,\n",
      "          4.9868e+05,  4.3914e+05, -1.5265e+05],\n",
      "        [ 3.6142e+02, -7.8083e+00, -1.6550e+03, -1.2984e+04,  2.6580e+02,\n",
      "         -1.4244e+04, -1.2003e+04,  6.1101e+03],\n",
      "        [-3.4993e+03,  1.7052e+03,  3.0039e+04,  2.0108e+03, -1.3139e+03,\n",
      "         -2.2922e+04,  2.1029e+05, -3.2197e+05],\n",
      "        [ 2.5787e+02, -8.4558e+01, -5.3450e+02, -8.1334e+02,  9.0925e+01,\n",
      "         -9.7527e+03, -6.0903e+03,  1.1619e+04],\n",
      "        [ 1.1284e+02, -2.2493e+01, -3.8448e+02, -2.0029e+03,  5.9534e+01,\n",
      "         -4.5703e+03, -3.3736e+03,  3.7401e+03],\n",
      "        [-4.6255e+03,  5.3262e+02,  1.6940e+04,  1.1779e+05, -2.8255e+03,\n",
      "          1.7505e+05,  1.3448e+05, -1.1820e+05]])\n",
      "Episode 18: Total Return: -0.097, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-3.8361e+03, -4.5426e+03,  9.8264e+03,  5.5845e+05, -7.4645e+03,\n",
      "          6.2741e+04,  7.6835e+04,  3.4361e+05],\n",
      "        [ 4.8652e+02,  5.7995e+02, -1.2404e+03, -7.1267e+04,  9.5422e+02,\n",
      "         -8.5182e+03, -9.7799e+03, -4.4351e+04],\n",
      "        [-2.5998e+04, -3.0941e+04,  6.6920e+04,  3.8025e+06, -5.0844e+04,\n",
      "          4.3600e+05,  5.2510e+05,  2.3502e+06],\n",
      "        [ 9.3010e+02,  1.1014e+03, -2.3880e+03, -1.3540e+05,  1.8094e+03,\n",
      "         -1.5098e+04, -1.8659e+04, -8.3220e+04],\n",
      "        [-9.5763e+03, -1.1361e+04,  2.4575e+04,  1.3965e+06, -1.8668e+04,\n",
      "          1.5804e+05,  1.9240e+05,  8.6064e+05],\n",
      "        [ 8.2200e+02,  9.4998e+02, -2.0492e+03, -1.1697e+05,  1.5615e+03,\n",
      "         -1.1972e+04, -1.5766e+04, -7.0505e+04],\n",
      "        [ 3.0009e+02,  3.5067e+02, -7.5094e+02, -4.3148e+04,  5.7688e+02,\n",
      "         -4.7516e+03, -5.8370e+03, -2.6368e+04],\n",
      "        [-7.3776e+03, -8.6236e+03,  1.8979e+04,  1.0596e+06, -1.4115e+04,\n",
      "          9.5706e+04,  1.4601e+05,  6.3588e+05]])\n",
      "fc2.weight grad: tensor([[-1.3563e+04, -1.9255e+04,  1.3892e+05,  2.2542e+06, -2.8153e+04,\n",
      "          1.6347e+05,  4.1100e+05,  1.5320e+06],\n",
      "        [ 1.6355e+03,  2.3075e+03, -1.6473e+04, -2.7012e+05,  3.3714e+03,\n",
      "         -1.9258e+04, -4.8990e+04, -1.8303e+05],\n",
      "        [-7.1373e+04, -1.0095e+05,  7.2362e+05,  1.1818e+07, -1.4755e+05,\n",
      "          8.4932e+05,  2.1474e+06,  8.0189e+06],\n",
      "        [ 2.7521e+03,  3.9104e+03, -2.8250e+04, -4.5778e+05,  5.7178e+03,\n",
      "         -3.3271e+04, -8.3522e+04, -3.1123e+05],\n",
      "        [-1.3809e+04, -1.9533e+04,  1.4002e+05,  2.2866e+06, -2.8549e+04,\n",
      "          1.6435e+05,  4.1550e+05,  1.5516e+06],\n",
      "        [ 2.2159e+03,  3.2034e+03, -2.3829e+04, -3.7504e+05,  4.6905e+03,\n",
      "         -2.8319e+04, -6.9517e+04, -2.5675e+05],\n",
      "        [ 8.6315e+02,  1.2361e+03, -9.0530e+03, -1.4470e+05,  1.8082e+03,\n",
      "         -1.0678e+04, -2.6606e+04, -9.8652e+04],\n",
      "        [-8.7674e+03, -1.2866e+04,  9.8002e+04,  1.5065e+06, -1.8868e+04,\n",
      "          1.1789e+05,  2.8271e+05,  1.0381e+06]])\n",
      "fc2.weight grad: tensor([[ 9.8792e+03,  1.1185e+04,  5.9998e+03, -1.2283e+06,  1.5093e+04,\n",
      "          4.2258e+04, -3.0419e+04, -6.5072e+05],\n",
      "        [-1.9943e+03, -2.2358e+03, -1.2001e+03,  2.4383e+05, -2.9792e+03,\n",
      "         -9.8792e+03,  6.2522e+03,  1.2761e+05],\n",
      "        [ 6.9775e+04,  7.9048e+04,  4.2404e+04, -8.6851e+06,  1.0676e+05,\n",
      "          2.9514e+05, -2.1447e+05, -4.6049e+06],\n",
      "        [-3.1242e+03, -3.5139e+03, -1.8865e+03,  3.8415e+05, -4.7033e+03,\n",
      "         -1.4735e+04,  9.7059e+03,  2.0191e+05],\n",
      "        [ 2.3432e+02,  2.7005e+02,  1.4458e+02, -3.0015e+04,  3.7235e+02,\n",
      "          7.1938e+02, -7.0217e+02, -1.6231e+04],\n",
      "        [-2.7243e+03, -3.1149e+03, -1.6683e+03,  3.4432e+05, -4.2526e+03,\n",
      "         -9.8936e+03,  8.2987e+03,  1.8448e+05],\n",
      "        [-1.2569e+03, -1.4267e+03, -7.6478e+02,  1.5693e+05, -1.9307e+03,\n",
      "         -5.1819e+03,  3.8691e+03,  8.3371e+04],\n",
      "        [ 3.6421e+02,  4.1671e+02,  2.2350e+02, -4.6107e+04,  5.7006e+02,\n",
      "          1.2828e+03, -1.0945e+03, -2.4743e+04]])\n",
      "Episode 19: Total Return: 0.203, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-8.2772e+03, -6.8902e+03, -1.5168e+03,  3.6507e+05, -4.3271e+03,\n",
      "         -6.1511e+03, -5.2673e+03,  1.3252e+05],\n",
      "        [ 2.6783e+03,  2.2059e+03,  4.8897e+02, -1.1636e+05,  1.3779e+03,\n",
      "          1.9439e+03,  1.7155e+03, -4.1644e+04],\n",
      "        [-5.7536e+04, -4.8055e+04, -1.0551e+04,  2.5496e+06, -3.0221e+04,\n",
      "         -4.3072e+04, -3.6524e+04,  9.2988e+05],\n",
      "        [ 3.7991e+03,  3.1403e+03,  6.9303e+02, -1.6591e+05,  1.9633e+03,\n",
      "          2.7798e+03,  2.4240e+03, -5.9765e+04],\n",
      "        [ 3.7587e+01,  1.2945e+01,  4.0552e+00, -2.9283e+02,  5.7380e-01,\n",
      "         -7.9655e+00,  2.8578e+01,  2.5686e+02],\n",
      "        [ 2.9447e+03,  2.4786e+03,  5.4455e+02, -1.3191e+05,  1.5688e+03,\n",
      "          2.2418e+03,  1.8689e+03, -4.8375e+04],\n",
      "        [ 1.5857e+03,  1.3201e+03,  2.9130e+02, -6.9940e+04,  8.2993e+02,\n",
      "          1.1784e+03,  1.0111e+03, -2.5339e+04],\n",
      "        [-2.1459e+04, -1.7795e+04, -3.9282e+03,  9.4136e+05, -1.1155e+04,\n",
      "         -1.5813e+04, -1.3690e+04,  3.3992e+05]])\n",
      "fc2.weight grad: tensor([[ 1.9195e+03,  2.5368e+03,  1.0540e+03, -1.2372e+05,  1.6729e+03,\n",
      "          2.7829e+03,  8.7015e+02, -1.7316e+03],\n",
      "        [-7.4670e+02, -9.8734e+02, -4.0998e+02,  4.8151e+04, -6.5105e+02,\n",
      "         -1.0834e+03, -3.3852e+02,  6.7285e+02],\n",
      "        [ 7.2037e+03,  9.5219e+03,  3.9555e+03, -4.6438e+05,  6.2792e+03,\n",
      "          1.0447e+04,  3.2657e+03, -6.4965e+03],\n",
      "        [-1.0311e+03, -1.3637e+03, -5.6619e+02,  6.6505e+04, -8.9918e+02,\n",
      "         -1.4965e+03, -4.6751e+02,  9.2971e+02],\n",
      "        [-3.5231e+00, -5.2912e+00, -1.8783e+00,  2.5563e+02, -3.3929e+00,\n",
      "         -6.0390e+00, -1.6265e+00,  2.0652e+00],\n",
      "        [-8.6157e+02, -1.1370e+03, -4.7316e+02,  5.5453e+04, -7.5000e+02,\n",
      "         -1.2464e+03, -3.9045e+02,  7.7865e+02],\n",
      "        [-4.5316e+02, -5.9876e+02, -2.4884e+02,  2.9202e+04, -3.9488e+02,\n",
      "         -6.5679e+02, -2.0542e+02,  4.0892e+02],\n",
      "        [ 2.1308e+02,  1.4130e+02,  1.3021e+02, -5.7716e+03,  1.0705e+02,\n",
      "          8.8616e+01,  1.6460e+02,  3.8695e+01]])\n",
      "fc2.weight grad: tensor([[-1.6345e+03, -1.2577e+03, -1.1392e+03,  5.2630e+04, -1.4319e+02,\n",
      "         -3.6505e+02, -3.6294e+03,  3.4194e+03],\n",
      "        [ 7.1847e+02,  5.5075e+02,  5.0667e+02, -2.3062e+04,  6.2962e+01,\n",
      "          1.5785e+02,  1.6323e+03, -1.4521e+03],\n",
      "        [-8.6259e+03, -6.6337e+03, -6.0176e+03,  2.7761e+05, -7.5570e+02,\n",
      "         -1.9235e+03, -1.9192e+04,  1.7978e+04],\n",
      "        [ 9.2638e+02,  7.1383e+02,  6.5721e+02, -2.9916e+04,  8.1168e+01,\n",
      "          2.0346e+02,  2.1153e+03, -1.9042e+03],\n",
      "        [ 1.1459e+02,  8.8666e+01,  7.4029e+01, -3.6909e+03,  1.0027e+01,\n",
      "          2.7666e+01,  2.2217e+02, -2.6991e+02],\n",
      "        [ 8.2634e+02,  6.3675e+02,  5.5684e+02, -2.6580e+04,  7.2358e+01,\n",
      "          1.9111e+02,  1.7311e+03, -1.8185e+03],\n",
      "        [ 4.8212e+02,  3.7094e+02,  3.3424e+02, -1.5516e+04,  4.2233e+01,\n",
      "          1.0825e+02,  1.0611e+03, -1.0156e+03],\n",
      "        [-1.3979e+02, -1.0762e+02, -9.7305e+01,  4.5034e+03, -1.2246e+01,\n",
      "         -3.1281e+01, -3.0956e+02,  2.9374e+02]])\n",
      "Episode 20: Total Return: 0.101, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-9.2771e+02, -1.2835e+03, -4.6139e+02,  7.4187e+04, -5.9089e+02,\n",
      "         -1.2044e+03,  2.7694e+04,  6.2525e+04],\n",
      "        [ 3.0315e+02,  4.1526e+02,  1.5062e+02, -2.4020e+04,  1.9183e+02,\n",
      "          3.8615e+02, -9.0344e+03, -1.9876e+04],\n",
      "        [-1.9035e+03, -2.6240e+03, -9.4639e+02,  1.5171e+05, -1.2096e+03,\n",
      "         -2.4542e+03,  5.6786e+04,  1.2701e+05],\n",
      "        [ 3.8583e+02,  5.3064e+02,  1.9187e+02, -3.0686e+04,  2.4493e+02,\n",
      "          4.9498e+02, -1.1500e+04, -2.5552e+04],\n",
      "        [ 2.1614e+01,  3.2219e+01,  1.0825e+01, -1.8527e+03,  1.4455e+01,\n",
      "          3.2229e+01, -6.5435e+02, -1.7703e+03],\n",
      "        [ 2.8538e+02,  4.0448e+02,  1.4217e+02, -2.3338e+04,  1.8453e+02,\n",
      "          3.8812e+02, -8.5622e+03, -2.0567e+04],\n",
      "        [ 1.8905e+02,  2.6315e+02,  9.4065e+01, -1.5204e+04,  1.2087e+02,\n",
      "          2.4835e+02, -5.6507e+03, -1.2962e+04],\n",
      "        [-5.7500e+01, -8.0181e+01, -2.8624e+01,  4.6321e+03, -3.6821e+01,\n",
      "         -7.5763e+01,  1.7185e+03,  3.9585e+03]])\n",
      "fc2.weight grad: tensor([[-1.3070e+03, -1.0478e+03, -3.3906e+02,  4.7973e+04, -3.1807e+02,\n",
      "         -4.4427e+02,  1.3606e+04,  1.0025e+04],\n",
      "        [ 4.7040e+02,  3.7681e+02,  1.2197e+02, -1.7247e+04,  1.1439e+02,\n",
      "          1.6000e+02, -4.8982e+03, -3.5925e+03],\n",
      "        [-2.7635e+03, -2.2151e+03, -7.1683e+02,  1.0141e+05, -6.7236e+02,\n",
      "         -9.3951e+02,  2.8773e+04,  2.1169e+04],\n",
      "        [ 6.2283e+02,  4.9904e+02,  1.6154e+02, -2.2839e+04,  1.5139e+02,\n",
      "          2.1179e+02, -6.4896e+03, -4.7515e+03],\n",
      "        [ 1.6504e+01,  1.3511e+01,  4.3299e+00, -6.2362e+02,  4.1196e+00,\n",
      "          5.5244e+00, -1.6985e+02, -1.4268e+02],\n",
      "        [ 5.3940e+02,  4.3309e+02,  1.4003e+02, -1.9843e+04,  1.3157e+02,\n",
      "          1.8317e+02, -5.6080e+03, -4.1813e+03],\n",
      "        [ 3.1661e+02,  2.5393e+02,  8.2149e+01, -1.1628e+04,  7.7097e+01,\n",
      "          1.0760e+02, -3.2949e+03, -2.4350e+03],\n",
      "        [-8.9757e+01, -7.2002e+01, -2.3296e+01,  3.2964e+03, -2.1842e+01,\n",
      "         -3.0494e+01,  9.3490e+02,  6.8896e+02]])\n",
      "Episode 21: Total Return: -0.330, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 1.1602e+03,  1.2456e+03,  2.5826e+02, -4.8101e+04,  2.7100e+02,\n",
      "          6.8384e+02, -7.0678e+03, -2.4353e+03],\n",
      "        [-4.9153e+02, -5.2617e+02, -1.0918e+02,  2.0293e+04, -1.1429e+02,\n",
      "         -2.8773e+02,  2.9963e+03,  1.0149e+03],\n",
      "        [ 1.7765e+03,  1.9058e+03,  3.9529e+02, -7.3579e+04,  4.1454e+02,\n",
      "          1.0453e+03, -1.0823e+04, -3.7111e+03],\n",
      "        [-6.4273e+02, -6.8774e+02, -1.4281e+02,  2.6530e+04, -1.4946e+02,\n",
      "         -3.7598e+02,  3.9160e+03,  1.3214e+03],\n",
      "        [ 8.7992e+01,  9.5201e+01,  1.9700e+01, -3.6893e+03,  2.0805e+01,\n",
      "          5.2823e+01, -5.3513e+02, -1.9286e+02],\n",
      "        [-5.5017e+02, -5.9501e+02, -1.2304e+02,  2.3041e+04, -1.2986e+02,\n",
      "         -3.2982e+02,  3.3491e+03,  1.2061e+03],\n",
      "        [-3.3564e+02, -3.6074e+02, -7.4765e+01,  1.3937e+04, -7.8523e+01,\n",
      "         -1.9835e+02,  2.0445e+03,  7.0941e+02],\n",
      "        [ 4.3036e+01,  4.7327e+01,  9.7510e+00, -1.8472e+03,  1.0437e+01,\n",
      "          2.6832e+01, -2.6080e+02, -1.0284e+02]])\n",
      "fc2.weight grad: tensor([[ 5.9925e+01,  1.1224e+02,  2.7056e+01, -2.1157e+03,  2.4949e+01,\n",
      "          7.3229e+01,  7.9845e+00,  1.5095e+01],\n",
      "        [-2.6970e+01, -5.0609e+01, -1.2185e+01,  9.5463e+02, -1.1270e+01,\n",
      "         -3.3049e+01, -3.5819e+00, -6.8052e+00],\n",
      "        [ 4.4664e+00,  4.3479e+00,  1.3208e+00, -6.4840e+01,  9.0742e-01,\n",
      "          5.8868e-01,  1.1341e-01,  2.0333e+00],\n",
      "        [-3.5146e+01, -6.5961e+01, -1.5878e+01,  1.2444e+03, -1.4698e+01,\n",
      "         -4.3045e+01, -4.6627e+00, -8.8786e+00],\n",
      "        [-4.2229e-01, -7.3961e-01, -1.8853e-01,  1.3451e+01, -1.4595e-01,\n",
      "         -4.9848e-01, -6.6673e-02, -9.0918e-02],\n",
      "        [-3.0870e+01, -5.7610e+01, -1.3922e+01,  1.0843e+03, -1.2752e+01,\n",
      "         -3.7555e+01, -4.1430e+00, -7.7411e+00],\n",
      "        [-1.8423e+01, -3.4464e+01, -8.3147e+00,  6.4934e+02, -7.6508e+00,\n",
      "         -2.2475e+01, -2.4603e+00, -4.6349e+00],\n",
      "        [ 2.8969e+00,  5.3412e+00,  1.3009e+00, -1.0006e+02,  1.1672e+00,\n",
      "          3.4654e+00,  3.9721e-01,  7.1742e-01]])\n",
      "fc2.weight grad: tensor([[-3.9379e+02, -9.3426e+02, -3.4422e+02,  1.7847e+04, -1.9598e+02,\n",
      "         -7.4739e+02,  3.5791e+03,  1.2400e+04],\n",
      "        [ 1.8870e+02,  4.4508e+02,  1.6403e+02, -8.4984e+03,  9.3402e+01,\n",
      "          3.5577e+02, -1.7035e+03, -5.8687e+03],\n",
      "        [-1.1597e+02, -2.7673e+02, -1.0189e+02,  5.2887e+03, -5.8014e+01,\n",
      "         -2.2131e+02,  1.0637e+03,  3.6939e+03],\n",
      "        [ 2.6004e+02,  6.1669e+02,  2.2723e+02, -1.1781e+04,  1.2937e+02,\n",
      "          4.9338e+02, -2.3617e+03, -8.1819e+03],\n",
      "        [-1.9148e+01, -4.1851e+01, -1.5506e+01,  7.9389e+02, -8.8358e+00,\n",
      "         -3.3232e+01,  1.5660e+02,  5.0398e+02],\n",
      "        [ 2.1428e+02,  5.1313e+02,  1.8891e+02, -9.8097e+03,  1.0755e+02,\n",
      "          4.1064e+02, -1.9727e+03, -6.8771e+03],\n",
      "        [ 1.1068e+02,  2.6003e+02,  9.5893e+01, -4.9637e+03,  5.4599e+01,\n",
      "          2.0801e+02, -9.9180e+02, -3.4160e+03],\n",
      "        [ 4.5031e+00,  9.3855e+00,  3.4748e+00, -1.7716e+02,  1.9831e+00,\n",
      "          7.3178e+00, -3.5653e+01, -1.0493e+02]])\n",
      "Episode 22: Total Return: -0.388, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.2399e+00, -1.0021e+01, -4.5020e+00,  6.8243e-02, -4.6002e-01,\n",
      "         -9.1786e+00, -6.8086e-01, -5.1360e-01],\n",
      "        [ 5.1361e-01,  4.3007e+00,  1.9319e+00, -3.2465e-02,  1.9391e-01,\n",
      "          3.9643e+00,  2.8155e-01,  2.1164e-01],\n",
      "        [-3.6407e-01, -2.8439e+00, -1.2778e+00,  1.7374e-02, -1.3276e-01,\n",
      "         -2.5892e+00, -2.0013e-01, -1.5172e-01],\n",
      "        [ 7.6887e-01,  6.2851e+00,  2.8234e+00, -4.4246e-02,  2.8691e-01,\n",
      "          5.7680e+00,  4.2203e-01,  3.1783e-01],\n",
      "        [ 1.4061e-02, -1.2227e-01, -5.4569e-02,  5.6996e-03, -2.2606e-04,\n",
      "         -1.5040e-01,  8.3283e-03,  7.8435e-03],\n",
      "        [ 7.3750e-01,  5.6309e+00,  2.5302e+00, -3.1565e-02,  2.6599e-01,\n",
      "          5.1040e+00,  4.0580e-01,  3.0833e-01],\n",
      "        [ 2.7230e-01,  2.3393e+00,  1.0506e+00, -1.8712e-02,  1.0430e-01,\n",
      "          2.1644e+00,  1.4924e-01,  1.1145e-01],\n",
      "        [-1.5358e-02, -4.9159e-02, -2.2036e-02, -1.3586e-03, -4.1212e-03,\n",
      "         -3.1367e-02, -8.7654e-03, -6.7073e-03]])\n",
      "fc2.weight grad: tensor([[-2.8532e+03, -1.3901e+03, -2.0690e+03,  1.8154e+05, -5.9833e+02,\n",
      "         -2.5096e+03,  4.1061e+04,  7.0528e+04],\n",
      "        [ 1.2581e+03,  6.3082e+02,  9.2148e+02, -8.0046e+04,  2.6938e+02,\n",
      "          1.1249e+03, -1.9152e+04, -3.2394e+04],\n",
      "        [-5.7112e+03, -2.0967e+03, -3.8292e+03,  3.5837e+05, -5.2804e+02,\n",
      "         -3.7125e+03,  6.4395e+04,  1.5714e+03],\n",
      "        [ 1.6730e+03,  8.1836e+02,  1.2148e+03, -1.0651e+05,  3.5168e+02,\n",
      "          1.4761e+03, -2.4192e+04, -4.1586e+04],\n",
      "        [-7.9839e+01, -7.4795e+01, -7.6246e+01,  5.1625e+03, -2.7641e+01,\n",
      "         -1.0890e+02,  3.1435e+03,  4.5678e+03],\n",
      "        [ 1.4678e+03,  6.8253e+02,  1.0477e+03, -9.3335e+04,  2.9786e+02,\n",
      "          1.2562e+03, -1.9291e+04, -3.3925e+04],\n",
      "        [ 7.4125e+02,  3.7224e+02,  5.4321e+02, -4.7176e+04,  1.5885e+02,\n",
      "          6.6364e+02, -1.1302e+04, -1.9126e+04],\n",
      "        [-2.1087e+01, -1.1840e+01, -1.5914e+01,  1.5024e+03, -4.4531e+00,\n",
      "         -2.3454e+01,  1.9539e+02,  6.2126e+02]])\n",
      "Episode 23: Total Return: -0.009, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 1.6568e+03, -1.1030e+04,  8.1614e+02, -8.0597e+04,  6.8737e+02,\n",
      "          8.2959e+02, -6.7410e+04, -4.6817e+04],\n",
      "        [-6.6553e+02,  4.4671e+03, -3.4322e+02,  3.3490e+04, -2.7955e+02,\n",
      "         -3.6748e+02,  2.8057e+04,  2.0530e+04],\n",
      "        [ 2.4991e+02, -1.6710e+03,  1.1871e+02, -1.1838e+04,  1.0289e+02,\n",
      "          1.1523e+02, -9.8877e+03, -6.6071e+03],\n",
      "        [-8.8608e+02,  5.9268e+03, -4.4352e+02,  4.3614e+04, -3.6931e+02,\n",
      "         -4.5927e+02,  3.6500e+04,  2.5851e+04],\n",
      "        [ 4.5359e+02, -3.0987e+03,  2.4082e+02, -2.3324e+04,  1.9249e+02,\n",
      "          2.6555e+02, -1.9560e+04, -1.4846e+04],\n",
      "        [-7.8326e+02,  5.1213e+03, -3.5205e+02,  3.5654e+04, -3.1726e+02,\n",
      "         -3.1703e+02,  2.9717e+04,  1.8316e+04],\n",
      "        [-3.9763e+02,  2.6763e+03, -2.0703e+02,  2.0152e+04, -1.6749e+02,\n",
      "         -2.2392e+02,  1.6888e+04,  1.2492e+04],\n",
      "        [-5.1686e+00,  1.3988e+01, -4.9564e+00,  4.2756e+02, -2.3965e+00,\n",
      "         -8.1433e+00,  3.6478e+02,  3.6034e+02]])\n",
      "fc2.weight grad: tensor([[ 4.3826e+03, -1.2197e+03, -2.6412e+03, -1.1399e+05,  4.1381e+02,\n",
      "         -5.2568e+03,  2.4916e+05,  3.8220e+05],\n",
      "        [-1.9388e+03,  5.2590e+02,  1.1450e+03,  5.0471e+04, -1.9665e+02,\n",
      "          2.2836e+03, -1.0679e+05, -1.6628e+05],\n",
      "        [ 4.0155e+04,  2.2783e+03, -4.9023e+03, -1.5392e+06,  5.1093e+03,\n",
      "         -2.6492e+04,  7.0681e+05,  2.2564e+06],\n",
      "        [-2.5272e+03,  6.9622e+02,  1.5103e+03,  6.5810e+04, -2.4573e+02,\n",
      "          3.0063e+03, -1.4190e+05, -2.1888e+05],\n",
      "        [-1.5794e+04, -1.1205e+04, -1.8471e+04,  1.5479e+06, -5.3576e+03,\n",
      "         -2.8010e+04,  7.5109e+05,  1.0325e+06],\n",
      "        [-2.1146e+03,  6.1422e+02,  1.3213e+03,  5.4590e+04, -1.7385e+02,\n",
      "          2.6329e+03, -1.2662e+05, -1.8996e+05],\n",
      "        [-1.1950e+03,  3.2274e+02,  7.0306e+02,  3.1145e+04, -1.2261e+02,\n",
      "          1.4014e+03, -6.5474e+04, -1.0217e+05],\n",
      "        [-1.5346e+04, -5.2175e+03, -4.2808e+03,  9.6382e+05, -2.7375e+03,\n",
      "         -5.8725e+03,  1.4683e+03, -3.0270e+05]])\n",
      "fc2.weight grad: tensor([[-1.0858e+03, -1.4311e+03, -1.8629e+03,  1.6102e+04,  2.2324e+02,\n",
      "          1.9005e+03,  1.9380e+05,  8.3748e+04],\n",
      "        [ 4.4725e+02,  5.8320e+02,  7.5620e+02, -9.8446e+03, -7.0824e+01,\n",
      "         -6.6418e+02, -7.6402e+04, -3.3979e+04],\n",
      "        [ 5.2480e+03,  6.3024e+03,  4.7179e+03, -6.2383e+05,  3.6566e+03,\n",
      "          1.4212e+04, -3.0866e+05, -3.4619e+05],\n",
      "        [ 5.6494e+02,  7.4029e+02,  9.6226e+02, -1.0549e+04, -1.0194e+02,\n",
      "         -9.0657e+02, -9.8594e+04, -4.3266e+04],\n",
      "        [-3.6740e+03, -5.1231e+03, -6.7208e+03,  3.9844e+04,  9.6127e+02,\n",
      "          7.0378e+03,  7.0229e+05,  3.0326e+05],\n",
      "        [ 4.2741e+02,  5.7502e+02,  7.5252e+02, -3.6599e+02, -1.2696e+02,\n",
      "         -9.7368e+02, -8.2443e+04, -3.3816e+04],\n",
      "        [ 2.7938e+02,  3.6425e+02,  4.7222e+02, -6.1771e+03, -4.4051e+01,\n",
      "         -4.1405e+02, -4.7688e+04, -2.1217e+04],\n",
      "        [-1.8257e+02, -2.0807e+01, -1.8385e+01,  1.1917e+04, -1.0336e+02,\n",
      "         -1.1590e+02,  7.9565e+02, -4.3340e+02]])\n",
      "Episode 24: Total Return: -0.177, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-2.5498e+02, -1.8715e+02, -2.2266e+02,  1.4557e+04, -1.2237e+02,\n",
      "         -2.5161e+02,  9.8282e+03,  6.5650e+03],\n",
      "        [ 1.0090e+02,  7.1311e+01,  8.5580e+01, -5.6358e+03,  4.8785e+01,\n",
      "          9.6835e+01, -3.7885e+03, -2.4528e+03],\n",
      "        [-3.8993e+00, -2.6677e+00, -3.2250e+00,  2.1366e+02, -1.8916e+00,\n",
      "         -3.6368e+00,  1.4270e+02,  8.9935e+01],\n",
      "        [ 1.3456e+02,  9.6802e+01,  1.1569e+02, -7.5924e+03,  6.4802e+01,\n",
      "          1.3072e+02, -5.1117e+03, -3.3597e+03],\n",
      "        [-1.4535e+02, -1.4481e+02, -1.6544e+02,  1.0328e+04, -7.3059e+01,\n",
      "         -2.1154e+02,  7.6650e+03,  6.3002e+03],\n",
      "        [ 1.2876e+02,  1.0024e+02,  1.1773e+02, -7.6124e+03,  6.1068e+01,\n",
      "          1.3286e+02, -5.1761e+03, -3.6193e+03],\n",
      "        [ 6.2399e+01,  4.3823e+01,  5.2671e+01, -3.4729e+03,  3.0212e+01,\n",
      "          5.9629e+01, -2.3333e+03, -1.5024e+03],\n",
      "        [-1.3783e+01, -9.9594e+00, -1.1894e+01,  7.8003e+02, -6.6458e+00,\n",
      "         -1.3480e+01,  5.2646e+02,  3.4697e+02]])\n",
      "fc2.weight grad: tensor([[-2.4830e-01, -2.4941e+00, -3.9318e+00,  1.0059e+02, -1.8186e-01,\n",
      "         -2.0557e+00,  7.3157e+01,  5.7968e+01],\n",
      "        [ 5.4615e-02,  9.3525e-01,  1.5004e+00, -3.7431e+01,  6.4440e-02,\n",
      "          6.8145e-01, -2.7762e+01, -2.1918e+01],\n",
      "        [-2.5171e-02, -5.4618e-02, -7.2759e-02,  2.3521e+00, -5.9153e-03,\n",
      "         -9.0732e-02,  1.4328e+00,  1.1780e+00],\n",
      "        [-1.7091e-02,  1.1237e+00,  1.8594e+00, -4.4360e+01,  6.9445e-02,\n",
      "          6.2522e-01, -3.4062e+01, -2.6737e+01],\n",
      "        [-1.8372e-02, -9.4629e-02, -1.1622e-01,  3.1509e+00, -1.1752e-02,\n",
      "         -7.6047e-02,  2.7291e+00,  1.6853e+00],\n",
      "        [ 3.1689e-01,  1.4413e+00,  2.1537e+00, -5.9420e+01,  1.2189e-01,\n",
      "          1.5927e+00, -4.0793e+01, -3.2663e+01],\n",
      "        [ 7.1976e-02,  6.1528e-01,  9.6299e-01, -2.4902e+01,  4.5967e-02,\n",
      "          5.3115e-01, -1.7954e+01, -1.4259e+01],\n",
      "        [-6.0379e-02, -1.8042e-01, -2.5598e-01,  7.6021e+00, -1.7352e-02,\n",
      "         -2.4630e-01,  4.9269e+00,  4.0034e+00]])\n",
      "fc2.weight grad: tensor([[-3.2472e+03, -4.1387e+03, -4.0550e+03,  3.4004e+05, -3.3802e+03,\n",
      "         -3.8165e+03,  2.8018e+05,  2.2131e+05],\n",
      "        [ 1.0863e+03,  1.3869e+03,  1.3595e+03, -1.1384e+05,  1.1317e+03,\n",
      "          1.2789e+03, -9.3997e+04, -7.4246e+04],\n",
      "        [-4.2400e+03, -3.4433e+03, -2.7484e+03,  3.8046e+05, -3.2087e+03,\n",
      "         -3.8308e+03,  1.1799e+05,  9.1219e+04],\n",
      "        [ 1.3888e+03,  1.7784e+03,  1.7447e+03, -1.4574e+05,  1.4490e+03,\n",
      "          1.6403e+03, -1.2078e+05, -9.5405e+04],\n",
      "        [-2.2017e+03, -2.7973e+03, -2.7388e+03,  2.3020e+05, -2.2878e+03,\n",
      "         -2.5745e+03,  1.8893e+05,  1.4921e+05],\n",
      "        [ 1.2881e+03,  1.6326e+03,  1.5969e+03, -1.3455e+05,  1.3373e+03,\n",
      "          1.5064e+03, -1.1010e+05, -8.6974e+04],\n",
      "        [ 6.9249e+02,  8.8203e+02,  8.6404e+02, -7.2493e+04,  7.2061e+02,\n",
      "          8.1320e+02, -5.9683e+04, -4.7142e+04],\n",
      "        [ 3.8980e+01,  4.9537e+01,  4.8539e+01, -4.0740e+03,  4.0475e+01,\n",
      "          4.5262e+01, -3.3448e+03, -2.6394e+03]])\n",
      "Episode 25: Total Return: -0.232, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 3.7231e+02,  5.6099e+02,  4.3356e+02, -3.3984e+04,  4.3021e+02,\n",
      "          6.1624e+02, -1.9574e+04, -1.8815e+04],\n",
      "        [-1.3003e+02, -1.9577e+02, -1.5130e+02,  1.1864e+04, -1.5027e+02,\n",
      "         -2.1506e+02,  6.8251e+03,  6.5703e+03],\n",
      "        [ 1.3781e+02,  9.6775e+01,  9.4254e+01, -9.6806e+03,  1.2256e+02,\n",
      "          1.1727e+02, -7.2669e+02, -4.8511e+03],\n",
      "        [-1.6818e+02, -2.5259e+02, -1.9521e+02,  1.5324e+04, -1.9443e+02,\n",
      "         -2.7752e+02,  8.7849e+03,  8.4940e+03],\n",
      "        [-3.9458e+00, -8.7148e+00, -6.5881e+00,  4.4389e+02, -4.8565e+00,\n",
      "         -9.7376e+00,  3.6697e+02,  2.6993e+02],\n",
      "        [-1.5459e+02, -2.3403e+02, -1.8086e+02,  1.4147e+04, -1.7850e+02,\n",
      "         -2.5699e+02,  8.2038e+03,  7.8190e+03],\n",
      "        [-8.1201e+01, -1.2230e+02, -9.4517e+01,  7.4101e+03, -9.3836e+01,\n",
      "         -1.3435e+02,  4.2654e+03,  4.1033e+03],\n",
      "        [-1.3203e+00, -2.0247e+00, -1.5647e+00,  1.2168e+02, -1.5214e+00,\n",
      "         -2.2212e+00,  7.1863e+01,  6.6948e+01]])\n",
      "fc2.weight grad: tensor([[   21701.5879,    19679.6387,    20287.5957, -1717158.0000,\n",
      "            24541.7148,    22237.4375, -1353546.0000,  -990247.7500],\n",
      "        [   -7069.2485,    -6410.2974,    -6608.3818,   559349.7500,\n",
      "            -7994.5190,    -7243.1958,   440912.0312,   322528.7500],\n",
      "        [    7188.0298,     6554.3164,     6747.5859,  -570209.8750,\n",
      "             8110.1860,     7500.9512,  -445229.7188,  -337787.7812],\n",
      "        [   -9157.1211,    -8307.2598,    -8562.9531,   724700.6875,\n",
      "           -10353.6797,    -9397.1318,   570773.7500,   418851.5625],\n",
      "        [  -33987.6641,   -30833.2520,   -31782.6621,  2689793.0000,\n",
      "           -38429.4492,   -34871.9688,  2118835.5000,  1554120.1250],\n",
      "        [   -8218.3008,    -7443.7080,    -7676.0688,   649918.8750,\n",
      "            -9298.6396,    -8385.6191,   513463.4062,   372420.1250],\n",
      "        [   -4479.0479,    -4060.7927,    -4186.4741,   354370.6875,\n",
      "            -5065.7070,    -4586.1504,   279440.0312,   204126.8906],\n",
      "        [   -3522.4990,    -3155.9878,    -3263.3435,   277175.7812,\n",
      "            -4003.3430,    -3464.3748,   223044.7344,   150232.7344]])\n",
      "Episode 26: Total Return: 0.105, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.7533e+03, -1.6142e+03, -1.5256e+03,  1.5284e+05, -2.6996e+03,\n",
      "         -3.3047e+03,  1.3619e+05,  1.5359e+05],\n",
      "        [ 8.1773e+02,  7.5452e+02,  7.1291e+02, -7.1353e+04,  1.2594e+03,\n",
      "          1.5451e+03, -6.3580e+04, -7.1915e+04],\n",
      "        [-1.6892e+04, -1.5492e+04, -1.4656e+04,  1.4690e+06, -2.5966e+04,\n",
      "         -3.1637e+04,  1.3063e+06,  1.4720e+06],\n",
      "        [ 9.8732e+02,  9.1985e+02,  8.6733e+02, -8.6623e+04,  1.5257e+03,\n",
      "          1.8925e+03, -7.7474e+04, -8.8090e+04],\n",
      "        [-5.3610e+01, -4.7316e+01, -4.5011e+01,  4.5849e+03, -8.1986e+01,\n",
      "         -9.6226e+01,  4.0783e+03,  4.3628e+03],\n",
      "        [ 9.5230e+02,  8.5942e+02,  8.1600e+02, -8.2050e+04,  1.4552e+03,\n",
      "          1.7395e+03, -7.2447e+04, -8.1037e+04],\n",
      "        [ 5.8892e+02,  5.4191e+02,  5.1234e+02, -5.1305e+04,  9.0610e+02,\n",
      "          1.1080e+03, -4.5661e+04, -5.1587e+04],\n",
      "        [-1.9816e+03, -1.8183e+03, -1.7203e+03,  1.7234e+05, -3.0453e+03,\n",
      "         -3.7113e+03,  1.5315e+05,  1.7290e+05]])\n",
      "fc2.weight grad: tensor([[-9.3313e+02, -6.7647e+02, -7.5291e+02,  5.6846e+04, -1.0007e+03,\n",
      "         -6.9284e+02,  4.7875e+04,  1.3238e+04],\n",
      "        [ 4.5496e+02,  3.3103e+02,  3.6811e+02, -2.7755e+04,  4.8780e+02,\n",
      "          3.3902e+02, -2.3349e+04, -6.5934e+03],\n",
      "        [-7.0788e+03, -5.1278e+03, -5.7083e+03,  4.3110e+05, -7.5916e+03,\n",
      "         -5.2518e+03,  3.6315e+05,  9.9964e+04],\n",
      "        [ 5.7194e+02,  4.1869e+02,  4.6490e+02, -3.4974e+04,  6.1300e+02,\n",
      "          4.2878e+02, -2.9367e+04, -8.5843e+03],\n",
      "        [-2.3611e+01, -1.6064e+01, -1.8165e+01,  1.4045e+03, -2.5417e+01,\n",
      "         -1.6485e+01,  1.2057e+03,  2.1380e+02],\n",
      "        [ 4.8041e+02,  3.4317e+02,  3.8335e+02, -2.9100e+04,  5.1560e+02,\n",
      "          3.5147e+02, -2.4616e+04, -6.2243e+03],\n",
      "        [ 3.2242e+02,  2.3379e+02,  2.6019e+02, -1.9643e+04,  3.4575e+02,\n",
      "          2.3942e+02, -1.6542e+04, -4.5793e+03],\n",
      "        [-1.0142e+03, -7.3529e+02, -8.1837e+02,  6.1784e+04, -1.0876e+03,\n",
      "         -7.5302e+02,  5.2031e+04,  1.4394e+04]])\n",
      "fc2.weight grad: tensor([[ 3.6389e+02,  4.3250e+02,  5.1604e+02, -9.5118e+03,  3.7939e+02,\n",
      "          7.0495e+02, -7.4777e+03, -2.9563e+03],\n",
      "        [-1.9344e+02, -2.3023e+02, -2.7473e+02,  5.0615e+03, -2.0158e+02,\n",
      "         -3.7552e+02,  3.9883e+03,  1.5793e+03],\n",
      "        [ 1.9667e+03,  2.3349e+03,  2.7860e+03, -5.1356e+04,  2.0526e+03,\n",
      "          3.8073e+03, -4.0359e+04, -1.5968e+04],\n",
      "        [-2.3682e+02, -2.8267e+02, -3.3735e+02,  6.2106e+03, -2.4641e+02,\n",
      "         -4.6133e+02,  4.9106e+03,  1.9476e+03],\n",
      "        [ 1.1273e+01,  1.3416e+01,  1.5995e+01, -2.9531e+02,  1.1695e+01,\n",
      "          2.1740e+01, -2.3036e+02, -8.9939e+01],\n",
      "        [-2.1842e+02, -2.5730e+02, -3.0699e+02,  5.6670e+03, -2.2918e+02,\n",
      "         -4.1959e+02,  4.4226e+03,  1.7484e+03],\n",
      "        [-1.4137e+02, -1.6777e+02, -2.0020e+02,  3.6900e+03, -1.4765e+02,\n",
      "         -2.7373e+02,  2.9012e+03,  1.1492e+03],\n",
      "        [ 4.0215e+02,  4.7720e+02,  5.6946e+02, -1.0495e+04,  4.2010e+02,\n",
      "          7.7879e+02, -8.2548e+03, -3.2715e+03]])\n",
      "Episode 27: Total Return: -0.115, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 5.7397e+02,  3.7336e+02,  1.4824e+02, -1.5608e+04,  4.2808e+02,\n",
      "          1.7988e+01, -1.8386e+03,  1.4431e+02],\n",
      "        [-3.0035e+02, -1.9557e+02, -7.7775e+01,  8.1842e+03, -2.2442e+02,\n",
      "         -1.1430e+01,  9.8908e+02, -7.6518e+01],\n",
      "        [ 4.3163e+03,  2.7764e+03,  1.0860e+03, -1.1565e+05,  3.1969e+03,\n",
      "         -1.6933e+01, -1.1166e+04,  1.5022e+03],\n",
      "        [-3.5966e+02, -2.3079e+02, -9.0046e+01,  9.6191e+03, -2.6660e+02,\n",
      "          1.6732e+00,  9.0737e+02, -1.4041e+02],\n",
      "        [-1.0408e+03, -7.0103e+02, -2.9170e+02,  2.9802e+04, -8.0154e+02,\n",
      "         -1.8197e+02,  5.6954e+03, -4.7741e+01],\n",
      "        [-3.4796e+02, -2.2940e+02, -9.2881e+01,  9.6743e+03, -2.6373e+02,\n",
      "         -3.3858e+01,  1.4539e+03, -7.3177e+01],\n",
      "        [-2.2405e+02, -1.4794e+02, -5.9958e+01,  6.2302e+03, -1.6944e+02,\n",
      "         -2.0752e+01,  9.3420e+02, -3.7145e+01],\n",
      "        [ 6.4349e+02,  4.1699e+02,  1.6495e+02, -1.7457e+04,  4.8096e+02,\n",
      "          2.1022e+01, -2.0107e+03,  2.1092e+02]])\n",
      "fc2.weight grad: tensor([[-6.6747e+02, -6.6636e+02, -7.7195e+02,  9.5568e+02, -3.3503e+02,\n",
      "         -9.2547e+02,  3.0131e+03, -3.8857e+02],\n",
      "        [ 3.6758e+02,  3.6836e+02,  4.2560e+02, -5.2804e+02,  1.8440e+02,\n",
      "          5.1109e+02, -1.6651e+03,  2.1452e+02],\n",
      "        [-4.1454e+03, -4.1473e+03, -4.7998e+03,  5.9538e+03, -2.0810e+03,\n",
      "         -5.7615e+03,  1.8757e+04, -2.4137e+03],\n",
      "        [ 4.4709e+02,  4.5115e+02,  5.1929e+02, -6.4783e+02,  2.2428e+02,\n",
      "          6.2589e+02, -2.0398e+03,  2.6144e+02],\n",
      "        [ 6.1412e+00,  4.7970e+00,  6.5973e+00, -6.3650e+00,  2.9467e+00,\n",
      "          5.8609e+00,  2.9852e-01,  2.3634e+00],\n",
      "        [ 4.1101e+02,  4.0835e+02,  4.7512e+02, -5.8742e+02,  2.0663e+02,\n",
      "          5.6876e+02, -1.8485e+03,  2.3797e+02],\n",
      "        [ 2.6839e+02,  2.6672e+02,  3.1000e+02, -3.8281e+02,  1.3481e+02,\n",
      "          3.7092e+02, -1.2065e+03,  1.5576e+02],\n",
      "        [-7.4464e+02, -7.4670e+02, -8.6331e+02,  1.0732e+03, -3.7391e+02,\n",
      "         -1.0377e+03,  3.3780e+03, -4.3360e+02]])\n",
      "Episode 28: Total Return: -0.313, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-3.8089e+03, -4.4821e+03, -4.3813e+03,  2.0212e+05, -2.4214e+03,\n",
      "         -5.5806e+03,  2.1113e+05,  1.0618e+05],\n",
      "        [ 1.7824e+03,  2.0987e+03,  2.0506e+03, -9.4612e+04,  1.1337e+03,\n",
      "          2.6130e+03, -9.8841e+04, -4.9745e+04],\n",
      "        [-1.5226e+04, -1.7927e+04, -1.7516e+04,  8.0817e+05, -9.6843e+03,\n",
      "         -2.2319e+04,  8.4431e+05,  4.2482e+05],\n",
      "        [ 2.1386e+03,  2.5253e+03,  2.4615e+03, -1.1367e+05,  1.3637e+03,\n",
      "          3.1430e+03, -1.1882e+05, -5.9954e+04],\n",
      "        [-1.5765e+02, -1.8627e+02, -1.8149e+02,  8.3821e+03, -1.0057e+02,\n",
      "         -2.3183e+02,  8.7626e+03,  4.4256e+03],\n",
      "        [ 2.0002e+03,  2.3451e+03,  2.2990e+03, -1.0595e+05,  1.2677e+03,\n",
      "          2.9209e+03, -1.1060e+05, -5.5396e+04],\n",
      "        [ 1.2693e+03,  1.4899e+03,  1.4594e+03, -6.7274e+04,  8.0517e+02,\n",
      "          1.8555e+03, -7.0240e+04, -3.5231e+04],\n",
      "        [-4.1568e+03, -4.8921e+03, -4.7814e+03,  2.2059e+05, -2.6430e+03,\n",
      "         -6.0908e+03,  2.3044e+05,  1.1588e+05]])\n",
      "fc2.weight grad: tensor([[-1.5711e+02, -2.5058e+02, -2.4653e+02,  7.7489e+02, -6.3841e+01,\n",
      "         -3.3591e+02,  6.1739e+03,  7.0773e+02],\n",
      "        [ 7.8807e+01,  1.2563e+02,  1.2356e+02, -3.8803e+02,  3.2061e+01,\n",
      "          1.6839e+02, -3.0951e+03, -3.5444e+02],\n",
      "        [-4.5505e+02, -7.2573e+02, -7.1369e+02,  2.2431e+03, -1.8508e+02,\n",
      "         -9.7276e+02,  1.7876e+04,  2.0487e+03],\n",
      "        [ 9.4377e+01,  1.5037e+02,  1.4777e+02, -4.6374e+02,  3.8479e+01,\n",
      "          2.0151e+02, -3.7028e+03, -4.2364e+02],\n",
      "        [-1.0809e+00, -1.6930e+00, -1.6378e+00,  5.0008e+00, -4.6158e-01,\n",
      "         -2.2566e+00,  4.1415e+01,  4.5855e+00],\n",
      "        [ 8.8817e+01,  1.4192e+02,  1.3973e+02, -4.4048e+02,  3.5964e+01,\n",
      "          1.9032e+02, -3.4969e+03, -4.0217e+02],\n",
      "        [ 5.6494e+01,  9.0192e+01,  8.8783e+01, -2.7947e+02,  2.2908e+01,\n",
      "          1.2093e+02, -2.2225e+03, -2.5520e+02],\n",
      "        [-1.7382e+02, -2.7730e+02, -2.7274e+02,  8.5765e+02, -7.0649e+01,\n",
      "         -3.7172e+02,  6.8304e+03,  7.8330e+02]])\n",
      "fc2.weight grad: tensor([[-2.7298e+02, -4.2685e+02, -4.7859e+02,  8.3650e+03, -1.9586e+02,\n",
      "         -6.1058e+02,  1.3602e+04,  6.8590e+03],\n",
      "        [ 1.3878e+02,  2.1651e+02,  2.4296e+02, -4.2467e+03,  9.9539e+01,\n",
      "          3.0965e+02, -6.8945e+03, -3.4785e+03],\n",
      "        [-7.9351e+02, -1.2387e+03, -1.3897e+03,  2.4291e+04, -5.6920e+02,\n",
      "         -1.7716e+03,  3.9451e+04,  1.9903e+04],\n",
      "        [ 1.6588e+02,  2.5793e+02,  2.8978e+02, -5.0658e+03,  1.1892e+02,\n",
      "          3.6879e+02, -8.2052e+03, -4.1433e+03],\n",
      "        [ 8.8228e-01,  1.4466e+00,  1.5957e+00, -2.7945e+01,  6.3983e-01,\n",
      "          2.0757e+00, -4.6677e+01, -2.3474e+01],\n",
      "        [ 1.5693e+02,  2.4651e+02,  2.7594e+02, -4.8228e+03,  1.1268e+02,\n",
      "          3.5274e+02, -7.8658e+03, -3.9631e+03],\n",
      "        [ 9.9949e+01,  1.5667e+02,  1.7550e+02, -3.0675e+03,  7.1742e+01,\n",
      "          2.2414e+02, -4.9958e+03, -2.5180e+03],\n",
      "        [-3.0157e+02, -4.7098e+02, -5.2831e+02,  9.2348e+03, -2.1635e+02,\n",
      "         -6.7364e+02,  1.5002e+04,  7.5684e+03]])\n",
      "Episode 29: Total Return: -0.149, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-7.2717e+03, -6.8179e+03, -9.9101e+03,  8.3519e+04, -4.9107e+03,\n",
      "         -8.7129e+03,  1.4215e+05,  3.1491e+04],\n",
      "        [ 3.9650e+03,  3.7184e+03,  5.3996e+03, -4.5247e+04,  2.6773e+03,\n",
      "          4.7408e+03, -7.8516e+04, -1.7146e+04],\n",
      "        [-6.2313e+04, -5.8431e+04, -8.4904e+04,  7.1428e+05, -4.2080e+04,\n",
      "         -7.4621e+04,  1.2232e+06,  2.6991e+05],\n",
      "        [ 4.6499e+03,  4.3616e+03,  6.3273e+03, -5.2708e+04,  3.1393e+03,\n",
      "          5.5471e+03, -9.3275e+04, -2.0062e+04],\n",
      "        [ 3.4829e+02,  3.2643e+02,  4.7788e+02, -4.2049e+03,  2.3563e+02,\n",
      "          4.2561e+02, -6.1627e+03, -1.5635e+03],\n",
      "        [ 4.4906e+03,  4.2078e+03,  6.1252e+03, -5.2037e+04,  3.0325e+03,\n",
      "          5.3930e+03, -8.6057e+04, -1.9394e+04],\n",
      "        [ 2.9585e+03,  2.7731e+03,  4.0333e+03, -3.4105e+04,  1.9979e+03,\n",
      "          3.5481e+03, -5.7360e+04, -1.2794e+04],\n",
      "        [-7.9939e+03, -7.4952e+03, -1.0888e+04,  9.1407e+04, -5.3975e+03,\n",
      "         -9.5616e+03,  1.5754e+05,  3.4505e+04]])\n",
      "fc2.weight grad: tensor([[-1.2700e+02, -3.2743e+02, -3.0496e+02,  3.5555e+03, -1.3342e+02,\n",
      "         -4.7706e+02,  3.2640e+03,  6.1042e+01],\n",
      "        [ 6.6580e+01,  1.7324e+02,  1.6164e+02, -1.9243e+03,  7.0104e+01,\n",
      "          2.5412e+02, -1.6712e+03, -3.3079e+01],\n",
      "        [-4.8107e+02, -1.2389e+03, -1.1550e+03,  1.3499e+04, -5.0434e+02,\n",
      "         -1.8063e+03,  1.2346e+04,  2.2997e+02],\n",
      "        [ 7.8081e+01,  2.0347e+02,  1.9033e+02, -2.2944e+03,  8.1965e+01,\n",
      "          2.9965e+02, -1.9356e+03, -3.8916e+01],\n",
      "        [-1.6040e+00, -2.5957e+00, -2.7553e+00,  2.4057e+01, -1.1307e+00,\n",
      "         -3.3679e+00,  5.6164e+01, -3.9504e-01],\n",
      "        [ 7.9968e+01,  2.0101e+02,  1.8734e+02, -2.1077e+03,  8.2800e+01,\n",
      "          2.8945e+02, -2.1441e+03, -3.4715e+01],\n",
      "        [ 5.0356e+01,  1.2855e+02,  1.1983e+02, -1.3814e+03,  5.2560e+01,\n",
      "          1.8659e+02, -1.3136e+03, -2.3271e+01],\n",
      "        [-1.4226e+02, -3.6492e+02, -3.4090e+02,  3.9951e+03, -1.4839e+02,\n",
      "         -5.3243e+02,  3.6503e+03,  6.6857e+01]])\n",
      "fc2.weight grad: tensor([[-2.3590e+01, -2.1425e+01, -3.2132e+01, -9.6453e-01, -7.6667e+00,\n",
      "         -2.6805e+01,  1.7954e+02, -1.8476e+01],\n",
      "        [ 1.4217e+01,  1.2898e+01,  1.9337e+01,  5.8399e-01,  4.5971e+00,\n",
      "          1.6072e+01, -1.0664e+02,  1.1192e+01],\n",
      "        [-9.0622e+01, -8.2334e+01, -1.2338e+02, -3.7140e+00, -2.9373e+01,\n",
      "         -1.0280e+02,  6.8520e+02, -7.1195e+01],\n",
      "        [ 1.6779e+01,  1.5223e+01,  2.2792e+01,  6.9305e-01,  5.3921e+00,\n",
      "          1.8879e+01, -1.2382e+02,  1.3299e+01],\n",
      "        [-2.2950e-01, -2.1143e-01, -3.2541e-01, -7.9300e-03, -8.7271e-02,\n",
      "         -2.9898e-01,  2.5498e+00, -1.4693e-01],\n",
      "        [ 1.5725e+01,  1.4327e+01,  2.1481e+01,  6.3790e-01,  5.1537e+00,\n",
      "          1.8045e+01, -1.2274e+02,  1.2216e+01],\n",
      "        [ 1.0494e+01,  9.5413e+00,  1.4308e+01,  4.2788e-01,  3.4205e+00,\n",
      "          1.1965e+01, -8.0582e+01,  8.1956e+00],\n",
      "        [-2.6742e+01, -2.4304e+01, -3.6411e+01, -1.0963e+00, -8.6651e+00,\n",
      "         -3.0339e+01,  2.0211e+02, -2.1019e+01]])\n",
      "Episode 30: Total Return: -0.160, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[  -5842.0928,   -6102.3047,   -6633.5947,   56781.6914,   -3867.0383,\n",
      "           -5506.3525,  225552.3750,  402086.6875],\n",
      "        [   2517.1406,    2636.9424,    2844.4138,  -23105.8418,    1670.8024,\n",
      "            2355.7651,  -96541.2266, -174565.6562],\n",
      "        [ -19388.8516,  -16425.2227,  -26697.2812, 1007004.9375,  -11407.9053,\n",
      "          -18861.6699, 1018089.7500,   84514.6562],\n",
      "        [   2942.4395,    3104.7139,    3293.7402,  -23732.7422,    1964.0938,\n",
      "            2716.1260, -111474.2656, -207238.1875],\n",
      "        [ -11721.5967,  -12400.6328,  -13091.3516,   90980.7734,   -7835.7144,\n",
      "          -10785.1221,  442954.0312,  828996.6875],\n",
      "        [   2873.0996,    2969.4604,    3328.6687,  -34264.6133,    1879.9126,\n",
      "            2788.9888, -114105.2656, -191570.7500],\n",
      "        [   1877.1831,    1946.7767,    2158.0613,  -20837.0996,    1233.6754,\n",
      "            1801.6406,  -73725.5391, -126677.3594],\n",
      "        [  -6045.3320,   -6356.5059,   -6817.9536,   53543.3125,   -4018.7007,\n",
      "           -5642.6470,  231500.2344,  421116.0938]])\n",
      "fc2.weight grad: tensor([[  -903.0960,   -676.8530,   -681.2993,  -1510.7668,   -575.8812,\n",
      "           -663.6485,   8687.3438,  49313.0156],\n",
      "        [   415.6523,    313.1558,    313.8090,    721.4344,    266.6109,\n",
      "            309.5285,  -4146.1572, -22887.5586],\n",
      "        [  -560.1515,   -267.8363,   -789.0521,  14759.0488,   -131.1635,\n",
      "           -402.5539,    267.8741,   3074.4778],\n",
      "        [   494.6030,    374.8212,    374.6918,    853.4766,    318.8231,\n",
      "            373.7947,  -5133.5513, -27423.3789],\n",
      "        [ -1595.3635,  -1209.2148,  -1216.0516,  -2446.1680,  -1024.5757,\n",
      "          -1206.3273,  16595.1035,  87959.2578],\n",
      "        [   461.6631,    344.4540,    351.0169,    623.8423,    291.3102,\n",
      "            335.4131,  -4307.1973, -24819.2969],\n",
      "        [   301.6430,    226.0326,    227.7312,    496.5419,    192.2137,\n",
      "            221.5603,  -2898.1895, -16453.6211],\n",
      "        [  -987.4868,   -746.0591,   -751.0247,  -1530.8138,   -632.5942,\n",
      "           -740.6329,  10050.4521,  54254.9453]])\n",
      "Episode 31: Total Return: -0.022, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[   2806.9810,    2143.4321,    5288.1631,  -50263.1523,    2394.0227,\n",
      "            5210.5352, -192322.7344, -206645.9844],\n",
      "        [  -1243.9244,    -950.6915,   -2345.2151,   22480.3633,   -1058.1660,\n",
      "           -2311.4897,   84946.7969,   91344.8750],\n",
      "        [   3286.4800,    1537.7694,    5002.2295,  -96862.3984,    2363.9370,\n",
      "            3913.6326,  -76744.3906,   -7520.9902],\n",
      "        [  -1463.8153,   -1119.4810,   -2761.4272,   26627.4434,   -1242.6693,\n",
      "           -2722.1953,   99719.4453,  107317.0000],\n",
      "        [   9099.5371,    6952.4209,   17150.8066, -163992.0000,    7748.1689,\n",
      "           16903.2812, -622065.1250, -668607.1250],\n",
      "        [  -1362.6912,   -1039.8983,   -2564.6636,   24392.5957,   -1165.6794,\n",
      "           -2528.5681,   93472.6406,  100061.1172],\n",
      "        [   -911.5183,    -696.0288,   -1716.8751,   16365.1006,    -777.8309,\n",
      "           -1692.2832,   62422.8438,   66977.7500],\n",
      "        [   2965.0806,    2266.0640,    5589.2534,  -53686.2070,    2523.3611,\n",
      "            5510.3516, -202414.0312, -217429.1250]])\n",
      "fc2.weight grad: tensor([[-2.8550e+02, -1.8880e+02, -5.0366e+02,  4.0638e+03, -1.9303e+02,\n",
      "         -3.9878e+02,  5.1398e+03,  5.9730e+03],\n",
      "        [ 1.2713e+02,  8.2394e+01,  2.2255e+02, -1.8297e+03,  8.5135e+01,\n",
      "          1.7389e+02, -2.1909e+03, -2.5554e+03],\n",
      "        [-4.9257e+02, -1.3899e+02, -8.8233e+02,  9.9360e+03, -2.1790e+02,\n",
      "         -6.1696e+02,  4.3758e+03,  9.4179e+00],\n",
      "        [ 1.4692e+02,  9.3662e+01,  2.5558e+02, -2.1331e+03,  9.7626e+01,\n",
      "          1.9755e+02, -2.4415e+03, -2.8566e+03],\n",
      "        [-7.6927e+02, -4.9878e+02, -1.3469e+03,  1.1070e+04, -5.1533e+02,\n",
      "         -1.0530e+03,  1.3281e+04,  1.5477e+04],\n",
      "        [ 1.4740e+02,  9.9635e+01,  2.6227e+02, -2.0724e+03,  1.0074e+02,\n",
      "          2.1073e+02, -2.7832e+03, -3.2182e+03],\n",
      "        [ 9.6119e+01,  6.3953e+01,  1.6997e+02, -1.3635e+03,  6.5179e+01,\n",
      "          1.3512e+02, -1.7534e+03, -2.0352e+03],\n",
      "        [-2.9792e+02, -1.9351e+02, -5.2200e+02,  4.2830e+03, -1.9975e+02,\n",
      "         -4.0857e+02,  5.1638e+03,  6.0154e+03]])\n",
      "fc2.weight grad: tensor([[   4791.7808,    8186.2915,   13583.7295, -203257.7344,    3777.3608,\n",
      "            9708.2900, -411718.6250, -449573.6562],\n",
      "        [  -2052.0723,   -3510.6841,   -5821.4692,   87148.4062,   -1617.7692,\n",
      "           -4162.6426,  176541.3281,  192610.4688],\n",
      "        [   1327.8997,    2294.9419,    3847.3345,  -58934.7148,    1061.8809,\n",
      "            2768.4871, -117324.0156, -122304.0469],\n",
      "        [  -2413.8047,   -4133.6182,   -6851.1948,  102596.7812,   -1903.0397,\n",
      "           -4900.6362,  207846.3750,  226630.2188],\n",
      "        [   8795.1455,   15040.6123,   24945.2656, -373382.5625,    6933.9502,\n",
      "           17834.6602, -756399.8125, -825443.0625],\n",
      "        [  -2267.0266,   -3866.0544,   -6420.4297,   96012.2422,   -1787.2305,\n",
      "           -4585.8726,  194492.4531,  212597.1875],\n",
      "        [  -1493.2334,   -2549.9163,   -4232.0347,   63316.0000,   -1177.1033,\n",
      "           -3024.1758,  128251.1953,  140080.0312],\n",
      "        [   5011.5571,    8570.7949,   14214.4541, -212766.1406,    3951.1538,\n",
      "           10162.8730, -431034.8438, -470358.3438]])\n",
      "Episode 32: Total Return: 0.303, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 8.0661e+02,  1.7743e+03,  2.4270e+03, -1.7904e+04,  8.8137e+02,\n",
      "          1.9177e+03, -9.1893e+04, -1.4701e+05],\n",
      "        [-3.3588e+02, -7.3795e+02, -1.0153e+03,  7.7247e+03, -3.6322e+02,\n",
      "         -7.9964e+02,  3.8142e+04,  6.0493e+04],\n",
      "        [ 4.5687e+02,  1.1106e+03,  1.4837e+03, -1.2209e+04,  5.5464e+02,\n",
      "          1.2179e+03, -5.9611e+04, -8.9338e+04],\n",
      "        [-4.0274e+02, -8.8409e+02, -1.2217e+03,  9.5036e+03, -4.3215e+02,\n",
      "         -9.5984e+02,  4.5626e+04,  7.1890e+04],\n",
      "        [ 1.8142e+03,  3.9850e+03,  5.4693e+03, -4.0956e+04,  1.9713e+03,\n",
      "          4.3128e+03, -2.0622e+05, -3.2849e+05],\n",
      "        [-3.5491e+02, -7.7767e+02, -1.0607e+03,  7.5697e+03, -3.9049e+02,\n",
      "         -8.3881e+02,  4.0395e+04,  6.5147e+04],\n",
      "        [-2.3612e+02, -5.1926e+02, -7.0954e+02,  5.1965e+03, -2.5851e+02,\n",
      "         -5.6092e+02,  2.6908e+04,  4.3128e+04],\n",
      "        [ 8.4788e+02,  1.8594e+03,  2.5587e+03, -1.9347e+04,  9.1746e+02,\n",
      "          2.0144e+03, -9.6181e+04, -1.5276e+05]])\n",
      "fc2.weight grad: tensor([[-1.4623e+03, -2.3242e+03, -4.4819e+03,  8.4025e+04, -9.3337e+02,\n",
      "         -2.7561e+03,  7.6437e+04,  3.4798e+04],\n",
      "        [ 6.1831e+02,  9.9846e+02,  1.8987e+03, -3.5310e+04,  4.0400e+02,\n",
      "          1.1752e+03, -3.2435e+04, -1.5943e+04],\n",
      "        [ 1.2461e+03,  1.4871e+03,  4.1196e+03, -7.4112e+04,  5.4850e+02,\n",
      "          2.0806e+03, -7.0202e+04, -1.9318e+03],\n",
      "        [ 7.0819e+02,  1.1686e+03,  2.1805e+03, -4.0095e+04,  4.7761e+02,\n",
      "          1.3616e+03, -3.7334e+04, -2.0214e+04],\n",
      "        [-5.4277e+03, -8.7180e+03, -1.6657e+04,  3.1061e+05, -3.5189e+03,\n",
      "         -1.0287e+04,  2.8441e+05,  1.3629e+05],\n",
      "        [ 6.9574e+02,  1.0668e+03,  2.1234e+03, -4.0514e+04,  4.2049e+02,\n",
      "          1.2868e+03, -3.6022e+04, -1.3541e+04],\n",
      "        [ 4.6418e+02,  7.2339e+02,  1.4194e+03, -2.6871e+04,  2.8768e+02,\n",
      "          8.6585e+02, -2.4149e+04, -9.9288e+03],\n",
      "        [-1.4635e+03, -2.3461e+03, -4.4901e+03,  8.3809e+04, -9.4582e+02,\n",
      "         -2.7707e+03,  7.6609e+04,  3.6416e+04]])\n",
      "Episode 33: Total Return: -0.066, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-2.4148e+02, -6.8174e+02, -7.7552e+02,  4.9904e+03,  9.9911e+02,\n",
      "         -4.6800e+02,  1.3788e+04,  1.8713e+04],\n",
      "        [ 1.0379e+02,  2.9576e+02,  3.3516e+02, -2.1483e+03, -4.4953e+02,\n",
      "          2.0341e+02, -5.9930e+03, -8.1160e+03],\n",
      "        [-1.5321e+01, -2.2821e+01, -4.7430e+01,  4.9101e+02,  2.1068e+01,\n",
      "         -2.5117e+01,  5.9425e+02,  2.8600e+02],\n",
      "        [ 1.1978e+02,  3.4535e+02,  3.8953e+02, -2.4912e+03, -5.4956e+02,\n",
      "          2.3818e+02, -7.0192e+03, -9.4617e+03],\n",
      "        [-8.1251e+02, -2.3006e+03, -2.6141e+03,  1.6832e+04,  3.4172e+03,\n",
      "         -1.5807e+03,  4.6577e+04,  6.3085e+04],\n",
      "        [ 1.1456e+02,  3.2156e+02,  3.6694e+02, -2.4031e+03, -4.6738e+02,\n",
      "          2.2106e+02, -6.5200e+03, -8.7604e+03],\n",
      "        [ 7.7042e+01,  2.1592e+02,  2.4635e+02, -1.5879e+03, -3.0677e+02,\n",
      "          1.4797e+02, -4.3587e+03, -5.9319e+03],\n",
      "        [-2.4159e+02, -6.8783e+02, -7.7999e+02,  5.0345e+03,  1.0485e+03,\n",
      "         -4.7352e+02,  1.3958e+04,  1.8814e+04]])\n",
      "fc2.weight grad: tensor([[ 2.2609e+05, -2.3418e+04, -3.9950e+04,  5.5825e+05,  6.2728e+04,\n",
      "         -2.2252e+04,  8.1840e+05,  6.7965e+05],\n",
      "        [-1.2997e+05,  1.3662e+04,  2.3337e+04, -3.2340e+05, -3.5746e+04,\n",
      "          1.3086e+04, -4.7876e+05, -4.0073e+05],\n",
      "        [-7.0028e+03,  9.8354e+02,  1.7164e+03, -2.0487e+04, -1.5932e+03,\n",
      "          1.0617e+03, -3.5917e+04, -3.3933e+04],\n",
      "        [-1.5364e+05,  1.6238e+04,  2.7753e+04, -3.8340e+05, -4.2114e+04,\n",
      "          1.5601e+04, -5.6965e+05, -4.7817e+05],\n",
      "        [ 1.7418e+06, -1.8234e+05, -3.1121e+05,  4.3234e+06,  4.8358e+05,\n",
      "         -1.7375e+05,  6.3744e+06,  5.3266e+06],\n",
      "        [-1.2421e+05,  1.2840e+04,  2.1873e+04, -3.0612e+05, -3.5115e+04,\n",
      "          1.2091e+04, -4.4662e+05, -3.7098e+05],\n",
      "        [-9.2532e+04,  9.5715e+03,  1.6326e+04, -2.2831e+05, -2.5695e+04,\n",
      "          9.0876e+03, -3.3440e+05, -2.7750e+05],\n",
      "        [ 2.3259e+05, -2.4295e+04, -4.1461e+04,  5.7668e+05,  6.4610e+04,\n",
      "         -2.3130e+04,  8.4916e+05,  7.0872e+05]])\n",
      "fc2.weight grad: tensor([[ 9.0948e+03, -4.4854e+03, -4.9257e+03,  2.8483e+04, -3.0855e+03,\n",
      "         -2.8165e+03,  9.3459e+04,  7.5651e+04],\n",
      "        [-4.4478e+03,  2.1545e+03,  2.3652e+03, -1.3839e+04,  1.4818e+03,\n",
      "          1.3552e+03, -4.5052e+04, -3.6198e+04],\n",
      "        [ 6.6051e+02, -3.6465e+02, -4.0340e+02,  2.1330e+03, -2.5343e+02,\n",
      "         -2.2635e+02,  7.4137e+03,  6.3463e+03],\n",
      "        [-5.2420e+03,  2.4983e+03,  2.7420e+03, -1.6213e+04,  1.7182e+03,\n",
      "          1.5740e+03, -5.2411e+04, -4.1829e+04],\n",
      "        [ 4.1196e+04, -2.0446e+04, -2.2459e+04,  1.2929e+05, -1.4069e+04,\n",
      "         -1.2831e+04,  4.2547e+05,  3.4539e+05],\n",
      "        [-4.3776e+03,  2.3163e+03,  2.5501e+03, -1.4037e+04,  1.5979e+03,\n",
      "          1.4446e+03, -4.7581e+04, -3.9717e+04],\n",
      "        [-3.1369e+03,  1.6086e+03,  1.7679e+03, -9.9654e+03,  1.1071e+03,\n",
      "          1.0064e+03, -3.3263e+04, -2.7355e+04],\n",
      "        [ 8.9895e+03, -4.4932e+03, -4.9378e+03,  2.8266e+04, -3.0937e+03,\n",
      "         -2.8176e+03,  9.3352e+04,  7.6057e+04]])\n",
      "Episode 34: Total Return: -0.267, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.4947e+03,  3.3190e+03,  4.1869e+03, -2.1028e+04,  2.3857e+03,\n",
      "          2.3976e+03, -5.3080e+04, -9.2999e+04],\n",
      "        [ 7.4648e+02, -1.6584e+03, -2.0920e+03,  1.0504e+04, -1.1920e+03,\n",
      "         -1.1979e+03,  2.6517e+04,  4.6472e+04],\n",
      "        [-2.7500e+02,  6.3357e+02,  7.9869e+02, -3.9414e+03,  4.5357e+02,\n",
      "          4.5617e+02, -9.9772e+03, -1.7861e+04],\n",
      "        [ 8.7086e+02, -1.9215e+03, -2.4241e+03,  1.2212e+04, -1.3820e+03,\n",
      "         -1.3888e+03,  3.0810e+04,  5.3781e+04],\n",
      "        [-7.4451e+03,  1.6690e+04,  2.1051e+04, -1.0524e+05,  1.1985e+04,\n",
      "          1.2047e+04, -2.6587e+05, -4.6841e+05],\n",
      "        [ 8.0209e+02, -1.8261e+03, -2.3025e+03,  1.1427e+04, -1.3090e+03,\n",
      "         -1.3162e+03,  2.8900e+04,  5.1379e+04],\n",
      "        [ 5.6023e+02, -1.2664e+03, -1.5971e+03,  7.9531e+03, -9.0864e+02,\n",
      "         -9.1342e+02,  2.0105e+04,  3.5591e+04],\n",
      "        [-1.4817e+03,  3.3290e+03,  4.1987e+03, -2.0969e+04,  2.3898e+03,\n",
      "          2.4023e+03, -5.2980e+04, -9.3463e+04]])\n",
      "fc2.weight grad: tensor([[-1.6553e+03, -4.2843e+03, -7.3877e+03,  2.8001e+04, -1.9551e+03,\n",
      "         -4.1319e+03,  1.2683e+05,  9.7020e+04],\n",
      "        [ 9.1173e+02,  2.3592e+03,  4.0685e+03, -1.5420e+04,  1.0766e+03,\n",
      "          2.2755e+03, -6.9853e+04, -5.3421e+04],\n",
      "        [-1.2531e+02, -3.2623e+02, -5.6001e+02,  2.1130e+03, -1.4860e+02,\n",
      "         -3.1338e+02,  9.5791e+03,  7.4343e+03],\n",
      "        [ 1.0503e+03,  2.7174e+03,  4.6876e+03, -1.7777e+04,  1.2403e+03,\n",
      "          2.6216e+03, -8.0500e+04, -6.1499e+04],\n",
      "        [-4.9684e+03, -1.2808e+04, -2.2159e+04,  8.4315e+04, -5.8532e+03,\n",
      "         -1.2389e+04,  3.8147e+05,  2.8857e+05],\n",
      "        [ 9.3420e+02,  2.4003e+03,  4.1651e+03, -1.5907e+04,  1.0984e+03,\n",
      "          2.3278e+03, -7.1876e+04, -5.3832e+04],\n",
      "        [ 6.6785e+02,  1.7188e+03,  2.9779e+03, -1.1348e+04,  7.8599e+02,\n",
      "          1.6646e+03, -5.1320e+04, -3.8650e+04],\n",
      "        [-1.6419e+03, -4.2288e+03, -7.3221e+03,  2.7889e+04, -1.9333e+03,\n",
      "         -4.0932e+03,  1.2613e+05,  9.5162e+04]])\n",
      "fc2.weight grad: tensor([[  1324.9583,   5429.1836,   8931.6875,  -9756.9277,   2444.6218,\n",
      "           4342.9731, -60290.3125, -50104.9570],\n",
      "        [  -782.3181,  -3205.5745,  -5273.3960,   5760.3491,  -1443.3210,\n",
      "          -2564.2153,  35596.7109,  29583.6133],\n",
      "        [   145.7678,   1212.7639,   1074.8214,    234.7419,    388.5477,\n",
      "            299.6958,   -216.4213, -12327.7012],\n",
      "        [  -906.0247,  -3713.9492,  -6109.1826,   6672.3857,  -1672.4885,\n",
      "          -2969.9756,  41223.1094,  34286.8672],\n",
      "        [   485.7709,   1671.9708,   2308.6887,   -222.3176,    681.7327,\n",
      "           1303.8762, -20131.9941, -16551.9883],\n",
      "        [  -838.1583,  -3451.2349,  -5668.0693,   6175.2949,  -1556.0726,\n",
      "          -2749.2996,  38081.0586,  31990.2891],\n",
      "        [  -589.8344,  -2425.2607,  -3984.5996,   4343.8535,  -1092.9408,\n",
      "          -1934.1953,  26806.9219,  22452.6172],\n",
      "        [  1367.5403,   5620.7954,   9236.7324, -10072.8037,   2532.9277,\n",
      "           4484.4478, -62165.7539, -52016.5898]])\n",
      "Episode 35: Total Return: -0.267, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-9.1534e+02, -1.0546e+03, -3.3448e+03, -8.7969e+02, -1.1968e+03,\n",
      "         -1.8057e+03,  5.9820e+04,  2.6585e+04],\n",
      "        [ 5.5672e+02,  6.4125e+02,  2.0321e+03,  5.3488e+02,  7.2649e+02,\n",
      "          1.0978e+03, -3.6374e+04, -1.6125e+04],\n",
      "        [ 5.3502e+01,  6.1746e+01,  1.9636e+02,  5.1467e+01,  7.0530e+01,\n",
      "          1.0582e+02, -3.5030e+03, -1.5731e+03],\n",
      "        [ 6.2784e+02,  7.2331e+02,  2.2938e+03,  6.0336e+02,  8.2062e+02,\n",
      "          1.2385e+03, -4.1028e+04, -1.8225e+04],\n",
      "        [-2.0461e+03, -1.3142e+03, -1.1960e+04, -3.0816e+03, -4.5158e+03,\n",
      "         -5.7476e+03,  2.1930e+05,  1.2722e+03],\n",
      "        [ 5.9456e+02,  6.8577e+02,  2.1826e+03,  5.7211e+02,  7.8362e+02,\n",
      "          1.1749e+03, -3.8899e+04, -1.7461e+04],\n",
      "        [ 4.4833e+02,  5.1695e+02,  1.6437e+03,  4.3125e+02,  5.8957e+02,\n",
      "          8.8552e+02, -2.9323e+04, -1.3125e+04],\n",
      "        [-8.7180e+02, -1.0050e+03, -3.1931e+03, -8.3837e+02, -1.1445e+03,\n",
      "         -1.7213e+03,  5.7006e+04,  2.5463e+04]])\n",
      "fc2.weight grad: tensor([[ 7.6336e+01,  1.8130e+02,  3.6129e+02,  1.0661e+02,  6.6370e+01,\n",
      "          1.7441e+02, -9.9994e+02, -6.8770e+01],\n",
      "        [-4.6065e+01, -1.0931e+02, -2.1770e+02, -6.4248e+01, -3.9914e+01,\n",
      "         -1.0527e+02,  6.0515e+02,  4.1162e+01],\n",
      "        [-6.3548e-01, -1.5354e+00, -3.0888e+00, -9.1069e-01, -5.8767e-01,\n",
      "         -1.4387e+00,  7.7989e+00,  6.7233e-01],\n",
      "        [-5.2347e+01, -1.2431e+02, -2.4770e+02, -7.3095e+01, -4.5489e+01,\n",
      "         -1.1960e+02,  6.8596e+02,  4.7108e+01],\n",
      "        [ 1.9127e+01,  7.5798e+01,  4.3052e+02,  1.3296e+02,  1.2663e+02,\n",
      "          1.2277e+02, -2.0599e+02,  6.7391e+01],\n",
      "        [-4.9061e+01, -1.1682e+02, -2.3320e+02, -6.8790e+01, -4.3075e+01,\n",
      "         -1.1202e+02,  6.3734e+02,  4.5229e+01],\n",
      "        [-3.6387e+01, -8.6561e+01, -1.7269e+02, -5.0948e+01, -3.1838e+01,\n",
      "         -8.3101e+01,  4.7410e+02,  3.3270e+01],\n",
      "        [ 7.3521e+01,  1.7482e+02,  3.4864e+02,  1.0286e+02,  6.4206e+01,\n",
      "          1.6792e+02, -9.5945e+02, -6.6933e+01]])\n",
      "Episode 36: Total Return: -0.371, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-2.9615e+02, -5.3856e+02, -5.3720e+02, -2.0331e+01, -1.0863e+02,\n",
      "         -4.7089e+02,  8.5412e+03, -4.3140e+01],\n",
      "        [ 1.4232e+02,  2.5865e+02,  2.5819e+02,  9.8218e+00,  5.2195e+01,\n",
      "          2.2599e+02, -4.1018e+03,  2.0690e+01],\n",
      "        [ 1.6574e+01,  3.0790e+01,  2.9931e+01,  9.2962e-01,  6.1156e+00,\n",
      "          2.7580e+01, -4.8965e+02,  2.5861e+00],\n",
      "        [ 1.6669e+02,  3.0340e+02,  3.0229e+02,  1.1359e+01,  6.1142e+01,\n",
      "          2.6554e+02, -4.8121e+03,  2.4346e+01],\n",
      "        [-2.5799e+03, -4.6777e+03, -4.6872e+03, -1.8169e+02, -9.4873e+02,\n",
      "         -4.0750e+03,  7.4174e+04, -3.7314e+02],\n",
      "        [ 1.5162e+02,  2.7719e+02,  2.7470e+02,  9.9389e+00,  5.5675e+01,\n",
      "          2.4385e+02, -4.3990e+03,  2.2467e+01],\n",
      "        [ 1.0640e+02,  1.9482e+02,  1.9267e+02,  6.8792e+00,  3.9057e+01,\n",
      "          1.7169e+02, -3.0921e+03,  1.5835e+01],\n",
      "        [-3.1068e+02, -5.6598e+02, -5.6349e+02, -2.1010e+01, -1.1411e+02,\n",
      "         -4.9586e+02,  8.9788e+03, -4.5553e+01]])\n",
      "fc2.weight grad: tensor([[-8.6272e+02, -6.0311e+02, -3.1715e+03, -1.8364e+02, -1.1572e+03,\n",
      "         -1.1502e+03,  2.8456e+04, -5.9262e+02],\n",
      "        [ 3.8234e+02,  2.8315e+02,  1.4247e+03,  7.7367e+01,  5.2861e+02,\n",
      "          5.2057e+02, -1.2718e+04,  2.4761e+02],\n",
      "        [ 2.8259e+01,  1.6398e+01,  1.0962e+02,  6.9192e+00,  3.7952e+01,\n",
      "          3.5170e+01, -8.9218e+02,  2.9388e+01],\n",
      "        [ 4.3862e+02,  3.2062e+02,  1.6306e+03,  8.9828e+01,  6.0267e+02,\n",
      "          5.9429e+02, -1.4559e+04,  2.8893e+02],\n",
      "        [-8.8538e+03, -5.8915e+03, -3.2154e+04, -1.9598e+03, -1.1567e+04,\n",
      "         -1.1601e+04,  2.9009e+05, -6.3395e+03],\n",
      "        [ 3.9705e+02,  2.8681e+02,  1.4664e+03,  8.2152e+01,  5.4024e+02,\n",
      "          5.3575e+02, -1.3166e+04,  2.6095e+02],\n",
      "        [ 2.8043e+02,  2.0755e+02,  1.0439e+03,  5.6774e+01,  3.8728e+02,\n",
      "          3.8175e+02, -9.3291e+03,  1.8111e+02],\n",
      "        [-8.8701e+02, -6.1305e+02, -3.2504e+03, -1.9058e+02, -1.1821e+03,\n",
      "         -1.1778e+03,  2.9213e+04, -6.1467e+02]])\n",
      "fc2.weight grad: tensor([[-6.9403e+01, -2.4349e+01, -3.9528e+02, -4.6882e+01, -1.9327e+02,\n",
      "         -6.9759e+01,  1.1528e+03, -1.0768e+02],\n",
      "        [ 1.3920e+00, -1.1356e+01,  1.0993e+02,  1.1489e+01,  6.4228e+01,\n",
      "          1.1352e+00, -1.6949e+02,  4.1825e+01],\n",
      "        [ 1.3159e+01,  9.2077e+00,  3.6248e+01,  4.8596e+00,  1.3721e+01,\n",
      "          1.3362e+01, -1.6367e+02,  5.3022e+00],\n",
      "        [ 9.3005e+00, -7.3231e+00,  1.4434e+02,  1.5725e+01,  7.9955e+01,\n",
      "          9.1205e+00, -2.8575e+02,  4.9946e+01],\n",
      "        [-1.3053e+03, -7.2627e+02, -5.1198e+03, -6.4251e+02, -2.2656e+03,\n",
      "         -1.3179e+03,  1.8358e+04, -1.1254e+03],\n",
      "        [ 1.4494e+01, -2.0884e+00,  1.4398e+02,  1.6155e+01,  7.6718e+01,\n",
      "          1.4394e+01, -3.2863e+02,  4.6402e+01],\n",
      "        [ 1.6947e+00, -7.7641e+00,  8.1443e+01,  8.5756e+00,  4.7203e+01,\n",
      "          1.5094e+00, -1.3102e+02,  3.0562e+01],\n",
      "        [-8.5617e+01, -3.5535e+01, -4.3995e+02, -5.2915e+01, -2.1022e+02,\n",
      "         -8.6166e+01,  1.3535e+03, -1.1432e+02]])\n",
      "Episode 37: Total Return: -0.223, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 3.6456e+03,  7.2751e+03,  1.4544e+04,  4.1143e+03,  2.0503e+03,\n",
      "          7.5484e+03, -2.1973e+05,  6.3290e+03],\n",
      "        [-1.2467e+03, -2.5650e+03, -5.1918e+03, -1.4439e+03, -7.5284e+02,\n",
      "         -2.6602e+03,  7.7525e+04, -2.2298e+03],\n",
      "        [-2.5909e+01, -2.9679e+01, -4.0781e+01, -1.8876e+01,  5.4453e-01,\n",
      "         -3.2133e+01,  9.1434e+02, -2.6156e+01],\n",
      "        [-1.4730e+03, -3.0051e+03, -6.0620e+03, -1.6938e+03, -8.7229e+02,\n",
      "         -3.1173e+03,  9.0818e+04, -2.6128e+03],\n",
      "        [ 2.8783e+04,  5.6343e+04,  1.1174e+05,  3.1958e+04,  1.5455e+04,\n",
      "          5.8473e+04, -1.7008e+06,  4.9040e+04],\n",
      "        [-1.3675e+03, -2.7752e+03, -5.5866e+03, -1.5654e+03, -8.0024e+02,\n",
      "         -2.8783e+03,  8.3836e+04, -2.4134e+03],\n",
      "        [-8.9940e+02, -1.8523e+03, -3.7507e+03, -1.0425e+03, -5.4441e+02,\n",
      "         -1.9208e+03,  5.5977e+04, -1.6102e+03],\n",
      "        [ 3.7223e+03,  7.3860e+03,  1.4731e+04,  4.1805e+03,  2.0654e+03,\n",
      "          7.6637e+03, -2.2303e+05,  6.4264e+03]])\n",
      "fc2.weight grad: tensor([[-1.7084e+02, -5.6148e+02, -1.1676e+03, -3.6846e+02, -2.3298e+02,\n",
      "         -6.0339e+02,  1.7679e+04, -2.4466e+02],\n",
      "        [ 1.1430e+02,  3.1432e+02,  6.5040e+02,  2.1396e+02,  1.3125e+02,\n",
      "          3.3164e+02, -9.8463e+03,  1.4244e+02],\n",
      "        [-2.7266e+01, -6.2642e+01, -1.2908e+02, -4.4614e+01, -2.6515e+01,\n",
      "         -6.4789e+01,  1.9535e+03, -2.9756e+01],\n",
      "        [ 1.1363e+02,  3.2316e+02,  6.6926e+02,  2.1832e+02,  1.3470e+02,\n",
      "          3.4217e+02, -1.0132e+04,  1.4528e+02],\n",
      "        [-2.4466e+02, -1.7581e+03, -3.7075e+03, -1.0348e+03, -7.1766e+02,\n",
      "         -1.9859e+03,  5.6168e+04, -6.8118e+02],\n",
      "        [ 9.1241e+01,  2.6869e+02,  5.5720e+02,  1.8029e+02,  1.1199e+02,\n",
      "          2.8570e+02, -8.4359e+03,  1.1989e+02],\n",
      "        [ 8.3713e+01,  2.2993e+02,  4.7581e+02,  1.5658e+02,  9.6053e+01,\n",
      "          2.4261e+02, -7.2032e+03,  1.0424e+02],\n",
      "        [-1.3460e+02, -4.8552e+02, -1.0120e+03, -3.1328e+02, -2.0099e+02,\n",
      "         -5.2619e+02,  1.5325e+04, -2.0774e+02]])\n",
      "Episode 38: Total Return: -0.036, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-4.4369e+04, -1.2046e+05, -1.7811e+05, -8.2228e+04, -4.0728e+04,\n",
      "         -1.1907e+05,  4.6960e+06, -3.6751e+04],\n",
      "        [ 2.5105e+04,  6.7825e+04,  1.0027e+05,  4.5882e+04,  2.3179e+04,\n",
      "          6.7113e+04, -2.6556e+06,  1.5240e+04],\n",
      "        [ 2.6358e+03,  7.6518e+03,  1.1326e+04,  5.8408e+03,  2.2186e+03,\n",
      "          7.4668e+03, -2.8140e+05,  1.0458e+04],\n",
      "        [ 2.8133e+04,  7.6342e+04,  1.1290e+05,  5.2083e+04,  2.5843e+04,\n",
      "          7.5463e+04, -2.9767e+06,  2.2715e+04],\n",
      "        [-8.7092e+05, -2.3734e+06, -3.5090e+06, -1.6309e+06, -7.9573e+05,\n",
      "         -2.3446e+06,  9.2239e+07, -8.7035e+05],\n",
      "        [ 2.6277e+04,  7.1475e+04,  1.0565e+05,  4.8938e+04,  2.4061e+04,\n",
      "          7.0641e+04, -2.7828e+06,  2.4005e+04],\n",
      "        [ 2.0873e+04,  5.6390e+04,  8.3344e+04,  3.8131e+04,  1.9268e+04,\n",
      "          5.5807e+04, -2.2086e+06,  1.2645e+04],\n",
      "        [-4.7207e+04, -1.2883e+05, -1.9048e+05, -8.8764e+04, -4.3057e+04,\n",
      "         -1.2723e+05,  5.0003e+06, -5.0277e+04]])\n",
      "fc2.weight grad: tensor([[-1.9113e+02, -3.4710e+02, -6.4624e+02, -1.5794e+02, -8.2016e+01,\n",
      "         -3.7421e+02,  9.8643e+03, -1.2067e+02],\n",
      "        [ 6.0591e+01,  1.0457e+02,  1.9687e+02,  4.6628e+01,  2.9370e+01,\n",
      "          1.1048e+02, -2.8717e+03,  3.4257e+01],\n",
      "        [-1.5020e+01, -1.5979e+01, -3.4213e+01, -5.2895e+00, -1.3441e+01,\n",
      "         -1.2538e+01,  2.4601e+02, -1.1922e+00],\n",
      "        [ 6.2529e+01,  1.1433e+02,  2.1262e+02,  5.2174e+01,  2.6308e+01,\n",
      "          1.2361e+02, -3.2652e+03,  4.0089e+01],\n",
      "        [-7.7860e+02, -1.4835e+03, -2.7344e+03, -6.8719e+02, -2.9118e+02,\n",
      "         -1.6282e+03,  4.3437e+04, -5.4245e+02],\n",
      "        [ 5.4380e+01,  1.0222e+02,  1.8890e+02,  4.7109e+01,  2.1219e+01,\n",
      "          1.1162e+02, -2.9677e+03,  3.6845e+01],\n",
      "        [ 4.7325e+01,  8.0752e+01,  1.5237e+02,  3.5829e+01,  2.3538e+01,\n",
      "          8.4895e+01, -2.1987e+03,  2.6052e+01],\n",
      "        [-1.5577e+02, -2.9159e+02, -5.3944e+02, -1.3420e+02, -6.1468e+01,\n",
      "         -3.1797e+02,  8.4465e+03, -1.0472e+02]])\n",
      "fc2.weight grad: tensor([[-1.1748e+01, -1.9191e+01, -3.1203e+01, -7.2617e+00, -4.1052e+00,\n",
      "         -2.1867e+01,  1.9519e-02, -9.1337e+00],\n",
      "        [ 3.5423e+00,  6.0832e+00,  9.8883e+00,  2.2051e+00,  1.4187e+00,\n",
      "          6.9977e+00, -3.4037e-02,  2.8028e+00],\n",
      "        [ 2.3204e-01, -3.3363e-03, -1.2304e-02,  1.2412e-01, -1.5623e-01,\n",
      "         -8.9984e-02,  3.5524e-02,  1.1778e-01],\n",
      "        [ 4.1115e+00,  6.5612e+00,  1.0646e+01,  2.5349e+00,  1.3324e+00,\n",
      "          7.4398e+00,  7.0188e-03,  3.1715e+00],\n",
      "        [-3.8530e+01, -5.9527e+01, -9.6663e+01, -2.3648e+01, -1.1320e+01,\n",
      "         -6.7053e+01, -2.5424e-01, -2.9398e+01],\n",
      "        [ 3.7492e+00,  5.7908e+00,  9.4287e+00,  2.2993e+00,  1.1110e+00,\n",
      "          6.5243e+00,  2.5820e-02,  2.8599e+00],\n",
      "        [ 2.6995e+00,  4.6953e+00,  7.6514e+00,  1.6822e+00,  1.1255e+00,\n",
      "          5.4151e+00, -3.0864e-02,  2.1453e+00],\n",
      "        [-1.0132e+01, -1.5983e+01, -2.5969e+01, -6.2347e+00, -3.1847e+00,\n",
      "         -1.8083e+01, -3.6178e-02, -7.7844e+00]])\n",
      "Episode 39: Total Return: 0.035, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ -11.6905,  -17.8676,  -38.4106,  -12.7775,   -1.2746,  -24.8520,\n",
      "          -19.4490,  -15.5080],\n",
      "        [   3.9730,    6.1567,   12.7089,    4.3445,    0.2997,    8.5161,\n",
      "            6.5176,    5.2347],\n",
      "        [   0.2722,    0.2079,    1.7840,    0.2910,    0.3701,    0.4065,\n",
      "            0.6926,    0.4587],\n",
      "        [   4.6856,    7.1205,   16.0203,    5.1070,    0.7077,    9.9364,\n",
      "            7.9873,    6.3436],\n",
      "        [ -47.3693,  -71.5688, -161.3555,  -51.6851,   -7.1481, -100.0580,\n",
      "          -80.4610,  -63.7511],\n",
      "        [   4.7871,    7.0991,   16.8179,    5.2209,    0.9237,   10.0001,\n",
      "            8.2660,    6.4909],\n",
      "        [   2.9778,    4.5958,    9.4690,    3.2596,    0.2159,    6.3646,\n",
      "            4.8627,    3.8993],\n",
      "        [ -10.4590,  -15.8014,  -35.6664,  -11.4109,   -1.5900,  -22.0927,\n",
      "          -17.7781,  -14.0852]])\n",
      "fc2.weight grad: tensor([[ 3.2859e+06,  3.4257e+06,  8.0878e+06,  4.8624e+06, -3.0740e+08,\n",
      "          7.3099e+06,  6.2436e+06,  1.0584e+07],\n",
      "        [-1.4206e+06, -1.4879e+06, -3.5298e+06, -2.1155e+06,  1.3556e+08,\n",
      "         -3.1932e+06, -2.7292e+06, -4.6528e+06],\n",
      "        [ 2.5339e+05,  2.6529e+05,  6.3061e+05,  3.7777e+05, -2.4308e+07,\n",
      "          5.7092e+05,  4.8766e+05,  8.3350e+05],\n",
      "        [-1.5641e+06, -1.6259e+06, -3.8281e+06, -2.3058e+06,  1.4462e+08,\n",
      "         -3.4582e+06, -2.9524e+06, -4.9884e+06],\n",
      "        [ 2.3410e+06,  2.4192e+06,  5.7002e+06,  3.4278e+06, -2.1535e+08,\n",
      "          5.1486e+06,  4.3831e+06,  7.4281e+06],\n",
      "        [-1.5921e+06, -1.6474e+06, -3.8587e+06, -2.3318e+06,  1.4411e+08,\n",
      "         -3.4821e+06, -2.9710e+06, -4.9881e+06],\n",
      "        [-1.1733e+06, -1.2117e+06, -2.8635e+06, -1.7319e+06,  1.0827e+08,\n",
      "         -2.5939e+06, -2.2101e+06, -3.7433e+06],\n",
      "        [ 2.8788e+06,  2.9674e+06,  7.0224e+06,  4.2575e+06, -2.6410e+08,\n",
      "          6.3485e+06,  5.4204e+06,  9.1502e+06]])\n",
      "fc2.weight grad: tensor([[ 4764961.5000,  2465809.5000, 13356913.0000, 13419040.0000,\n",
      "         13742789.0000,  3330383.0000, 14587354.0000, 10781587.0000],\n",
      "        [-2132504.7500, -1107414.3750, -5926183.0000, -5947613.0000,\n",
      "         -6221117.0000, -1480991.6250, -6460489.0000, -4777982.5000],\n",
      "        [  275711.7500,   143896.2188,   758967.3750,   762152.8750,\n",
      "           828008.8750,   189913.0781,   827111.7500,   609843.7500],\n",
      "        [-2235916.0000, -1155778.6250, -6286418.0000, -6318863.0000,\n",
      "         -6433015.0000, -1566041.1250, -6870778.5000, -5075440.0000],\n",
      "        [ 2996114.0000,  1547774.0000,  8432412.0000,  8474647.0000,\n",
      "          8584035.0000,  2100487.2500,  9215786.0000,  6811230.0000],\n",
      "        [-2196563.7500, -1131335.1250, -6227449.0000, -6264040.5000,\n",
      "         -6231405.0000, -1548282.3750, -6816186.0000, -5035037.0000],\n",
      "        [  550606.5625,   670653.1875,  1431105.5000,   938313.1875,\n",
      "         -8097831.5000,   858546.4375,  1041736.5000,   155310.9688],\n",
      "        [ 2517464.2500,  1364546.0000,  5305752.0000,  5005718.0000,\n",
      "         11550060.0000,  1369302.5000,  5534416.5000,  5098946.0000]])\n",
      "Episode 40: Total Return: -0.061, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-9.1319e+06, -7.7218e+06, -2.0362e+07, -9.1101e+06,  1.2223e+08,\n",
      "         -1.0597e+07, -8.8278e+06, -1.3866e+07],\n",
      "        [ 4.0175e+06,  3.4004e+06,  8.9760e+06,  4.0114e+06, -5.3914e+07,\n",
      "          4.6669e+06,  3.8892e+06,  6.1223e+06],\n",
      "        [-5.9583e+05, -5.0475e+05, -1.3331e+06, -5.9618e+05,  8.0010e+06,\n",
      "         -6.9287e+05, -5.7825e+05, -9.0923e+05],\n",
      "        [ 4.3562e+06,  3.6828e+06,  9.7092e+06,  4.3455e+06, -5.8267e+07,\n",
      "          5.0540e+06,  4.2103e+06,  6.6089e+06],\n",
      "        [-6.0135e+06, -5.0828e+06, -1.3398e+07, -5.9960e+06,  8.0410e+07,\n",
      "         -6.9748e+06, -5.8088e+06, -9.1187e+06],\n",
      "        [ 4.3981e+06,  3.7145e+06,  9.7829e+06,  4.3822e+06, -5.8685e+07,\n",
      "          5.0968e+06,  4.2435e+06,  6.6498e+06],\n",
      "        [ 3.2485e+06,  2.7358e+06,  7.2213e+06,  3.2327e+06, -4.3269e+07,\n",
      "          3.7569e+06,  3.1284e+06,  4.9212e+06],\n",
      "        [-7.6183e+06, -6.4283e+06, -1.6942e+07, -7.3934e+06,  1.0501e+08,\n",
      "         -8.8346e+06, -7.1642e+06, -1.1691e+07]])\n",
      "fc2.weight grad: tensor([[ 2.2395e+07,  3.3830e+06,  4.3214e+07,  1.5044e+07, -2.8746e+08,\n",
      "          4.9671e+06,  1.8414e+07,  3.3011e+07],\n",
      "        [-1.1663e+07, -1.9481e+06, -2.2401e+07, -7.1103e+06,  1.7080e+08,\n",
      "         -2.7118e+06, -8.5474e+06, -1.6516e+07],\n",
      "        [ 2.1001e+06,  3.8994e+05,  4.0244e+06,  1.2498e+06, -3.2900e+07,\n",
      "          5.1350e+05,  1.4878e+06,  2.9215e+06],\n",
      "        [-1.0147e+07, -1.5121e+06, -1.9598e+07, -6.9561e+06,  1.2679e+08,\n",
      "         -2.2362e+06, -8.5408e+06, -1.5076e+07],\n",
      "        [ 1.5286e+07,  2.2885e+06,  2.9498e+07,  1.0260e+07, -1.9554e+08,\n",
      "          3.3773e+06,  1.2562e+07,  2.2541e+07],\n",
      "        [-8.0274e+06, -9.3238e+05, -1.5638e+07, -6.3902e+06,  7.3044e+07,\n",
      "         -1.5933e+06, -8.0418e+06, -1.2782e+07],\n",
      "        [-7.0699e+06, -9.7065e+05, -1.3695e+07, -5.1131e+06,  8.0007e+07,\n",
      "         -1.5029e+06, -6.3376e+06, -1.0764e+07],\n",
      "        [ 1.7748e+07,  2.5194e+06,  3.4333e+07,  1.2494e+07, -2.1060e+08,\n",
      "          3.8286e+06,  1.5419e+07,  2.6706e+07]])\n",
      "Episode 41: Total Return: 0.262, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-7.2297e+06, -4.4802e+06, -1.6053e+07, -4.9471e+06,  1.6560e+08,\n",
      "         -5.9193e+06, -5.6002e+06, -1.3315e+07],\n",
      "        [ 3.3534e+06,  2.0846e+06,  7.4590e+06,  2.2938e+06, -7.6998e+07,\n",
      "          2.7515e+06,  2.5973e+06,  6.1751e+06],\n",
      "        [-4.1896e+05, -2.5734e+05, -9.2689e+05, -2.8691e+05,  9.5367e+06,\n",
      "         -3.4087e+05, -3.2475e+05, -7.7025e+05],\n",
      "        [ 3.4630e+06,  2.1436e+06,  7.6854e+06,  2.3699e+06, -7.9258e+07,\n",
      "          2.8331e+06,  2.6827e+06,  6.3773e+06],\n",
      "        [-4.5999e+06, -2.8504e+06, -1.0212e+07, -3.1476e+06,  1.0536e+08,\n",
      "         -3.7662e+06, -3.5630e+06, -8.4736e+06],\n",
      "        [ 3.3564e+06,  2.0723e+06,  7.4367e+06,  2.2977e+06, -7.6658e+07,\n",
      "          2.7412e+06,  2.6002e+06,  6.1842e+06],\n",
      "        [ 2.5874e+06,  1.6000e+06,  5.7383e+06,  1.7709e+06, -5.9169e+07,\n",
      "          2.1154e+06,  2.0044e+06,  4.7661e+06],\n",
      "        [-6.1262e+06, -3.7921e+06, -1.3594e+07, -4.1925e+06,  1.4020e+08,\n",
      "         -5.0120e+06, -4.7455e+06, -1.1284e+07]])\n",
      "fc2.weight grad: tensor([[ 5.5025e+07,  4.4116e+07,  1.1444e+08,  3.5920e+07, -1.3930e+09,\n",
      "          5.2941e+07,  2.9978e+07,  9.1697e+07],\n",
      "        [-2.6176e+07, -2.0996e+07, -5.4498e+07, -1.7135e+07,  6.6213e+08,\n",
      "         -2.5177e+07, -1.4362e+07, -4.3709e+07],\n",
      "        [ 3.2373e+06,  2.5978e+06,  6.7214e+06,  2.0976e+06, -8.2147e+07,\n",
      "          3.1166e+06,  1.7331e+06,  5.3843e+06],\n",
      "        [-2.7487e+07, -2.2037e+07, -5.7152e+07, -1.7926e+07,  6.9602e+08,\n",
      "         -2.6448e+07, -1.4941e+07, -4.5784e+07],\n",
      "        [ 3.6771e+07,  2.9472e+07,  7.6459e+07,  2.3995e+07, -9.3091e+08,\n",
      "          3.5379e+07,  2.0011e+07,  6.1238e+07],\n",
      "        [-2.7588e+07, -2.2097e+07, -5.7284e+07, -1.7933e+07,  6.9920e+08,\n",
      "         -2.6556e+07, -1.4866e+07, -4.5813e+07],\n",
      "        [-2.1820e+07, -1.7487e+07, -4.5348e+07, -1.4216e+07,  5.5267e+08,\n",
      "         -2.0998e+07, -1.1827e+07, -3.6306e+07],\n",
      "        [ 4.6485e+07,  3.7255e+07,  9.6624e+07,  3.0299e+07, -1.1772e+09,\n",
      "          4.4731e+07,  2.5226e+07,  7.7368e+07]])\n",
      "fc2.weight grad: tensor([[  63326.7891,   94845.9062,  808981.3125,  625880.0625,  204813.6406,\n",
      "          217854.2969,  535320.3125, -555649.1250],\n",
      "        [ -46392.7578,  -55139.9922, -448069.7500, -327100.9062,   85790.6016,\n",
      "         -122158.3906, -303113.5000,  230636.8750],\n",
      "        [  -1646.0969,    2089.3308,   28198.1309,   28458.0137,   79849.6797,\n",
      "            6886.4292,   17112.8750,  -44679.6250],\n",
      "        [ -29737.9160,  -47283.3789, -409051.2812, -320404.8125, -145944.1719,\n",
      "         -109764.3906, -269663.0312,  296083.4688],\n",
      "        [  42124.2109,   62782.9570,  531947.2500,  410727.9375,  121630.0312,\n",
      "          143498.5625,  351629.3438, -362951.8125],\n",
      "        [ -10906.8359,  -37221.7344, -346850.2812, -296426.7500, -369323.8125,\n",
      "          -91438.8672, -219382.3125,  349782.6875],\n",
      "        [  -4546.0581,   -7968.7354,  -38689.0977,  -88148.9609, -189091.8125,\n",
      "          -33450.1797,   60998.3086,  367357.6875],\n",
      "        [  14237.8525,   20433.9238,   90455.5938,  181396.8750,  282626.4688,\n",
      "           73148.6875, -118545.8594, -733153.0000]])\n",
      "Episode 42: Total Return: 0.207, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-6.3149e+05, -2.4643e+05, -2.3711e+06, -1.1611e+06,  1.5534e+07,\n",
      "         -3.1146e+05, -2.2081e+06, -2.3051e+06],\n",
      "        [ 3.0963e+05,  1.2566e+05,  1.1653e+06,  5.6542e+05, -7.7168e+06,\n",
      "          1.5378e+05,  1.0770e+06,  1.1363e+06],\n",
      "        [-2.5030e+04, -1.8610e+03, -1.1005e+05, -6.1770e+04,  5.0858e+05,\n",
      "         -6.4754e+03, -1.2314e+05, -1.1018e+05],\n",
      "        [ 3.0751e+05,  1.1817e+05,  1.1584e+06,  5.6908e+05, -7.5398e+06,\n",
      "          1.5030e+05,  1.0836e+06,  1.1269e+06],\n",
      "        [-4.0661e+05, -1.6278e+05, -1.5096e+06, -7.3542e+05,  1.0033e+07,\n",
      "         -2.0537e+05, -1.3919e+06, -1.4621e+06],\n",
      "        [ 3.2037e+05,  1.1824e+05,  1.1886e+06,  5.8967e+05, -7.7107e+06,\n",
      "          1.5866e+05,  1.1145e+06,  1.1461e+06],\n",
      "        [ 2.5497e+05,  9.6950e+04,  9.5368e+05,  4.6981e+05, -6.2128e+06,\n",
      "          1.2566e+05,  8.9155e+05,  9.2430e+05],\n",
      "        [-5.2771e+05, -2.0243e+05, -1.9728e+06, -9.7000e+05,  1.2890e+07,\n",
      "         -2.6087e+05, -1.8406e+06, -1.9124e+06]])\n",
      "fc2.weight grad: tensor([[ 1.1747e+06,  3.4616e+06,  8.2868e+06,  1.7050e+06, -1.3273e+08,\n",
      "          2.6002e+06,  2.1076e+05,  7.5202e+06],\n",
      "        [-5.6613e+05, -1.6726e+06, -3.9905e+06, -8.2021e+05,  6.3993e+07,\n",
      "         -1.2530e+06, -9.2918e+04, -3.6232e+06],\n",
      "        [ 4.4786e+04,  1.2923e+05,  3.2068e+05,  6.6649e+04, -5.0659e+06,\n",
      "          9.9354e+04,  1.5995e+04,  2.8955e+05],\n",
      "        [-5.8022e+05, -1.7097e+06, -4.0951e+06, -8.4266e+05,  6.5576e+07,\n",
      "         -1.2844e+06, -1.0591e+05, -3.7160e+06],\n",
      "        [ 6.6113e+05,  1.9480e+06,  4.6601e+06,  9.5859e+05, -7.4673e+07,\n",
      "          1.4633e+06,  1.1523e+05,  4.2292e+06],\n",
      "        [-6.0071e+05, -1.7608e+06, -4.2398e+06, -8.7376e+05,  6.7788e+07,\n",
      "         -1.3299e+06, -1.2162e+05, -3.8438e+06],\n",
      "        [-4.6994e+05, -1.3816e+06, -3.3165e+06, -6.8289e+05,  5.3075e+07,\n",
      "         -1.0403e+06, -8.9600e+04, -3.0084e+06],\n",
      "        [ 9.9023e+05,  2.9128e+06,  6.9864e+06,  1.4382e+06, -1.1184e+08,\n",
      "          2.1920e+06,  1.8502e+05,  6.3380e+06]])\n",
      "fc2.weight grad: tensor([[ 7.2666e+05,  9.1154e+05,  3.4623e+06,  3.2770e+05, -1.0233e+07,\n",
      "          1.1370e+06,  5.0219e+05,  2.1888e+06],\n",
      "        [-4.0075e+05, -5.2658e+05, -1.8040e+06, -1.6800e+05,  5.0519e+06,\n",
      "         -6.3456e+05, -4.2964e+05, -1.3118e+06],\n",
      "        [-9.8024e+03, -1.2967e+04, -4.2192e+04, -3.5411e+03,  1.2939e+05,\n",
      "         -1.5370e+04, -7.1041e+03, -2.9653e+04],\n",
      "        [-3.6489e+05, -4.5797e+05, -1.7373e+06, -1.6447e+05,  5.1320e+06,\n",
      "         -5.7104e+05, -2.5369e+05, -1.1001e+06],\n",
      "        [ 3.5164e+05,  4.4157e+05,  1.6715e+06,  1.5799e+05, -4.9406e+06,\n",
      "          5.5019e+05,  2.4450e+05,  1.0598e+06],\n",
      "        [-4.0310e+05, -5.2513e+05, -1.8261e+06, -1.7233e+05,  5.0836e+06,\n",
      "         -6.3625e+05, -4.3666e+05, -1.3177e+06],\n",
      "        [-3.1991e+05, -4.1806e+05, -1.4466e+06, -1.3594e+05,  4.0344e+06,\n",
      "         -5.0560e+05, -3.4556e+05, -1.0466e+06],\n",
      "        [ 6.7716e+05,  8.8565e+05,  3.0594e+06,  2.8704e+05, -8.5386e+06,\n",
      "          1.0704e+06,  7.3036e+05,  2.2153e+06]])\n",
      "Episode 43: Total Return: 0.009, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-6.4698e+04,  2.8146e+03, -1.0676e+05, -6.4577e+03,  7.2550e+05,\n",
      "         -9.9116e+03,  5.2746e+04,  3.7924e+03],\n",
      "        [ 2.9671e+04, -4.1203e+03,  4.2275e+04,  2.0944e+03, -3.2688e+05,\n",
      "          7.8213e+02, -2.8160e+04, -9.7537e+03],\n",
      "        [ 4.3173e+02, -1.1235e+03, -1.5380e+03, -5.1525e+02, -7.9564e+03,\n",
      "         -2.1121e+03, -2.8760e+03, -4.8337e+03],\n",
      "        [ 2.0970e+04, -7.3581e+03,  3.8922e+04, -4.2259e+03, -3.6791e+05,\n",
      "         -2.0624e+04, -4.5739e+04, -5.4834e+04],\n",
      "        [-1.8108e+04,  6.8249e+03, -3.2396e+04,  3.8676e+03,  3.1783e+05,\n",
      "          1.8652e+04,  4.0479e+04,  4.9210e+04],\n",
      "        [ 3.5905e+04,  3.8694e+03,  7.2021e+04,  5.2425e+03, -4.1377e+05,\n",
      "          1.2713e+04, -2.1673e+04,  1.3248e+04],\n",
      "        [ 2.7142e+04,  7.9117e+02,  4.9397e+04,  3.3085e+03, -3.0837e+05,\n",
      "          6.7708e+03, -1.9380e+04,  3.9676e+03],\n",
      "        [-5.5993e+04, -3.7542e+02, -9.8908e+04, -6.4373e+03,  6.3353e+05,\n",
      "         -1.2291e+04,  4.1756e+04, -4.6102e+03]])\n",
      "fc2.weight grad: tensor([[ 8.4017e+04,  1.0958e+05,  6.6540e+05,  1.5770e+05, -5.8993e+06,\n",
      "          2.7178e+05,  1.5033e+05,  5.6285e+05],\n",
      "        [-4.1401e+04, -5.4103e+04, -3.2799e+05, -7.7740e+04,  2.9083e+06,\n",
      "         -1.3389e+05, -7.4177e+04, -2.7768e+05],\n",
      "        [-1.1227e+02, -1.1789e+02, -3.5311e+03, -1.5241e+03,  2.3241e+04,\n",
      "         -4.2962e+02, -2.1534e+03, -2.6334e+03],\n",
      "        [-4.2726e+04, -5.5714e+04, -3.3837e+05, -8.0190e+04,  2.9998e+06,\n",
      "         -1.3821e+05, -7.6433e+04, -2.8619e+05],\n",
      "        [ 3.9455e+04,  5.1424e+04,  3.1244e+05,  7.4044e+04, -2.7698e+06,\n",
      "          1.2764e+05,  7.0557e+04,  2.6420e+05],\n",
      "        [-4.3100e+04, -5.6004e+04, -3.4113e+05, -8.0833e+04,  3.0236e+06,\n",
      "         -1.3948e+05, -7.6910e+04, -2.8808e+05],\n",
      "        [-3.4278e+04, -4.4642e+04, -2.7140e+05, -6.4317e+04,  2.4059e+06,\n",
      "         -1.1090e+05, -6.1265e+04, -2.2942e+05],\n",
      "        [ 7.0486e+04,  9.1819e+04,  5.5812e+05,  1.3226e+05, -4.9477e+06,\n",
      "          2.2804e+05,  1.2600e+05,  4.7184e+05]])\n",
      "Episode 44: Total Return: 0.120, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 3.7135e+05,  3.0858e+05,  1.0674e+06,  2.6351e+05, -7.0351e+06,\n",
      "          6.7331e+05,  2.4833e+05,  5.9662e+05],\n",
      "        [-2.5168e+05, -1.6479e+05, -6.6076e+05, -1.6274e+05,  3.2304e+06,\n",
      "         -3.8107e+05, -2.4445e+05, -5.6466e+05],\n",
      "        [-4.6511e+04, -3.6764e+04, -1.1818e+05, -3.1894e+04,  8.9149e+05,\n",
      "         -8.4803e+04, -2.2602e+04, -6.3779e+04],\n",
      "        [-1.7997e+05, -1.4246e+05, -4.5539e+05, -1.2341e+05,  3.4887e+06,\n",
      "         -3.2940e+05, -8.5549e+04, -2.3977e+05],\n",
      "        [-2.8245e+03, -8.4466e+04, -5.7223e+04,  1.2684e+05, -4.1098e+06,\n",
      "          1.6389e+05,  3.8849e+06,  3.2343e+03],\n",
      "        [-2.9379e+05, -1.9366e+05, -7.7256e+05, -1.9024e+05,  3.7637e+06,\n",
      "         -4.4690e+05, -2.8026e+05, -6.5920e+05],\n",
      "        [-2.1956e+05, -1.4429e+05, -5.7695e+05, -1.4208e+05,  2.8153e+06,\n",
      "         -3.3328e+05, -2.1120e+05, -4.9263e+05],\n",
      "        [ 4.6923e+05,  3.0841e+05,  1.2331e+06,  3.0366e+05, -6.0163e+06,\n",
      "          7.1233e+05,  4.5116e+05,  1.0528e+06]])\n",
      "fc2.weight grad: tensor([[ 1.7317e+03, -2.5532e+03, -4.6962e+03,  9.6821e+05, -4.0960e+03,\n",
      "          8.2086e+02,  2.1249e+05, -9.1194e+03],\n",
      "        [-1.3014e+02,  1.3050e+03,  2.9965e+03, -4.7699e+05,  2.1317e+03,\n",
      "          1.3840e+02, -1.6888e+05,  3.7137e+03],\n",
      "        [-7.0629e+02, -1.5891e+03, -4.3592e+03,  5.6432e+05, -2.6553e+03,\n",
      "         -8.1206e+02,  2.7701e+05, -3.4524e+03],\n",
      "        [-7.7641e+02,  1.4334e+02, -2.7159e+02, -7.0600e+04,  1.9621e+02,\n",
      "         -5.4788e+02,  4.2201e+04,  1.3649e+03],\n",
      "        [-3.5737e+04, -1.3215e+05, -2.0079e+04,  3.8578e+05, -1.7488e+04,\n",
      "         -1.3111e+04,  1.3551e+06, -5.3709e+04],\n",
      "        [ 4.7021e+02,  2.2732e+03,  5.8070e+03, -8.1972e+05,  3.7697e+03,\n",
      "          7.6207e+02, -3.5294e+05,  5.6152e+03],\n",
      "        [ 3.1080e+02,  1.5560e+03,  3.9430e+03, -5.5803e+05,  2.5666e+03,\n",
      "          5.0977e+02, -2.3875e+05,  3.8445e+03],\n",
      "        [ 2.9754e+02, -3.2871e+03, -7.5869e+03,  1.2030e+06, -5.3797e+03,\n",
      "         -3.7345e+02,  4.2910e+05, -9.3248e+03]])\n",
      "fc2.weight grad: tensor([[-1.0106e+03, -4.9479e+02, -1.8571e+03,  2.0121e+05, -4.0338e+02,\n",
      "         -1.0434e+03,  2.7594e+05,  1.9761e+02],\n",
      "        [ 2.9415e+02,  2.1495e+02,  5.0778e+02, -5.2242e+04,  9.2894e+01,\n",
      "          2.9650e+02, -7.9041e+04, -5.9242e+01],\n",
      "        [-1.8792e+02, -2.8377e+02, -2.5753e+02,  2.0404e+04, -9.6097e+00,\n",
      "         -1.7463e+02,  4.7898e+04,  4.0541e+01],\n",
      "        [ 2.1036e+02,  1.5829e+01,  4.2667e+02, -4.9638e+04,  1.1393e+02,\n",
      "          2.2601e+02, -5.9000e+04, -3.9176e+01],\n",
      "        [ 1.0776e+03,  4.5931e+03,  1.4490e+03,  1.0873e+04,  6.7281e+02,\n",
      "          5.2101e+02, -1.7377e+05,  1.4461e+03],\n",
      "        [ 3.6068e+02,  3.7796e+02,  5.7078e+02, -5.3969e+04,  7.5522e+01,\n",
      "          3.5203e+02, -9.4906e+04, -7.4279e+01],\n",
      "        [ 2.4022e+02,  2.6288e+02,  3.7463e+02, -3.4908e+04,  4.5998e+01,\n",
      "          2.3330e+02, -6.2991e+04, -5.0186e+01],\n",
      "        [-8.3416e+02, -6.1873e+02, -1.4365e+03,  1.4741e+05, -2.6111e+02,\n",
      "         -8.3994e+02,  2.2402e+05,  1.6739e+02]])\n",
      "Episode 45: Total Return: -0.449, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-2.8159e+03, -3.6502e+03, -3.4037e+03,  2.5169e+05, -2.0683e+03,\n",
      "         -2.9106e+03,  4.3521e+05, -1.5680e+03],\n",
      "        [ 1.4532e+03,  1.9669e+03,  1.9531e+03, -1.4585e+05,  1.0651e+03,\n",
      "          1.4633e+03, -2.2798e+05,  7.4756e+02],\n",
      "        [-1.4201e+03, -2.0077e+03, -2.1105e+03,  1.5909e+05, -1.0389e+03,\n",
      "         -1.3901e+03,  2.2620e+05, -6.6851e+02],\n",
      "        [ 2.9724e+02,  3.0554e+02,  1.7076e+02, -1.1262e+04,  2.2048e+02,\n",
      "          3.4447e+02, -4.2694e+04,  2.2472e+02],\n",
      "        [-6.7133e+03, -1.8553e+04, -8.0624e+03,  1.9855e+04, -4.5869e+03,\n",
      "         -6.8887e+03,  1.6392e+06, -3.9298e+03],\n",
      "        [ 1.9692e+03,  2.7284e+03,  2.7950e+03, -2.0998e+05,  1.4423e+03,\n",
      "          1.9536e+03, -3.1139e+05,  9.6889e+02],\n",
      "        [ 1.1960e+03,  1.6455e+03,  1.6704e+03, -1.2523e+05,  8.7607e+02,\n",
      "          1.1918e+03, -1.8868e+05,  5.9614e+02],\n",
      "        [-2.8833e+03, -3.8704e+03, -3.7985e+03,  2.8344e+05, -2.1148e+03,\n",
      "         -2.9184e+03,  4.5092e+05, -1.5096e+03]])\n",
      "fc2.weight grad: tensor([[-2.3356e+03, -2.8891e+03, -1.0950e+03,  2.5954e+04, -3.9103e+02,\n",
      "         -2.5985e+03,  3.9237e+05, -3.7700e+03],\n",
      "        [ 7.9485e+02,  9.9019e+02,  3.2812e+02, -5.1674e+03,  1.3151e+02,\n",
      "          8.9086e+02, -1.3618e+05,  1.3044e+03],\n",
      "        [-3.4471e+02, -4.4126e+02, -6.7359e+01, -3.9287e+03, -5.4412e+01,\n",
      "         -3.9736e+02,  6.3525e+04, -6.0180e+02],\n",
      "        [ 6.6318e+02,  8.1278e+02,  3.5982e+02, -1.1388e+04,  1.1278e+02,\n",
      "          7.3064e+02, -1.0850e+05,  1.0469e+03],\n",
      "        [-4.7240e+03, -1.4091e+04, -3.4212e+03, -5.8218e+03, -3.2372e+03,\n",
      "         -4.2191e+03,  8.0644e+05, -1.9136e+03],\n",
      "        [ 8.0825e+02,  1.0174e+03,  2.6813e+02,  1.4737e+02,  1.3147e+02,\n",
      "          9.1550e+02, -1.4239e+05,  1.3580e+03],\n",
      "        [ 5.7311e+02,  7.1857e+02,  2.0703e+02, -1.2954e+03,  9.3777e+01,\n",
      "          6.4669e+02, -9.9950e+04,  9.5479e+02],\n",
      "        [-1.7477e+03, -2.1761e+03, -7.2990e+02,  1.2045e+04, -2.8951e+02,\n",
      "         -1.9575e+03,  2.9894e+05, -2.8640e+03]])\n",
      "Episode 46: Total Return: -0.145, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-5.0180e+03, -5.4715e+03, -5.8697e+03,  1.6159e+05, -3.0511e+03,\n",
      "         -5.5392e+03,  5.6014e+05, -1.1798e+04],\n",
      "        [ 1.8071e+03,  1.9895e+03,  2.0780e+03, -5.4995e+04,  1.0960e+03,\n",
      "          2.0019e+03, -2.0155e+05,  4.1302e+03],\n",
      "        [-8.8654e+02, -1.0050e+03, -9.6553e+02,  2.2171e+04, -5.3378e+02,\n",
      "         -9.9290e+02,  9.8646e+04, -1.8485e+03],\n",
      "        [ 1.3794e+03,  1.4876e+03,  1.6443e+03, -4.7163e+04,  8.4100e+02,\n",
      "          1.5165e+03, -1.5411e+05,  3.3446e+03],\n",
      "        [-4.3563e+02, -6.6249e+02, -4.9082e+02, -3.5201e+02, -3.1093e+02,\n",
      "         -5.2611e+02,  6.0314e+04, -4.7665e+02],\n",
      "        [ 1.9866e+03,  2.2151e+03,  2.2328e+03, -5.5858e+04,  1.2014e+03,\n",
      "          2.2112e+03, -2.2137e+05,  4.3712e+03],\n",
      "        [ 1.5173e+03,  1.6776e+03,  1.7318e+03, -4.5031e+04,  9.1962e+02,\n",
      "          1.6835e+03, -1.6920e+05,  3.4263e+03],\n",
      "        [-3.7968e+03, -4.1821e+03, -4.3628e+03,  1.1527e+05, -2.3030e+03,\n",
      "         -4.2068e+03,  4.2349e+05, -8.6687e+03]])\n",
      "fc2.weight grad: tensor([[   350.1127,    184.4736,    400.5822,  -1240.3890,    183.8124,\n",
      "            211.8335, -13264.7607,    612.1907],\n",
      "        [  -109.6109,    -56.9758,   -125.3149,    347.1682,    -59.5041,\n",
      "            -67.0764,   4461.2256,   -194.2827],\n",
      "        [    39.8040,     19.0409,     45.2018,    -44.2546,     25.4996,\n",
      "             25.8620,  -2233.1951,     75.7969],\n",
      "        [   -99.4221,    -53.1510,   -113.8979,    390.0987,    -50.3966,\n",
      "            -59.4587,   3483.0535,   -171.4164],\n",
      "        [    74.7574,     92.0234,    157.3677,    220.9017,     63.9316,\n",
      "             52.8854,  -6016.0332,    144.7757],\n",
      "        [  -101.5211,    -51.0335,   -115.6802,    238.8960,    -59.0441,\n",
      "            -63.6446,   4751.5229,   -185.2655],\n",
      "        [   -83.0643,    -42.5125,    -94.7545,    234.9131,    -46.4338,\n",
      "            -51.3483,   3592.1218,   -149.0669],\n",
      "        [   238.2275,    123.1450,    272.0817,   -728.6970,    130.5562,\n",
      "            146.2571,  -9889.9736,    423.9622]])\n",
      "fc2.weight grad: tensor([[-9.3750e+02, -4.4646e+02, -5.9634e+02, -1.0610e+03, -7.0379e+02,\n",
      "         -9.7450e+01,  5.4852e+04, -9.9219e+02],\n",
      "        [ 5.3980e+02,  2.8553e+02,  3.7820e+02,  6.5533e+02,  4.5193e+02,\n",
      "          7.7535e+01, -3.2893e+04,  5.9060e+02],\n",
      "        [-9.8155e+03, -4.9929e+03, -6.6346e+03, -1.1612e+04, -7.8890e+03,\n",
      "         -1.2591e+03,  5.8898e+05, -1.0602e+04],\n",
      "        [ 2.9652e+02,  1.3047e+02,  1.7542e+02,  3.1854e+02,  2.0506e+02,\n",
      "          2.2776e+01, -1.6854e+04,  3.0663e+02],\n",
      "        [ 3.5833e+03,  1.8265e+03,  2.4268e+03,  4.2453e+03,  2.8861e+03,\n",
      "          4.6242e+02, -2.1519e+05,  3.8727e+03],\n",
      "        [ 5.7262e+02,  2.9968e+02,  3.9744e+02,  6.9102e+02,  4.7387e+02,\n",
      "          7.9709e+01, -3.4749e+04,  6.2400e+02],\n",
      "        [ 3.8842e+02,  1.9834e+02,  2.6358e+02,  4.6119e+02,  3.1328e+02,\n",
      "          5.0330e+01, -2.3345e+04,  4.1986e+02],\n",
      "        [-5.5497e+02, -2.8385e+02, -3.7708e+02, -6.5925e+02, -4.4850e+02,\n",
      "         -7.2312e+01,  3.3374e+04, -6.0036e+02]])\n",
      "Episode 47: Total Return: 0.213, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 1.4296e+03,  9.7511e+02,  6.4551e+02, -4.2098e+04,  5.9477e+02,\n",
      "          1.4621e+03,  2.7969e+04,  1.1601e+03],\n",
      "        [-5.7830e+02, -3.6924e+02, -2.9846e+02,  1.4529e+04, -2.4194e+02,\n",
      "         -5.4540e+02, -8.5320e+03, -4.5221e+02],\n",
      "        [-6.7057e+03, -3.8279e+03, -5.6088e+03, -1.5350e+04, -3.2217e+03,\n",
      "         -4.3517e+03,  1.7819e+05, -4.2473e+03],\n",
      "        [-1.8662e+02, -1.5133e+02, -5.1241e+01,  7.8269e+03, -7.6848e+01,\n",
      "         -2.3411e+02, -6.2368e+03, -1.6727e+02],\n",
      "        [ 3.7079e+03,  2.1177e+03,  3.0989e+03,  8.5033e+03,  1.7819e+03,\n",
      "          2.4072e+03, -9.8655e+04,  2.3495e+03],\n",
      "        [-6.6900e+02, -4.2584e+02, -3.4231e+02,  1.6778e+04, -2.7902e+02,\n",
      "         -6.2976e+02, -9.8522e+03, -5.2308e+02],\n",
      "        [-4.7049e+02, -2.9672e+02, -2.4381e+02,  1.1546e+04, -1.9618e+02,\n",
      "         -4.3810e+02, -6.6504e+03, -3.6617e+02],\n",
      "        [ 1.0483e+03,  6.7443e+02,  5.2860e+02, -2.6942e+04,  4.3738e+02,\n",
      "          9.9919e+02,  1.6154e+04,  8.2404e+02]])\n",
      "fc2.weight grad: tensor([[-1934.5984,  -753.5864, -1381.7333, 11517.9814, -3179.7539, -2091.3086,\n",
      "          -912.6924,  -984.2079],\n",
      "        [  618.8478,   238.2151,   435.5102, -3639.0811,  1005.1699,   663.7114,\n",
      "           289.7992,   311.8278],\n",
      "        [  -26.2644,  -173.5478,  -383.8732,   643.6202,  -670.7330,  -296.2355,\n",
      "           -99.7039,  -161.1328],\n",
      "        [  406.6271,   166.8073,   309.6749, -2546.9155,   703.6097,   455.0553,\n",
      "           198.0049,   215.5396],\n",
      "        [ -188.9520,   -74.0570,  -136.0097,  1130.1353,  -312.4375,  -205.0787,\n",
      "           -89.4336,   -96.5532],\n",
      "        [  735.0893,   280.7043,   512.0466, -4299.2910,  1184.7329,   784.3267,\n",
      "           342.8490,   368.3491],\n",
      "        [  559.9793,   206.4393,   373.2170, -3156.9055,   871.3521,   583.7968,\n",
      "           255.5609,   272.7825],\n",
      "        [-1195.8787,  -458.4435,  -837.1868,  7011.9619, -1934.6599, -1279.1725,\n",
      "          -558.8367,  -600.8471]])\n",
      "fc2.weight grad: tensor([[  107.1569,   -48.2259,   162.0245, -1122.8666,   220.1005,    64.3421,\n",
      "            81.9475,   195.8947],\n",
      "        [  -26.5770,    17.6194,   -41.5371,   320.5105,   -51.7396,   -12.3000,\n",
      "           -21.3832,   -51.3796],\n",
      "        [ -130.5580,   -58.7573,   -43.0142,  -243.0988,  -178.0046,  -128.2350,\n",
      "           -38.9586,   -84.8611],\n",
      "        [  -37.9785,    -2.7242,   -52.8164,   254.1817,   -88.3693,   -35.9113,\n",
      "           -25.4542,   -60.2145],\n",
      "        [   10.6145,    -6.3561,    16.4670,  -124.0256,    21.1286,     5.4470,\n",
      "             8.4504,    20.3661],\n",
      "        [  -27.4029,    24.8663,   -44.3047,   376.9112,   -49.5994,    -8.0605,\n",
      "           -23.1852,   -55.7240],\n",
      "        [   -5.1381,    28.3709,   -13.8805,   244.2968,     2.9147,    14.0295,\n",
      "            -8.6980,   -21.7436],\n",
      "        [   53.4806,   -38.6541,    84.2613,  -666.3743,   102.2396,    22.4774,\n",
      "            43.5457,   104.5740]])\n",
      "Episode 48: Total Return: -0.252, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.8641e+03, -1.3109e+03, -7.6180e+02,  2.4902e+04, -1.8299e+03,\n",
      "         -3.2058e+03,  6.4515e+04, -3.4912e+02],\n",
      "        [ 5.4794e+02,  3.8030e+02,  2.1946e+02, -6.4758e+03,  5.2790e+02,\n",
      "          9.3518e+02, -1.9010e+04,  1.0765e+02],\n",
      "        [ 5.2319e+02,  2.6186e+03,  2.1066e+03, -4.2105e+04,  5.5178e+03,\n",
      "          5.4219e+03, -1.4245e+05,  1.0731e+03],\n",
      "        [ 5.4317e+02,  4.4053e+02,  2.7308e+02, -1.5813e+04,  6.5821e+02,\n",
      "          1.0232e+03, -1.9307e+04,  2.0507e+01],\n",
      "        [-1.0658e+02, -9.5964e+01, -6.1933e+01,  4.5469e+03, -1.4912e+02,\n",
      "         -2.1500e+02,  3.8279e+03,  8.2426e+00],\n",
      "        [ 6.1934e+02,  3.9836e+02,  2.2068e+02, -2.8839e+03,  5.2828e+02,\n",
      "          1.0084e+03, -2.1075e+04,  1.6838e+02],\n",
      "        [ 3.8660e+02,  1.4145e+02,  4.4013e+01,  1.4097e+04,  1.0248e+02,\n",
      "          4.6747e+02, -1.2414e+04,  2.4968e+02],\n",
      "        [-9.8269e+02, -6.1839e+02, -3.3800e+02,  2.2772e+03, -8.1112e+02,\n",
      "         -1.5806e+03,  3.3569e+04, -2.8071e+02]])\n",
      "fc2.weight grad: tensor([[ 7.1723e+03,  7.4911e+03,  7.9294e+03, -6.9775e+05,  2.3091e+04,\n",
      "          1.2238e+04, -2.6518e+04,  5.1218e+03],\n",
      "        [-2.1991e+03, -2.2963e+03, -2.4316e+03,  2.1392e+05, -7.0761e+03,\n",
      "         -3.7511e+03,  8.1271e+03, -1.5719e+03],\n",
      "        [ 5.6372e+02,  5.8898e+02,  6.2361e+02, -5.4747e+04,  1.8072e+03,\n",
      "          9.6158e+02, -2.1293e+03,  4.0703e+02],\n",
      "        [-1.9579e+03, -2.0438e+03, -2.1630e+03,  1.9090e+05, -6.3372e+03,\n",
      "         -3.3415e+03,  7.0296e+03, -1.3782e+03],\n",
      "        [ 2.8095e+02,  2.9322e+02,  3.1007e+02, -2.7459e+04,  9.1502e+02,\n",
      "          4.7986e+02, -9.7958e+02,  1.9458e+02],\n",
      "        [-2.6404e+03, -2.7588e+03, -2.9200e+03,  2.5658e+05, -8.4787e+03,\n",
      "         -4.5052e+03,  9.9098e+03, -1.8987e+03],\n",
      "        [-2.1609e+03, -2.2589e+03, -2.3928e+03,  2.0926e+05, -6.8789e+03,\n",
      "         -3.6842e+03,  8.4439e+03, -1.5883e+03],\n",
      "        [ 4.0865e+03,  4.2686e+03,  4.5200e+03, -3.9709e+05,  1.3117e+04,\n",
      "          6.9704e+03, -1.5320e+04,  2.9406e+03]])\n",
      "Episode 49: Total Return: -0.241, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.5006e+02, -1.7933e+02, -1.4382e+02,  5.1304e+03, -9.0531e+02,\n",
      "         -3.0808e+02,  5.7030e+02, -1.6534e+02],\n",
      "        [ 4.1707e+01,  4.9957e+01,  4.0071e+01, -1.4317e+03,  2.5262e+02,\n",
      "          8.6117e+01, -1.5809e+02,  4.6021e+01],\n",
      "        [-8.7985e+00, -1.0672e+01, -8.5775e+00,  3.0923e+02, -5.4556e+01,\n",
      "         -1.8765e+01,  3.2793e+01, -9.7804e+00],\n",
      "        [ 3.9239e+01,  4.6166e+01,  3.6917e+01, -1.3015e+03,  2.2973e+02,\n",
      "          7.7262e+01, -1.5227e+02,  4.2848e+01],\n",
      "        [-2.1410e+00, -2.2215e+00, -1.7325e+00,  5.4666e+01, -9.6730e+00,\n",
      "         -2.8670e+00,  9.5879e+00, -2.1790e+00],\n",
      "        [ 4.9239e+01,  5.9282e+01,  4.7614e+01, -1.7079e+03,  3.0135e+02,\n",
      "          1.0310e+02, -1.8520e+02,  5.4486e+01],\n",
      "        [ 3.4948e+01,  4.3186e+01,  3.4831e+01, -1.2724e+03,  2.2442e+02,\n",
      "          7.8165e+01, -1.2678e+02,  3.9270e+01],\n",
      "        [-8.4124e+01, -1.0130e+02, -8.1346e+01,  2.9179e+03, -5.1484e+02,\n",
      "         -1.7618e+02,  3.1648e+02, -9.3110e+01]])\n",
      "fc2.weight grad: tensor([[-1254.6647, -1058.7432, -1006.5405, 17709.8652, -2610.8542, -1079.5942,\n",
      "         -1102.9269, -1242.7974],\n",
      "        [  423.7080,   358.5060,   339.7500, -5945.8799,   887.7758,   366.4598,\n",
      "           375.2971,   422.0630],\n",
      "        [ -181.2136,  -239.6470,  -224.6723,   110.1283,  -738.4404,  -396.9095,\n",
      "          -379.6424,  -241.1327],\n",
      "        [  302.3438,   256.2171,   241.5032, -4229.7202,   634.0790,   260.2465,\n",
      "           267.8771,   302.5622],\n",
      "        [ -124.2291,  -105.5782,  -100.8299,  1724.2542,  -266.1409,  -111.3992,\n",
      "          -113.0613,  -124.2736],\n",
      "        [  453.4551,   382.0168,   364.9364, -6421.7251,   941.9730,   391.4167,\n",
      "           398.0951,   447.1181],\n",
      "        [  261.4922,   217.5443,   210.6173, -3803.4685,   525.1423,   219.6441,\n",
      "           221.0769,   251.2197],\n",
      "        [ -751.0047,  -633.0016,  -602.8461, 10626.7451, -1558.6830,  -645.3380,\n",
      "          -658.3221,  -741.9917]])\n",
      "fc2.weight grad: tensor([[ -2221.6287,  -1596.6790,  -1614.3552,  32246.0664,  -4131.2480,\n",
      "          -1364.6908,  -1345.9767,  -1689.3613],\n",
      "        [   769.4892,    555.4537,    562.1542, -11088.1641,   1452.3422,\n",
      "            482.6588,    475.4159,    588.9983],\n",
      "        [  -401.9158,   -329.9453,   -453.1997,    416.2868,  -1454.5081,\n",
      "           -585.8969,   -465.5835,   -342.6537],\n",
      "        [   537.9276,    388.5832,    393.6091,  -7733.7173,   1019.9631,\n",
      "            339.9006,    334.4091,    412.2872],\n",
      "        [  -271.3446,   -198.2024,   -200.9308,   3838.1284,   -531.2513,\n",
      "           -178.8851,   -175.8357,   -211.3619],\n",
      "        [   822.7878,    590.8998,    597.0060, -11967.1465,   1523.4955,\n",
      "            501.9964,    495.6189,    624.8610],\n",
      "        [   456.1040,    320.5325,    322.2728,  -6866.7827,    782.6535,\n",
      "            249.4925,    248.1233,    335.1838],\n",
      "        [ -1328.2498,   -953.1534,   -963.2657,  19330.7148,  -2456.2268,\n",
      "           -809.3929,   -798.7954,  -1007.6638]])\n",
      "Episode 50: Total Return: 0.236, Epsilon: 0.30\n",
      "Episode 1: Total Return: -0.025, Epsilon: 0.30\n",
      "Episode 2: Total Return: -0.028, Epsilon: 0.30\n",
      "Episode 3: Total Return: 0.073, Epsilon: 0.30\n",
      "Episode 4: Total Return: 0.061, Epsilon: 0.30\n",
      "Episode 5: Total Return: 0.040, Epsilon: 0.30\n",
      "Episode 6: Total Return: -0.115, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ -314.6788,  -303.2322,  -368.9720,  3757.7151, -1115.8578,  -378.8777,\n",
      "          -243.5385,  -162.9741],\n",
      "        [   98.5828,    95.1665,   115.8023, -1185.1084,   352.2084,   119.4368,\n",
      "            76.9472,    51.2867],\n",
      "        [  -10.5611,   -10.3670,   -12.6306,   133.1646,   -39.7692,   -13.3768,\n",
      "            -8.7342,    -5.6520],\n",
      "        [   63.5073,    61.1211,    74.3043,  -765.0565,   227.6160,    77.1026,\n",
      "            49.8250,    33.2194],\n",
      "        [   -9.3157,    -9.2765,   -11.3085,   123.0871,   -36.9468,   -12.3279,\n",
      "            -8.1625,    -5.1428],\n",
      "        [  116.7210,   112.7093,   137.2271, -1392.7301,   413.3146,   140.4196,\n",
      "            90.1001,    60.2625],\n",
      "        [   84.0710,    80.4080,    97.8393,  -973.6101,   287.9637,    98.3698,\n",
      "            62.5353,    42.6280],\n",
      "        [ -195.4142,  -188.1981,  -229.0180,  2325.1003,  -690.0695,  -234.4856,\n",
      "          -150.4996,  -100.9159]])\n",
      "Episode 7: Total Return: -0.084, Epsilon: 0.30\n",
      "Episode 8: Total Return: -0.015, Epsilon: 0.30\n",
      "Episode 9: Total Return: 0.096, Epsilon: 0.30\n",
      "Episode 10: Total Return: 0.008, Epsilon: 0.30\n",
      "Episode 11: Total Return: -0.006, Epsilon: 0.30\n",
      "Episode 12: Total Return: 0.021, Epsilon: 0.30\n",
      "Episode 13: Total Return: 0.022, Epsilon: 0.30\n",
      "Episode 14: Total Return: -0.119, Epsilon: 0.30\n",
      "Episode 15: Total Return: -0.054, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-5.8815e+08,  4.2184e+06,  7.4187e+06,  1.2175e+07,  1.2902e+07,\n",
      "         -1.3003e+08,  1.3091e+07,  1.9176e+07],\n",
      "        [ 2.0824e+08, -1.5506e+06, -2.6074e+06, -4.1135e+06, -4.6542e+06,\n",
      "          3.3950e+07, -4.2313e+06, -6.6109e+06],\n",
      "        [-2.4594e+05,  2.6198e+03,  2.8089e+03,  2.2002e+03,  6.7672e+03,\n",
      "          1.2364e+05, -5.2108e+02,  5.4362e+03],\n",
      "        [ 1.4454e+08, -1.1264e+06, -1.7923e+06, -2.6926e+06, -3.3187e+06,\n",
      "          1.3470e+07, -2.5920e+06, -4.4467e+06],\n",
      "        [-2.6933e+07,  2.0575e+05,  3.3516e+05,  5.1936e+05,  6.1585e+05,\n",
      "         -3.5516e+06,  5.1533e+05,  8.4603e+05],\n",
      "        [ 2.2347e+08, -1.5412e+06, -2.8399e+06, -4.8318e+06, -4.8011e+06,\n",
      "          6.2110e+07, -5.4032e+06, -7.4687e+06],\n",
      "        [ 1.2564e+08, -6.4119e+05, -1.6724e+06, -3.5050e+06, -2.3688e+06,\n",
      "          8.3136e+07, -4.6415e+06, -4.9161e+06],\n",
      "        [-3.3823e+08,  2.3273e+06,  4.2993e+06,  7.3472e+06,  7.2758e+06,\n",
      "         -9.5907e+07,  8.2304e+06,  1.1342e+07]])\n",
      "Episode 16: Total Return: 0.045, Epsilon: 0.30\n",
      "Episode 17: Total Return: 0.063, Epsilon: 0.30\n",
      "Episode 18: Total Return: -0.049, Epsilon: 0.30\n",
      "Episode 19: Total Return: -0.029, Epsilon: 0.30\n",
      "Episode 20: Total Return: -0.054, Epsilon: 0.30\n",
      "Episode 21: Total Return: 0.106, Epsilon: 0.30\n",
      "Episode 22: Total Return: -0.035, Epsilon: 0.30\n",
      "Episode 23: Total Return: 0.034, Epsilon: 0.30\n",
      "Episode 24: Total Return: -0.063, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.2900e+07,  4.9048e+05,  9.8578e+05,  4.5437e+05,  6.9482e+05,\n",
      "         -3.6499e+06,  1.7109e+06,  1.2309e+06],\n",
      "        [ 4.3323e+06, -1.6339e+05, -3.2825e+05, -1.4570e+05, -2.3070e+05,\n",
      "          1.1480e+06, -5.6348e+05, -4.0465e+05],\n",
      "        [-9.2109e+03,  2.8575e+02,  5.6691e+02, -1.2176e+01,  3.6704e+02,\n",
      "          1.2029e+03,  6.7876e+02,  4.5304e+02],\n",
      "        [ 3.0283e+06, -1.1266e+05, -2.2611e+05, -9.3656e+04, -1.5812e+05,\n",
      "          7.0941e+05, -3.8062e+05, -2.7249e+05],\n",
      "        [-4.4124e+05,  1.4978e+04,  2.9910e+04,  6.1780e+03,  2.0176e+04,\n",
      "         -1.9012e+04,  4.3438e+04,  3.0257e+04],\n",
      "        [ 4.9666e+06, -1.8996e+05, -3.8201e+05, -1.8103e+05, -2.6984e+05,\n",
      "          1.4750e+06, -6.6863e+05, -4.8161e+05],\n",
      "        [ 3.3240e+06, -1.3195e+05, -2.6585e+05, -1.4619e+05, -1.9019e+05,\n",
      "          1.2699e+06, -4.8779e+05, -3.5399e+05],\n",
      "        [-7.7659e+06,  2.9694e+05,  5.9706e+05,  2.8242e+05,  4.2169e+05,\n",
      "         -2.2983e+06,  1.0443e+06,  7.5223e+05]])\n",
      "Episode 25: Total Return: -0.099, Epsilon: 0.30\n",
      "Episode 26: Total Return: -0.030, Epsilon: 0.30\n",
      "Episode 27: Total Return: -0.009, Epsilon: 0.30\n",
      "Episode 28: Total Return: -0.013, Epsilon: 0.30\n",
      "Episode 29: Total Return: 0.085, Epsilon: 0.30\n",
      "Episode 30: Total Return: -0.039, Epsilon: 0.30\n",
      "Episode 31: Total Return: 0.023, Epsilon: 0.30\n",
      "Episode 32: Total Return: -0.093, Epsilon: 0.30\n",
      "Episode 33: Total Return: 0.115, Epsilon: 0.30\n",
      "Episode 34: Total Return: 0.014, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 8.6885e+07, -1.2887e+06, -3.9251e+06, -3.8417e+06, -1.9728e+06,\n",
      "          2.6824e+06, -5.4200e+06, -4.8521e+06],\n",
      "        [-2.9870e+07,  4.3990e+05,  1.3543e+06,  1.3142e+06,  6.7597e+05,\n",
      "         -8.7812e+05,  1.8616e+06,  1.6563e+06],\n",
      "        [ 1.4297e+05, -2.0434e+03, -6.5741e+03, -6.1655e+03, -3.1877e+03,\n",
      "          3.3913e+03, -8.8966e+03, -7.7145e+03],\n",
      "        [-2.1250e+07,  3.0719e+05,  9.7244e+05,  9.2311e+05,  4.7670e+05,\n",
      "         -5.4541e+05,  1.3218e+06,  1.1573e+06],\n",
      "        [ 3.7641e+06, -4.9481e+04, -1.8005e+05, -1.5329e+05, -8.0926e+04,\n",
      "          2.7353e+04, -2.3151e+05, -1.8657e+05],\n",
      "        [-3.3640e+07,  5.0280e+05,  1.5139e+06,  1.4952e+06,  7.6669e+05,\n",
      "         -1.0901e+06,  2.0998e+06,  1.8923e+06],\n",
      "        [-2.1469e+07,  3.3468e+05,  9.4449e+05,  9.8277e+05,  4.9919e+05,\n",
      "         -8.8823e+05,  1.3471e+06,  1.2588e+06],\n",
      "        [ 5.1462e+07, -7.6859e+05, -2.3167e+06, -2.2863e+06, -1.1724e+06,\n",
      "          1.6611e+06, -3.2124e+06, -2.8930e+06]])\n",
      "Episode 35: Total Return: 0.029, Epsilon: 0.30\n",
      "Episode 36: Total Return: 0.035, Epsilon: 0.30\n",
      "Episode 37: Total Return: 0.007, Epsilon: 0.30\n",
      "Episode 38: Total Return: 0.047, Epsilon: 0.30\n",
      "Episode 39: Total Return: 0.046, Epsilon: 0.30\n",
      "Episode 40: Total Return: 0.021, Epsilon: 0.30\n",
      "Episode 41: Total Return: -0.050, Epsilon: 0.30\n",
      "Episode 42: Total Return: -0.039, Epsilon: 0.30\n",
      "Episode 43: Total Return: 0.014, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-9.1867e+07,  1.0187e+06, -6.3378e+07,  3.9162e+06,  1.3622e+06,\n",
      "          1.3800e+06,  3.8778e+06,  6.0165e+06],\n",
      "        [ 2.8761e+07, -3.4120e+05,  2.1513e+07, -1.3012e+06, -4.3437e+05,\n",
      "         -4.2230e+05, -1.2783e+06, -2.0006e+06],\n",
      "        [-4.0906e+06,  4.5969e+04,  8.5367e+03,  2.7929e+04,  8.2495e+04,\n",
      "          3.4057e+04, -3.0556e+04,  7.2717e+04],\n",
      "        [ 1.4686e+07, -2.1802e+05,  1.4271e+07, -8.1213e+05, -2.3734e+05,\n",
      "         -1.9648e+05, -7.7922e+05, -1.2515e+06],\n",
      "        [ 5.0412e+06, -7.4174e+03, -7.5454e+04, -5.7795e+04, -4.5759e+04,\n",
      "         -9.6573e+04, -9.4935e+04, -9.3117e+04],\n",
      "        [ 4.0340e+07, -4.1942e+05,  2.5731e+07, -1.6253e+06, -5.8817e+05,\n",
      "         -6.1816e+05, -1.6219e+06, -2.4954e+06],\n",
      "        [ 3.9902e+07, -3.3173e+05,  1.9218e+07, -1.3274e+06, -5.5232e+05,\n",
      "         -6.4783e+05, -1.3644e+06, -2.0317e+06],\n",
      "        [-5.9931e+07,  6.2383e+05, -3.8284e+07,  2.4172e+06,  8.7412e+05,\n",
      "          9.1808e+05,  2.4119e+06,  3.7110e+06]])\n",
      "Episode 44: Total Return: 0.024, Epsilon: 0.30\n",
      "Episode 45: Total Return: 0.051, Epsilon: 0.30\n",
      "Episode 46: Total Return: -0.061, Epsilon: 0.30\n",
      "Episode 47: Total Return: 0.044, Epsilon: 0.30\n",
      "Episode 48: Total Return: -0.086, Epsilon: 0.30\n",
      "Episode 49: Total Return: 0.005, Epsilon: 0.30\n",
      "Episode 50: Total Return: 0.023, Epsilon: 0.30\n",
      "Episode 1: Total Return: -0.012, Epsilon: 0.30\n",
      "Episode 2: Total Return: 0.069, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 2.8694e+06, -8.1108e+04,  2.4601e+06, -2.3915e+05, -1.0048e+05,\n",
      "         -6.4484e+04, -3.6452e+05, -4.5709e+05],\n",
      "        [-1.0078e+06,  2.8815e+04, -8.9207e+05,  8.5917e+04,  3.5614e+04,\n",
      "          2.2905e+04,  1.3017e+05,  1.6296e+05],\n",
      "        [ 2.7620e+03, -2.7304e+01,  3.4027e+03, -2.7936e+02, -8.0498e+01,\n",
      "         -2.6906e+01, -2.1569e+02, -3.7977e+02],\n",
      "        [-6.4824e+05,  2.0035e+04, -7.0256e+05,  6.4079e+04,  2.4385e+04,\n",
      "          1.5919e+04,  9.3559e+04,  1.1592e+05],\n",
      "        [-7.9264e+01,  1.0459e+02,  1.5882e+03, -1.1226e+02,  1.6830e+02,\n",
      "         -1.5246e+02,  3.7514e+01,  2.0940e+02],\n",
      "        [-1.2114e+06,  3.3238e+04, -9.5204e+05,  9.5042e+04,  4.1433e+04,\n",
      "          2.6421e+04,  1.4729e+05,  1.8553e+05],\n",
      "        [-9.1915e+05,  2.2708e+04, -5.0722e+05,  5.7381e+04,  2.8962e+04,\n",
      "          1.8071e+04,  9.5323e+04,  1.2221e+05],\n",
      "        [ 1.7426e+06, -4.7887e+04,  1.3763e+06, -1.3718e+05, -5.9673e+04,\n",
      "         -3.8073e+04, -2.1239e+05, -2.6745e+05]])\n",
      "Episode 3: Total Return: 0.051, Epsilon: 0.30\n",
      "Episode 4: Total Return: -0.002, Epsilon: 0.30\n",
      "Episode 5: Total Return: -0.137, Epsilon: 0.30\n",
      "Episode 6: Total Return: -0.110, Epsilon: 0.30\n",
      "Episode 7: Total Return: -0.074, Epsilon: 0.30\n",
      "Episode 8: Total Return: -0.020, Epsilon: 0.30\n",
      "Episode 9: Total Return: 0.011, Epsilon: 0.30\n",
      "Episode 10: Total Return: -0.005, Epsilon: 0.30\n",
      "Episode 11: Total Return: -0.056, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 6.0062e+05,  1.5753e+05, -1.0425e+07,  6.7102e+05,  2.5383e+05,\n",
      "          7.6551e+05, -1.9193e+04,  7.7252e+05],\n",
      "        [-1.7121e+05, -4.5143e+04,  3.0080e+06, -1.8692e+05, -7.3259e+04,\n",
      "         -2.1982e+05,  3.8712e+03, -2.2432e+05],\n",
      "        [ 5.8686e+05,  9.8431e+03, -4.3496e+04,  2.0091e+06, -1.5731e+04,\n",
      "         -6.4913e+03, -1.2293e+04, -3.3874e+04],\n",
      "        [-1.0159e+05, -2.5804e+04,  1.8696e+06, -8.3779e+04, -4.5552e+04,\n",
      "         -1.2839e+05, -9.8644e+03, -1.4962e+05],\n",
      "        [-3.2346e+06,  3.8367e+04,  1.4527e+05, -7.3232e+06,  5.5378e+04,\n",
      "          9.2571e+04,  8.3231e+04,  1.6610e+05],\n",
      "        [-1.7683e+05, -4.7022e+04,  3.0528e+06, -2.0784e+05, -7.4333e+04,\n",
      "         -2.2748e+05,  1.0501e+04, -2.2219e+05],\n",
      "        [-1.0130e+05, -2.7735e+04,  1.5570e+06, -1.6480e+05, -3.7842e+04,\n",
      "         -1.2957e+05,  2.5753e+04, -9.6283e+04],\n",
      "        [ 3.7238e+05,  9.8579e+04, -6.3951e+06,  4.3928e+05,  1.5569e+05,\n",
      "          4.7672e+05, -2.2385e+04,  4.6507e+05]])\n",
      "Episode 12: Total Return: -0.018, Epsilon: 0.30\n",
      "Episode 13: Total Return: -0.023, Epsilon: 0.30\n",
      "Episode 14: Total Return: 0.066, Epsilon: 0.30\n",
      "Episode 15: Total Return: 0.003, Epsilon: 0.30\n",
      "Episode 16: Total Return: -0.001, Epsilon: 0.30\n",
      "Episode 17: Total Return: 0.017, Epsilon: 0.30\n",
      "Episode 18: Total Return: 0.055, Epsilon: 0.30\n",
      "Episode 19: Total Return: 0.019, Epsilon: 0.30\n",
      "Episode 20: Total Return: 0.052, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ -300875.8438,  -466152.3750,  -139647.7500, -1348008.1250,\n",
      "          -290815.0312,  -482332.5625,  -274927.1250,  -958323.1250],\n",
      "        [   23237.2207,   387346.5000,    -9688.0986,   351751.7188,\n",
      "           -16469.9570,   -68540.6797,    21204.6230,    35186.6758],\n",
      "        [    3237.5139,  -189608.5156,    44554.1680, -2385667.2500,\n",
      "            44673.3672,    41712.1250,    39759.1367,    40575.3086],\n",
      "        [   58102.4102,   151895.0781,    29689.9199,   241290.4375,\n",
      "            60860.7812,   106579.8203,    44948.9961,   179312.6562],\n",
      "        [  -33847.3086,   -41873.9492,   -15302.7559,  -155730.6250,\n",
      "           -32037.9688,   -52158.9922,   -32475.8945,  -109268.8359],\n",
      "        [   25779.1875,   362893.7188,    -9639.8994,   370835.1250,\n",
      "           -15953.6953,   -70044.2500,    27133.3906,    45984.3320],\n",
      "        [   19720.4980,    78986.9141,    -4118.9062,   228851.6250,\n",
      "            -5349.6128,   -36131.3633,    31934.1719,    56638.0547],\n",
      "        [  -44341.3203,  -671652.5000,    17394.1172,  -653582.4375,\n",
      "            29111.3926,   124989.2891,   -44419.8477,   -74720.9062]])\n",
      "Episode 21: Total Return: 0.006, Epsilon: 0.30\n",
      "Episode 22: Total Return: -0.058, Epsilon: 0.30\n",
      "Episode 23: Total Return: 0.055, Epsilon: 0.30\n",
      "Episode 24: Total Return: 0.082, Epsilon: 0.30\n",
      "Episode 25: Total Return: 0.000, Epsilon: 0.30\n",
      "Episode 26: Total Return: -0.121, Epsilon: 0.30\n",
      "Episode 27: Total Return: -0.000, Epsilon: 0.30\n",
      "Episode 28: Total Return: 0.065, Epsilon: 0.30\n",
      "Episode 29: Total Return: -0.037, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-1.5923e+06, -1.4850e+05, -3.4430e+04,  8.3989e+05,  2.6195e+04,\n",
      "         -1.7399e+04, -6.2917e+04, -2.4276e+05],\n",
      "        [ 5.9992e+05,  5.8116e+04,  1.3375e+04, -2.9822e+05, -9.7561e+03,\n",
      "          7.7171e+03,  2.9546e+04,  1.0107e+05],\n",
      "        [-3.0041e+05, -1.2987e+05, -3.8314e+04,  3.7943e+06, -4.4615e+04,\n",
      "         -4.5359e+04,  2.1544e+03,  3.4805e+04],\n",
      "        [ 3.9061e+05,  1.7021e+04,  5.2480e+03, -3.4572e+05, -7.4271e+03,\n",
      "         -5.0239e+03, -3.1681e+04, -1.7726e+04],\n",
      "        [-1.2897e+05, -1.7292e+04, -3.7017e+03,  2.7520e+04,  1.8487e+03,\n",
      "         -4.0536e+03, -1.8456e+04, -4.1599e+04],\n",
      "        [ 5.8379e+05,  6.3019e+04,  1.4091e+04, -2.4303e+05, -9.1597e+03,\n",
      "          1.0635e+04,  4.4589e+04,  1.2433e+05],\n",
      "        [ 1.8578e+05,  3.7785e+04,  7.3271e+03,  4.5758e+04, -2.0025e+03,\n",
      "          1.1660e+04,  5.6233e+04,  1.0848e+05],\n",
      "        [-1.0589e+06, -1.0186e+05, -2.3454e+04,  5.3360e+05,  1.7259e+04,\n",
      "         -1.3181e+04, -4.9958e+04, -1.7478e+05]])\n",
      "Episode 30: Total Return: -0.021, Epsilon: 0.30\n",
      "Episode 31: Total Return: 0.044, Epsilon: 0.30\n",
      "Episode 32: Total Return: -0.039, Epsilon: 0.30\n",
      "Episode 33: Total Return: -0.132, Epsilon: 0.30\n",
      "Episode 34: Total Return: -0.119, Epsilon: 0.30\n",
      "Episode 35: Total Return: -0.007, Epsilon: 0.30\n",
      "Episode 36: Total Return: -0.052, Epsilon: 0.30\n",
      "Episode 37: Total Return: 0.011, Epsilon: 0.30\n",
      "Episode 38: Total Return: -0.047, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[ 4.3790e+03,  1.0362e+04,  3.8784e+03,  1.2453e+05,  2.8654e+03,\n",
      "          6.1631e+03,  1.1362e+04,  3.3018e+04],\n",
      "        [-1.7114e+03, -4.0347e+03, -1.5389e+03, -4.7315e+04, -1.2195e+03,\n",
      "         -2.4936e+03, -4.5874e+03, -1.3040e+04],\n",
      "        [ 3.6814e+02,  1.8111e+02,  4.0125e+02, -2.3024e+04,  4.7127e+02,\n",
      "          4.5516e+02,  5.0165e+02,  4.6249e+02],\n",
      "        [-3.7855e+02, -9.6403e+02, -2.3270e+02, -1.6839e+04,  1.9279e+02,\n",
      "         -1.5817e+02, -3.3556e+02, -2.2618e+03],\n",
      "        [-4.3227e+01, -1.0239e+02, -3.6939e+01, -1.2791e+03, -2.2369e+01,\n",
      "         -5.5570e+01, -1.0228e+02, -3.1429e+02],\n",
      "        [-1.8485e+03, -4.3394e+03, -1.6901e+03, -4.9459e+04, -1.4371e+03,\n",
      "         -2.7953e+03, -5.1311e+03, -1.4247e+04],\n",
      "        [-9.3408e+02, -2.1515e+03, -9.1448e+02, -2.1374e+04, -9.8556e+02,\n",
      "         -1.6328e+03, -2.9720e+03, -7.5433e+03],\n",
      "        [ 3.2818e+03,  7.7490e+03,  2.9324e+03,  9.1826e+04,  2.2584e+03,\n",
      "          4.7134e+03,  8.6789e+03,  2.4897e+04]])\n",
      "Episode 39: Total Return: -0.046, Epsilon: 0.30\n",
      "Episode 40: Total Return: -0.068, Epsilon: 0.30\n",
      "Episode 41: Total Return: 0.033, Epsilon: 0.30\n",
      "Episode 42: Total Return: 0.012, Epsilon: 0.30\n",
      "Episode 43: Total Return: -0.037, Epsilon: 0.30\n",
      "Episode 44: Total Return: -0.037, Epsilon: 0.30\n",
      "Episode 45: Total Return: 0.002, Epsilon: 0.30\n",
      "Episode 46: Total Return: 0.004, Epsilon: 0.30\n",
      "Episode 47: Total Return: -0.079, Epsilon: 0.30\n",
      "fc2.weight grad: tensor([[-3.1615e+02, -6.1752e+03,  6.8701e+01, -7.0652e+04,  7.7744e+02,\n",
      "         -5.2395e+02,  8.7568e+02, -1.4966e+03],\n",
      "        [ 1.2317e+02,  2.4220e+03, -2.8389e+01,  2.7914e+04, -3.1273e+02,\n",
      "          2.0465e+02, -3.4981e+02,  5.9357e+02],\n",
      "        [ 8.6864e+02, -7.0708e+03,  6.5153e+02, -8.3609e+04,  1.2462e+03,\n",
      "         -1.5146e+02,  1.6287e+03, -3.7828e+02],\n",
      "        [ 5.6264e+01,  9.9437e+02, -1.3618e+00,  1.0081e+04, -7.6646e+01,\n",
      "          9.0458e+01, -1.0136e+02,  2.0127e+02],\n",
      "        [-8.0028e+01, -3.6517e+02, -2.4911e+01, -6.3061e+02, -3.9130e+00,\n",
      "         -1.7615e+01, -2.2036e+01, -8.7629e+01],\n",
      "        [ 1.2301e+02,  2.4448e+03, -3.1044e+01,  2.8496e+04, -3.2761e+02,\n",
      "          2.0508e+02, -3.6286e+02,  6.0892e+02],\n",
      "        [ 3.3767e+01,  7.3229e+02, -1.4741e+01,  9.2859e+03, -1.2671e+02,\n",
      "          5.8145e+01, -1.3200e+02,  2.0626e+02],\n",
      "        [-2.4653e+02, -4.8096e+03,  5.2722e+01, -5.4966e+04,  6.0404e+02,\n",
      "         -4.0882e+02,  6.8076e+02, -1.1653e+03]])\n",
      "Episode 48: Total Return: 0.033, Epsilon: 0.30\n",
      "Episode 49: Total Return: 0.079, Epsilon: 0.30\n",
      "Episode 50: Total Return: -0.023, Epsilon: 0.30\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "input_size = 7\n",
    "output_size = 3 \n",
    "learning_rate = 0.9\n",
    "discount_factor = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.9995\n",
    "\n",
    "env = PairTradeEnv(workingPairOutcome, top_keys, validPairsList, return_df)\n",
    "agent = QLearningAgent(input_size, output_size, learning_rate, discount_factor, epsilon, epsilon_decay)\n",
    "\n",
    "## Training constants\n",
    "total_episodes = 50\n",
    "total_epoch = 3\n",
    "number_of_pairs = len(workingPairOutcome)\n",
    "ls_epo_train_reward = []\n",
    "ls_epo_test_reward = []\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    ls_epi_reward = []\n",
    "    for episode in range(total_episodes):\n",
    "        arr_pair_reward = np.zeros(number_of_pairs)\n",
    "\n",
    "        for pair_idx in range(number_of_pairs):\n",
    "            state = env.reset(pair_idx)\n",
    "            pair_reward = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                action = agent.choose_action(state)\n",
    "                next_state, reward, done, _ = env.step(action, pair_idx)\n",
    "                pair_reward += reward\n",
    "                reward *= 5\n",
    "\n",
    "                agent.store_experience(state, action, reward, next_state, done)\n",
    "                agent.learn()\n",
    "                \n",
    "                state = next_state\n",
    "\n",
    "            arr_pair_reward[pair_idx] = pair_reward\n",
    "        \n",
    "        total_reward = arr_pair_reward.mean()\n",
    "        print(f\"Episode {episode+1}: Total Return: {total_reward:.3f}, Epsilon: {agent.epsilon:.2f}\")\n",
    "        ls_epi_reward.append(total_reward)\n",
    "\n",
    "        plt.plot(ls_epi_reward)\n",
    "\n",
    "    agent.q_network.eval()\n",
    "    agent.target_network.eval()\n",
    "\n",
    "    ls_epo_train_reward.append(evaluate_agent_train(agent, env, number_of_pairs))\n",
    "    ls_epo_test_reward.append(evaluate_agent_test(agent, env, number_of_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "3\n",
      "0.9\n",
      "0.99\n",
      "1.0\n",
      "0.9995\n",
      "3\n",
      "50\n",
      "Evaluation: Average Total Train Return:[-0.06490984734068209, 0.09539002653632332, 0.010519322236009676]\n",
      "Evaluation: Average Total Train Return: mean 0.0137, SD 0.0655\n",
      "Evaluation: Average Total Test Return: [-0.061122772836067416, 0.09539002653632332, 0.010519322236009676]\n",
      "Evaluation: Average Total Test Return: mean 0.0149, SD 0.0640\n"
     ]
    }
   ],
   "source": [
    "ls_print = [\n",
    "    input_size,\n",
    "    output_size,\n",
    "    learning_rate,\n",
    "    discount_factor,\n",
    "    epsilon,\n",
    "    epsilon_decay,\n",
    "    total_epoch,\n",
    "    total_episodes\n",
    "    ]\n",
    "for i, p in enumerate(ls_print):\n",
    "    print(f\"{p}\")\n",
    "print(f\"Evaluation: Average Total Train Return:{ls_epo_train_reward}\")\n",
    "print(f\"Evaluation: Average Total Train Return: mean {np.array(ls_epo_train_reward).mean():.4f}, SD {np.array(ls_epo_train_reward).std():.4f}\")\n",
    "print(f\"Evaluation: Average Total Test Return: {ls_epo_test_reward}\")\n",
    "print(f\"Evaluation: Average Total Test Return: mean {np.array(ls_epo_test_reward).mean():.4f}, SD {np.array(ls_epo_test_reward).std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# After training, save the entire Q-network\n",
    "torch.save(agent.q_network, 'q_network.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 Dec\n",
    "- revert to **v20241210_0**, verify result is with reward modification\n",
    "    - **v20241211_0** epsilon update after 2000, modified reward *5 positive / -1 else, update target every 2000 learn occurences ==> ***total reward: 0.44***\n",
    "- revert to **v20241210_0**, verify result \n",
    "    - without reward modification, ensure update network 1000 learn occ. 3 episodes only, epsilon_decay = 0.93 ==> still doing short only\n",
    "- experimenting with one episode and get the q-values:\n",
    "    - 1 episode has very even Q value across all actions ==> Q values all 0 (18 mins)\n",
    "    - 1 episode try with reward shaping max(1,reward*5) positive else -1 ==> all shorting emphasise Short term rewards too much(18 mins)\n",
    "    - 1 episode try with reward shaping reward*5 if positive else -1 ==> all shorting still\n",
    "    - 1 episode try with reward shaping reward if positive else -1 to reward ==> all shorting still\n",
    "    - 1 episode try with reward shaping reward if positive elif <0 -1 to reward ==> all flat\n",
    "    - 1 episode try with reward shaping 2*reward if positive elif <0 -1 to reward ==> all flat\n",
    "    - 1 episode try with reward shaping 5*reward if positive elif <0 -1 to reward ==> all flat\n",
    "    - 1 episode try with reward shaping +1 reward if positive elif <0 -1 to reward ==> all short\n",
    "- add back spread as one continuous variable for DQN\n",
    "    - use ***v20241211_1*** architecture except. learning rate: .3, eps decay: 0.9885, episode: 1, learn every 100 occ, 4x4, ADAM, disc factor: .99 ==> Q-values are different! but seems it is too underfit.. mark this as first 7 input version with some fitting. mark this as ***v20241211_2***\n",
    "    - v20241211_2 but with learning rate: .9 ==> learning rate too high, oscillating for one gradient from 0 to non-zero through training period\n",
    "    - v20241211_2 but with learning rate: .5 ==> still underfit as both test and train are negative but small returns\n",
    "    - v20241211_2 to overcome the underfitting in both previous scenarios plan to increase neurons and decrease learning rate.\n",
    "        - v20241211_2: 8x8 nn ==> overfit\n",
    "- seems that it is underfit rather than overfit because, it can get the general trend of mean reversion or choose a general model. First try to train more episodes before changing the params. can afford to reduce the eps decay\n",
    "\n",
    "### 14 Dec\n",
    "- update workflow to run multiple epoch to auto check consistency. did 10 episodes 2 epochs over 37 mins. not too long. \n",
    "- running large batch of 50 episodes 3 epochs to see if SD of the returns can reduce.\n",
    "- reward also observed to be -.2 to +.2 range. with very high 0 values. must find a way to reduce the peakness. for now *5 the reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_q_network = torch.load('q_network_replay1batch_32x4.pth')\n",
    "\n",
    "# loaded_q_network = QNetwork(6,3)  # Replace QNetwork with your model class\n",
    "# loaded_q_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-values: tensor([[10635.8213, 10496.3545, 10516.8516],\n",
      "        [10397.9053, 10200.8037, 10308.1006],\n",
      "        [ 9393.7275,  9115.6816,  9234.6689],\n",
      "        [ 8551.4268,  9955.6133,  8750.5039],\n",
      "        [ 7553.3853,  8033.2798,  7586.3022],\n",
      "        [ 6396.4136,  7261.0469,  6552.6392]])\n",
      "Greedy actions: [-1, -1, -1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Assuming states is a list of 6 states, each a list or NumPy array\n",
    "states = [[-0.5, 0, 0, 0, 1, 0, 0],\n",
    "        [-1.5, 0, 0, 0, 1, 1, 0],\n",
    "        [-2.5, 0, 0, 0, 1, 1, 1],\n",
    "        [0.5, 0, 0, 1, 0, 0, 0],\n",
    "        [1.5, 1, 1, 1, 0, 0, 0],\n",
    "        [2.5, 1, 1, 1, 0, 0, 0]]\n",
    "\n",
    "# Convert to PyTorch tensor (ensure float32 for compatibility)\n",
    "states_tensor = torch.tensor(states, dtype=torch.float32)\n",
    "\n",
    "# Evaluate the Q-values for all states\n",
    "agent.q_network.eval()  # Set the network to evaluation mode\n",
    "with torch.no_grad():\n",
    "    q_values = agent.q_network(states_tensor)  # Output will be a tensor of shape (6, output_size)\n",
    "\n",
    "# Example: Get the greedy actions for each state\n",
    "action_indices = torch.argmax(q_values, dim=1).tolist()\n",
    "actions = [agent.index_to_action[index] for index in action_indices]\n",
    "\n",
    "print(\"Q-values:\", q_values)\n",
    "print(\"Greedy actions:\", actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-0.5, 0, 0, 0, 1, 0, 0): -1,\n",
       " (-1.5, 0, 0, 0, 1, 1, 0): -1,\n",
       " (-2.5, 0, 0, 0, 1, 1, 1): -1,\n",
       " (0.5, 0, 0, 1, 0, 0, 0): 0,\n",
       " (1.5, 1, 1, 1, 0, 0, 0): 0,\n",
       " (2.5, 1, 1, 1, 0, 0, 0): 0,\n",
       " (0, 0, 0, 0, 0, 0, 0): 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_policy_actions = dict(zip([tuple(state) for state in states], actions))\n",
    "dict_policy_actions[(0, 0, 0, 0, 0, 0, 0)] = 0\n",
    "dict_policy_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30 Nov\n",
    "- first few tries, network is very large\n",
    "- added epsilon search in \"choose_action\" functionso that there will be some chance to explore\n",
    "- changed reward function to multiply losses and give exponential returns to incentivise risk taking\n",
    "\n",
    "### 1 dec 2105: \n",
    "- might have performance is always oscillating negative and positive. This might be because of too large a learning rate. also start from start of training periods max steps to be 3000 so that total results are comparable\n",
    "    - this helped quite abit. \n",
    "    \n",
    "`\n",
    "input_size = 7  # Adjust to your specific input size\n",
    "output_size = 3  # Adjust to your desired number of discrete actions\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.8\n",
    "epsilon = 1 # down to .3\n",
    "epsilon_decay = 0.9999\n",
    "num_episodes = 500\n",
    "max_steps_per_episode = 3000\n",
    "`\n",
    "\n",
    "- want to try changing epsilon to only update after the entire episode instead of after each step. its decaying too quickly\n",
    "- I want to try with changing reward by changing \"learn\" to use total_reward instead of \"reward\"\n",
    "- Scale the states. need to explore scaling the state since it is still in terms of absolute differences. NN is not able to do proportions\n",
    "- training epochs should be smaller at up to 30 days because mean reversion pattern is 1 to 33 days\n",
    "    - very bad performance with 40 day epochs\n",
    "\n",
    "### 1 dec 2217:\n",
    "- changed target q value fxn to remove exponential reward and scaled negative reward. now both positive and negative are the same. added portion of total reward in episode to incentivise more long term rewards.\n",
    "    - `        if reward > 0:\n",
    "            target_q_value = reward + self.discount_factor * next_q_value * (1 - done) + total_reward * .1\n",
    "        else:\n",
    "            target_q_value = reward + self.discount_factor * next_q_value * (1 - done) + total_reward * .1`\n",
    "    -       `  if episode%1==0:\n",
    "            agent.epsilon *= agent.epsilon_decay`\n",
    "\n",
    "### 2 Dec 2101:\n",
    "- managed to scale but results are not any better\n",
    "- thinking of reducing learning rate to reduce the oscillations\n",
    "    - will try to run with learning rate at 0.01\n",
    "- right now total reward is taking all of the target q function. maybe can make it a 50/50 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 dec\n",
    "- training taking \n",
    "    - a full length training dataset.\n",
    "    - 1000 per learning step\n",
    "    - learning rate test (1.5 mins per episode)\n",
    "        - episodes: 5\n",
    "        - learning rate: 0.05 ==> total reward: .037\n",
    "        - learning rate: 0.5 ==> total reward: -.6\n",
    "        - learning rate: 0.3 ==> total reward: 0.88, .044\n",
    "        - learning rate: 0.15 ==> total reward: -.023\n",
    "        - learning rate: 0.25 ==> total reward: -.6\n",
    "        - learning rate: 0.35 ==> total reward: .028\n",
    "    - with drop out layer test (1.75 mins per episode)\n",
    "        - learning rate: 0.3 ==> total reward: -0.488\n",
    "        - learning rate: 0.4 ==> total reward: -0.422\n",
    "        - learning rate: 0.5 ==> total reward: .26, .13, .096\n",
    "        - learning rate: 0.6 ==> total reward: .03\n",
    "        - learning rate: 0.7 ==> total reward: -.08\n",
    "- performance still bad. should include dropout layer? --> performance a bit worse but more consistent\n",
    "- try removing spread so that the input is only boolean of SD and last position\n",
    "    - drop out layer test (1.75 mins per episode)\n",
    "        - learning rate: 0.1 ==> total reward: -.36\n",
    "        - learning rate: 0.3 ==> total reward: -.01\n",
    "        - learning rate: 0.5 ==> total reward: -.26\n",
    "### 5 dec\n",
    "- previously target and online network updated at the same time, but it should be used to regularise. So will try with updating more periodically instead of every learn step. reduced NN to 16 and 8 hidden layers with dropout (1.67 min per episode)\n",
    "    - learning rate: 0.3, update target every 10 learn occurences ==> total reward: .03\n",
    "    - learning rate: 0.3, update target every 100 learn occurences ==> total reward: .26\n",
    "    - learning rate: 0.3, update target every 500 learn occurences ==> total reward: -.383\n",
    "    - learning rate: 0.3, update target every 600 learn occurences ==> total reward: .22\n",
    "    - learning rate: 0.3, update target every 675 learn occurences ==> total reward: .41\n",
    "    - learning rate: 0.3, update target every 700 learn occurences ==> total reward: .10, .03\n",
    "    - learning rate: 0.3, update target every 750 learn occurences ==> total reward: .40, .15, -0.353\n",
    "    - learning rate: 0.3, update target every 1000 learn occurences ==> total reward: .05\n",
    "    - learning rate: 0.3, update target every 10 learn occurences, remove dropout layers ==> total reward: -.203\n",
    "    - learning rate: 0.5, update target every 10 learn occurences, remove dropout layers ==> total reward: -.334\n",
    "- changed ADAM optimiser to SGD (1.6 min per episode)\n",
    "    - learning rate: 0.15, update target every 750 learn occurences ==> total reward: .084\n",
    "    - learning rate: 0.3, update target every 750 learn occurences ==> total reward: -.20\n",
    "    - learning rate: 0.5, update target every 750 learn occurences ==> total reward: .303\n",
    "    - learning rate: 0.6, update target every 750 learn occurences ==> total reward: -.110\n",
    "    - learning rate: 0.7, update target every 750 learn occurences ==> total reward: -.556, -0.449\n",
    "- long term run with 50 episodes\n",
    "    - SGD, learning rate: 0.5, update target every 750 learn occurences ==> total reward: -.04 (79 min)\n",
    "    - ADAM, learning rate: 0.3, update target every 750 learn occurences ==> total reward: -.01 (84.5 min)\n",
    "    - ADAM, 32 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: 0.54 (88 min)\n",
    "- long term run with 300 episodes\n",
    "    - ADAM, 32X16 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward:  -0.28(540 min)\n",
    "### 6 Dec\n",
    "1. reduce to only 4 SD flags - Done\n",
    "2. discount factor up to .99 - Done\n",
    "3. try increasing punishment with X10 negative reward if less than 0 - Done\n",
    "\n",
    "- there is a positive gradient\n",
    "    - 5 episodes, X10 negative reward ADAM, 32X16 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: .05\n",
    "    - 5 episodes, X10 negative reward ADAM, 32X8 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: -0.01\n",
    "    - 5 episodes, X100 negative reward ADAM, 32X16 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: -0.01 (8 mins)\n",
    "    - 5 episodes, X100 negative reward ADAM, 32X16 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: 0.014\n",
    "    - 300 episodes, X100 negative reward ADAM, 32X16 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: 0.017\n",
    "    - 50 episodes, X100 negative reward ADAM, 32X16 hidden layer, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: \n",
    "- try reducing net to only 4 neurons\n",
    "    - 5 episodes, X100 negative reward ADAM, 4X4 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: 0.0\n",
    "    - 10 episodes, X100 negative reward ADAM, 4X4 hidden layer, learning rate: 0.3, update target every 750 learn occurences ==> total reward: 0.0\n",
    "### 8 Dec \n",
    "- 50 episodes, X100 negative reward ADAM, 4X4 hidden layer, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: 0.118\n",
    "- 300 episodes, X100 negative reward ADAM, 4X4 hidden layer, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: -0.02 (epsilon 10), 0.29 (epsilon .46)\n",
    "- try removing previous action in state space to move to 4 state spaces only . 4X4\n",
    "    - 4X4, 10 episodes, X100 negative reward ADAM, 4X4 hidden layer, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: 0.282\n",
    "    - 4X4, epsilon_decay = 0.955, 20 episodes, X100 negative reward ADAM, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: -.20\n",
    "    - 4X4, epsilon_decay = 0.9885, 20 episodes, X100 negative reward ADAM, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: 0.08\n",
    "    - 32X4, epsilon_decay = 0.9885, 20 episodes, X100 negative reward ADAM, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: 0.07\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 20 episodes, X100 negative reward ADAM, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: .21\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 10 episodes, X100 negative reward ADAM, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.5 ==> total reward: .002\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 10 episodes, X100 negative reward ADAM, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.5 ==> total reward: .002\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 300 episodes, X100 negative reward ADAM, learning rate: 0.3, update target every 750 learn occurences, discount_factor = 0.99 ==> total reward: 0.115\n",
    "### 9 Dec\n",
    "- state cases should be imbalanced\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 20 episodes,  ADAM, learning rate: 0.3, update target every 1000 learn occurences, discount_factor = 0.99 ==> total reward: -0.29\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 5 episodes,  ADAM, learning rate: 0.3, update target every 1000 learn occurences, discount_factor = 0.99 ==> total reward: 0.223\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 5 episodes, ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99 ==> total reward: 0.126\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 10 episodes,  ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99 ==> total reward: \n",
    "- changed data set to 17 pairs\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 10 episodes,  ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99 ==> total reward: -0.16\n",
    "    - 17 pairs, add back dropout layers, 32X4, epsilon_decay = 0.9885, 5 episodes,  ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99, changed reward *5 for positive, -1 for negative ==> total reward:0.06 (at least got positive gradient), try run again to get more data on consistency. also need to observe if exploiting might be necessary\n",
    "    - 17 pairs, add back dropout layers, 32X4, epsilon_decay = 0.9885, 5 episodes,  ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99, changed reward *5 for positive, -1 for negative ==> total reward:0.087 \n",
    "\n",
    "### 10 Dec\n",
    "- changed data set to 17 pairs\n",
    "    - 17 pairs, add back dropout layers, 32X4, epsilon_decay = 0.9885, 10 episodes,  ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99, changed reward *5 for positive, -1 for negative ==> total reward:-0.10 \n",
    "- no need for complicated network, reduce to 8 (5 min per ep)\n",
    "    - 17 pairs, add back dropout layers, 8X4, epsilon_decay = 0.9885, 5 episodes,  ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99, changed reward *5 for positive, -1 for negative ==> total reward: -0.113\n",
    "- try removing dropout layers\n",
    "    - 17 pairs, add back dropout layers, 8X4, epsilon_decay = 0.9885, 5 episodes,  ADAM, learning rate: 0.3, update target every 550 learn occurences, discount_factor = 0.99, changed reward *5 for positive, -1 for negative ==> total reward: 0.04\n",
    "- replay above 20241209 good result\n",
    "    - **v20241210_0** add back dropout layers, 32X4, epsilon_decay = 0.9885, 5 episodes,  ADAM, learning rate: 0.3, update target every 1000 learn occurences, discount_factor = 0.99 ==> total reward: 0.33 (20 min per episode)\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 10 episodes,  ADAM, learning rate: 0.3, update target every 1000 learn occurences, discount_factor = 0.99 ==> total reward: 0.082 at episode 5, 0.195 at episode 10 (18.5 mins per episode)\n",
    "- Think need to update the target network more frequently. might be missing the learnings from the policy network.\n",
    "    - add back dropout layers, 32X4, epsilon_decay = 0.9885, 30 episodes,  ADAM, learning rate: 0.3, update target every 50 learn occurences, discount_factor = 0.99 ==> total reward: -.11 after 28 episodes (18.5 mins per sepisode)-0.04 after 5 episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
