{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0916fd52-43ba-4d15-b2d5-05084c7e6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python calculation for the example and exercise from Lecture 4 notes\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import scipy.interpolate\n",
    "import statistics\n",
    "from statistics import NormalDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f84ea-240b-4c93-97f3-02c2828e4d62",
   "metadata": {},
   "source": [
    "<img src=\"attachment:cda85664-5f24-49cf-b6d6-af17b4e3c1ac.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0de7b21-5470-4116-9e17-88e13b5a5eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10-day 99% VaR using the parametric VaR model is equal to: 197,746\n"
     ]
    }
   ],
   "source": [
    "mu = [0.000356, 0.000267, 0.000133, 0.000153]\n",
    "sigma = [[0.00007, 0.0001, -0.000045, 0.000068],\n",
    "         [0.0001, 0.0004, -0.00008, 0.000241],\n",
    "         [-0.000045, -0.00008, 0.000178, -0.000118],\n",
    "         [0.000068, 0.000241, -0.000118, 0.000324]\n",
    "        ]\n",
    "\n",
    "mu10d = np.multiply(mu, 10)\n",
    "sigma10d = np.multiply(sigma, 10)\n",
    "w = np.array([1000000, 1000000, 1000000, 400000])\n",
    "meanL = np.inner(w, mu10d) + 2500 * (0.001 * 10) / 0.01 \n",
    "varianceL = np.dot(np.dot(w, sigma10d), np.transpose(w)) + 2500 * 2500 * 0.0005 * 0.0005 * 10\n",
    "\n",
    "var = np.abs(stat.norm.ppf(0.01, loc=meanL, scale=np.sqrt(varianceL)))\n",
    "print(f\"The 10-day 99% VaR using the parametric VaR model is equal to: {var:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8f05d-83ee-4eda-a26f-dceb306cfd15",
   "metadata": {},
   "source": [
    "<img src=\"attachment:88087327-b92c-4f3d-bdfe-bdcdfa6ebf04.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def8bac5-ec51-4b26-b766-0a0e886926fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/\"\n",
    "offset = 693594\n",
    "\n",
    "df_appl = pd.read_csv(file_path + \"AAPL.csv\").set_index('Date')\n",
    "df_appl.index = pd.to_datetime(df_appl.index).date\n",
    "df_appl = df_appl.sort_index()\n",
    "\n",
    "df_dbs = pd.read_csv(file_path + \"DBS.csv\").set_index('Date')\n",
    "df_dbs.index = pd.to_datetime(df_dbs.index).date\n",
    "df_dbs = df_dbs.sort_index()\n",
    "\n",
    "df_usdsgd = pd.read_csv(file_path + \"USDSGD.csv\").set_index('Date')\n",
    "df_usdsgd.index = pd.to_datetime(df_usdsgd.index).date\n",
    "df_usdsgd = df_usdsgd.sort_index()\n",
    "\n",
    "\n",
    "d1 = [ d.toordinal()-693594  for d in df_appl.index.tolist()]\n",
    "p1 = df_appl['Close'].tolist()\n",
    "interp1 =  scipy.interpolate.interp1d(d1, p1)\n",
    "\n",
    "d2 = [ d.toordinal()-693594  for d in df_dbs.index.tolist()]\n",
    "p2 = df_dbs['Close'].tolist()\n",
    "interp2 =  scipy.interpolate.interp1d(d2, p2)\n",
    "\n",
    "d3 = [ d.toordinal()-693594  for d in df_usdsgd.index.tolist()]\n",
    "p3 = df_usdsgd['Close'].tolist()\n",
    "interp3 =  scipy.interpolate.interp1d(d3, p3)\n",
    "\n",
    "dlist = list(set(d1) | set(d2) | set(d3))\n",
    "\n",
    "numchg = len(dlist)-1\n",
    "appl = [ interp1(dlist[i+1]).flat[0] / interp1(dlist[i]).flat[0] - 1.0  for i in range(numchg) ]\n",
    "dbs = [ interp2(dlist[i+1]).flat[0] / interp2(dlist[i]).flat[0] - 1.0  for i in range(numchg) ]\n",
    "usdsgd = [ interp3(dlist[i+1]).flat[0] / interp3(dlist[i]).flat[0] - 1.0  for i in range(numchg) ]\n",
    "\n",
    "alldata = { 'appl' : appl,\n",
    "           'dbs' : dbs,\n",
    "           'usdsgd' : usdsgd }\n",
    "\n",
    "df_all = pd.DataFrame(alldata, columns=['appl', 'dbs', 'usdsgd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fb5162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appl</th>\n",
       "      <th>dbs</th>\n",
       "      <th>usdsgd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005755</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>-0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.009002</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>-0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011274</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004810</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>-0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-0.033856</td>\n",
       "      <td>-0.006725</td>\n",
       "      <td>0.002949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>-0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>-0.001418</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>-0.023969</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.002517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appl       dbs    usdsgd\n",
       "0   -0.005755  0.000339  0.002829\n",
       "1    0.002814  0.002372 -0.000817\n",
       "2   -0.009002 -0.001014 -0.001189\n",
       "3   -0.011274 -0.000338  0.004909\n",
       "4   -0.004810  0.002370 -0.002072\n",
       "..        ...       ...       ...\n",
       "257 -0.033856 -0.006725  0.002949\n",
       "258  0.021008  0.002483 -0.005660\n",
       "259 -0.001418 -0.002251 -0.003179\n",
       "260  0.003226  0.000000  0.001632\n",
       "261 -0.023969  0.008123  0.002517\n",
       "\n",
       "[262 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0bab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Parametric VaR [1d, 99%]: 1,042,033\n",
      "Parametric VaR [10d, 99%]: 3,018,277\n",
      "============================================================================================================================\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Monte Carlo VaR:\n",
      "VaR [1d, 99%], Full Revaluation: 1,040,840\n",
      "VaR [10d, 99%], Full Revaluation: 2,945,670\n",
      "VaR [10d, 99%] using square-root-of-time rule: 3,291,424\n",
      "\n",
      "VaR [1d, 99%], Sensitivity: 1,041,422\n",
      "VaR [10d, 99%], Sensitivity: 2,862,026\n",
      "============================================================================================================================\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Historical VaR:\n",
      "VaR [1d, 99%], Full Revaluation: 1,027,655\n",
      "VaR [10d, 99%] using square-root-of-time rule: 3,249,730\n",
      "\n",
      "VaR [1d, 99%], Sensitivity: 1,028,280\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corr_mat = df_all.corr()\n",
    "cov_mat = df_all.cov()\n",
    "\n",
    "appl_mean = np.average(appl)\n",
    "appl_std = statistics.stdev(appl)\n",
    "dbs_mean = np.average(dbs)\n",
    "dbs_std = statistics.stdev(dbs)\n",
    "usdsgd_mean = np.average(usdsgd)\n",
    "usdsgd_std = statistics.stdev(usdsgd)\n",
    "\n",
    "mean_vec = np.array([appl_mean, dbs_mean, usdsgd_mean])\n",
    "\n",
    "mean10d_vec = np.array([appl_mean*10, dbs_mean*10, usdsgd_mean*10])\n",
    "cov10d_mat = (cov_mat * 10).to_numpy()\n",
    "\n",
    "\n",
    "# Parametric VaR\n",
    "usdsgd_p0 = 1.354\n",
    "appl_p0 = 227.63\n",
    "dbs_p0 = 44.68\n",
    "n_appl = 100000\n",
    "n_dbs = 200000\n",
    "w_parametric = np.array([n_appl*appl_p0*usdsgd_p0, n_dbs*dbs_p0, n_appl*appl_p0*usdsgd_p0])\n",
    "m10d = np.inner(w_parametric, mean10d_vec)\n",
    "v10d = np.inner(np.dot(w_parametric, cov10d_mat), w_parametric)\n",
    "var10d = np.abs(stat.norm.ppf(0.01, loc=m10d, scale=np.sqrt(v10d)))\n",
    "m1d =  np.inner(w_parametric, mean_vec)\n",
    "v1d = np.inner(np.dot(w_parametric, cov_mat), w_parametric)\n",
    "var1d = np.abs(stat.norm.ppf(0.01, loc=m1d, scale=np.sqrt(v1d)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Parametric VaR [1d, 99%]: {var1d:,.0f}\")\n",
    "print(f\"Parametric VaR [10d, 99%]: {var10d:,.0f}\")\n",
    "print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "# full revaluation 1d pnl evaluation\n",
    "def pnl1d_full(appl_daily_return, dbs_return, usdsgd_return):\n",
    "    return n_appl*appl_p0*usdsgd_p0*((1+appl_daily_return)*(1+usdsgd_return)-1) + n_dbs*dbs_p0*((1+dbs_return)-1)\n",
    "\n",
    "# sensitivity based 1d pnl evaluation \n",
    "def pnl1d_sen(appl_daily_return, dbs_return, usdsgd_return):\n",
    "    return n_appl*appl_p0*usdsgd_p0*(appl_daily_return+usdsgd_return) + n_dbs*dbs_p0*dbs_return\n",
    "\n",
    "\n",
    "# full revaluation 10d pnl evaluation\n",
    "def pnl10d_full(returns):\n",
    "    a10d = 0.0\n",
    "    fx10d = 0.0\n",
    "    d10d = 0.0\n",
    "    for i in range(0,10):\n",
    "        a10d = a10d + returns[i][0]\n",
    "        fx10d = fx10d  +returns[i][2]\n",
    "        d10d = d10d  +returns[i][1]\n",
    "    return n_appl*appl_p0*usdsgd_p0*a10d + n_appl*appl_p0*usdsgd_p0*fx10d + n_dbs*dbs_p0*d10d\n",
    "\n",
    "# sensitivity based 10d pnl evaluation \n",
    "def pnl10d_sen(returns):\n",
    "    a10d = 1.0\n",
    "    d10d = 1.0\n",
    "    for i in range(0,10):\n",
    "        a10d = a10d * (1+returns[i][0])*(1+returns[i][2])\n",
    "        d10d = d10d * (1+returns[i][1])\n",
    "    return n_appl*appl_p0*usdsgd_p0*(a10d-1)  +n_dbs*dbs_p0*(d10d-1)\n",
    "    \n",
    "# Monte Carlo VaR\n",
    "n_mc = 100000\n",
    "factor_loadings = np.linalg.cholesky(corr_mat)\n",
    "uniforms = np.random.uniform(size=(n_mc,3))\n",
    "snorms = [ [NormalDist().inv_cdf(u) for u in r]  for r in uniforms]\n",
    "snorms_correlated = np.dot(snorms, factor_loadings.transpose())\n",
    "return1d_sample = [ [ appl_mean + appl_std * z[0],   dbs_mean + dbs_std * z[1], usdsgd_mean + usdsgd_std * z[2] ]  for z in snorms_correlated]\n",
    "pnl1d_full_sample = [ pnl1d_full(s[0], s[1], s[2])  for s in return1d_sample]\n",
    "var1d_full_mc = np.abs(np.percentile(pnl1d_full_sample, 1))\n",
    "pnl10d_full_sample = [ pnl10d_full(return1d_sample[k*10:(k+1)*10]) for k in range(0, int(n_mc/10)) ]\n",
    "var10d_full_mc = np.abs(np.percentile(pnl10d_full_sample, 1))\n",
    "pnl1d_sen_sample = [ pnl1d_sen(s[0], s[1], s[2])  for s in return1d_sample]\n",
    "var1d_sen_mc = np.abs(np.percentile(pnl1d_sen_sample, 1))\n",
    "pnl10d_sen_sample = [ pnl10d_sen(return1d_sample[k*10:(k+1)*10]) for k in range(0, int(n_mc/10)) ]\n",
    "var10d_sen_mc = np.abs(np.percentile(pnl10d_sen_sample, 1))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Monte Carlo VaR:\")\n",
    "print(f\"VaR [1d, 99%], Full Revaluation: {var1d_full_mc:,.0f}\") \n",
    "print(f\"VaR [10d, 99%], Full Revaluation: {var10d_full_mc:,.0f}\") \n",
    "print(f\"VaR [10d, 99%] using square-root-of-time rule: {np.sqrt(10)*var1d_full_mc:,.0f}\") \n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 99%], Sensitivity: {var1d_sen_mc:,.0f}\") \n",
    "print(f\"VaR [10d, 99%], Sensitivity: {var10d_sen_mc:,.0f}\") \n",
    "print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "# Historical VaR\n",
    "hist_returns = df_all.to_numpy().tolist()\n",
    "pnl1d_full_hist_sample = [ pnl1d_full(s[0], s[1], s[2])  for s in hist_returns]\n",
    "var1d_full_hist = np.abs(np.percentile(pnl1d_full_hist_sample, 1))\n",
    "pnl1d_sen_hist_sample = [ pnl1d_sen(s[0], s[1], s[2])  for s in hist_returns]\n",
    "var1d_sen_hist = np.abs(np.percentile(pnl1d_sen_hist_sample, 1))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Historical VaR:\")\n",
    "print(f\"VaR [1d, 99%], Full Revaluation: {var1d_full_hist:,.0f}\") \n",
    "print(f\"VaR [10d, 99%] using square-root-of-time rule: {np.sqrt(10)*var1d_full_hist:,.0f}\")\n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 99%], Sensitivity: {var1d_sen_hist:,.0f}\") \n",
    "print(\"============================================================================================================================\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
