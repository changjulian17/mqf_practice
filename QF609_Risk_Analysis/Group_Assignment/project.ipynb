{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python calculation for the example and exercise from Lecture 4 notes\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import scipy.interpolate\n",
    "import statistics\n",
    "from statistics import NormalDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>msft</th>\n",
       "      <th>f</th>\n",
       "      <th>bac</th>\n",
       "      <th>1Y</th>\n",
       "      <th>2Y</th>\n",
       "      <th>3Y</th>\n",
       "      <th>4Y</th>\n",
       "      <th>5Y</th>\n",
       "      <th>6Y</th>\n",
       "      <th>7Y</th>\n",
       "      <th>8Y</th>\n",
       "      <th>9Y</th>\n",
       "      <th>10Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.017543</td>\n",
       "      <td>-0.017059</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.037305</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>-0.025373</td>\n",
       "      <td>-0.003039</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.042405</td>\n",
       "      <td>-0.026579</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>-0.005542</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001947</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.029270</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       aapl      msft         f       bac        1Y        2Y        3Y  \\\n",
       "1 -0.017543 -0.017059  0.002244  0.004439  0.000521  0.000439  0.000342   \n",
       "2 -0.037305 -0.035368 -0.025373 -0.003039  0.000234  0.000474  0.000404   \n",
       "3 -0.042405 -0.026579  0.015314 -0.005542  0.000690  0.001098  0.001085   \n",
       "4 -0.001947  0.033326  0.018854  0.025077 -0.000394 -0.000497 -0.000448   \n",
       "5  0.003902  0.029270  0.014064  0.005980  0.000429  0.000536  0.000499   \n",
       "\n",
       "         4Y        5Y        6Y        7Y        8Y        9Y       10Y  \n",
       "1  0.000296  0.000225  0.000124  0.000029 -0.000043 -0.000097 -0.000144  \n",
       "2  0.000254  0.000153  0.000118  0.000109  0.000099  0.000090  0.000091  \n",
       "3  0.000957  0.000832  0.000761  0.000704  0.000624  0.000545  0.000495  \n",
       "4 -0.000322 -0.000204 -0.000116 -0.000038  0.000045  0.000126  0.000192  \n",
       "5  0.000413  0.000332  0.000313  0.000328  0.000342  0.000345  0.000339  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'AAPL')\n",
    "msft = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'MSFT')\n",
    "f = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'F')\n",
    "bac = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'BAC')\n",
    "sofr_curve = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'SofrCurve')\n",
    "\n",
    "# Extract \"T\" as a separate array\n",
    "T_array = sofr_curve[\"T\"].values\n",
    "df_transposed = sofr_curve[sofr_curve.columns[2:]].T\n",
    "df_transposed.reset_index(inplace=True)\n",
    "col_names = ['Date'] + list(sofr_curve['Tenor'])\n",
    "df_transposed.columns = col_names\n",
    "\n",
    "sofr_curve = df_transposed[['Date'] + list(df_transposed.columns[7:17])]\n",
    "df_swap = pd.concat([df_transposed['Date'], sofr_curve[sofr_curve.columns[1:]].diff()],\n",
    "                    axis=1)\n",
    "df_stocks = pd.concat([aapl,\n",
    "                        msft['Adj Close'],\n",
    "                        f['Adj Close'],\n",
    "                        bac['Adj Close']],axis=1)\n",
    "df_stocks.columns = ['Date', 'aapl', 'msft', 'f', 'bac']\n",
    "df_stocks[df_stocks.columns[1:]] = df_stocks[df_stocks.columns[1:]].pct_change()\n",
    "\n",
    "\n",
    "df_returns = df_stocks.merge(df_swap,        # TODO change sofr curve to be modelled with change in rate rather than return\n",
    "                        on=['Date'],\n",
    "                        how='outer')\\\n",
    "                        .ffill()\\\n",
    "                        .drop(columns=['Date'])\\\n",
    "                        .dropna()\n",
    "\n",
    "df_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Full Revaluation\n",
    "$$\\begin{aligned}\n",
    "P_0 &= 100mio P_swap_0 + 1mio AAPL_0 + 1mio MSFT_0 + 1mio F + 1mio BAC_0     \\\\\n",
    "P_1 &= 100mio P_swap_1 + 1mio AAPL_1 + 1mio MSFT_1 + 1mio F_1 + 1mio BAC_1   \\\\\n",
    "\n",
    "\\Delta_1 L &= P_1 - P_0  \\\\\n",
    "&=  \\left[ 1e8 S_{swap}(1) +  S_{aapl}(1)  +  S_{msft}(1)  +  S_{f}(1)  +  S_{bac}(1) \\right] \\\\\n",
    "    & \\, \\,- \\left[ 1e8 S_{swap}(0) +  S_{aapl}(0)  +  S_{msft}(0)  +  S_{f}(0)  +  S_{bac}(0)  \\right] \\\\\n",
    "    &= \\left[ 1e8 S_{swap}(1) - 1e8 S_{swap}(0) \\right] + \\left[  S_{aapl}(1) -  S_{aapl}(0) \\right] + \\left[  S_{msft}(1) -  S_{msft}(0) \\right] \\\\\n",
    "    & \\,\\, + \\left[  S_{f}(1) -  S_{f}(0) \\right]  + \\left[  S_{bac}(1) -  S_{bac}(0) \\right] \\\\         \\\\\n",
    "\\Delta_1 L    &= N \\left[ \\sum_{i=1}^T PV01_i \\times \\Delta R_i  \\right] +  S_{aapl}(0) R_{aapl}^1  + S_{msft}(0)  R_{msft}^1  + S_{f}(0)  R_{f}^1  + S_{bac}(0) R_{bac}^1 \\\\         \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "### Pricing swap for full eval\n",
    "compute changes in zero rate based on sample $(Z_{1} = Z_0 * (1+R_1))$ use new SOFT curve  to price swap at 4.2%\n",
    "\n",
    "\n",
    "## For Sensitivity Analysis\n",
    "$$\\begin{aligned}\n",
    "\\Delta_1 L (\\mu , \\sigma^2) \\\\\n",
    "\\\\\n",
    "\\mu \\approx &100mio \\mathbb{E}[\\Delta_{swap}] + 1mio \\mathbb{E}[\\Delta_{aapl} + \\Delta_{msft}  + \\Delta_{f}  + \\Delta_{bac}]        \\\\\n",
    "\n",
    "\\sigma^2 \\approx &\\text{Var}(100mio\\Delta_{swap}) + \\text{Var}(1mio [\\Delta_{aapl} + \\Delta_{msft}  + \\Delta_{f}  + \\Delta_{bac}])\n",
    "\\end{aligned}$$\n",
    "\n",
    "### Pricing swap for sensitivity change \n",
    "get partial differential by changing one tenor by 1 bp then mark the change in PV.\n",
    "\n",
    "$$\n",
    "PV01_i = \\frac{S(0,r_i + \\Delta_{r_i}) - S(0,r_i)}{\\Delta_{r_i}}\n",
    "$$\n",
    "For our model, we use $\\Delta_{r_i} = 0.0001$\n",
    "$$\\begin{aligned}\n",
    "\\Delta PV &= N \\left[ \\sum_{i=1}^T PV01_i \\times \\Delta_{r_i} \\right]  \\\\ \n",
    "\n",
    "\\Delta PV &= N \\left[ \\sum_{i=1}^T PV01_i \\times  R_{r_i} PV_0^i \\right]  \n",
    "\n",
    "\\end{aligned}$$\n",
    "where N is the notional of swap and $\\Delta_{r_i} =  R_{r_i} PV_0^i$\n",
    "\n",
    "---\n",
    "\n",
    "# Useful functions and constants\n",
    "\n",
    "1. Make a function to calculate payer swap\n",
    "2. Get discount factors\n",
    "3. Calculate initial value of swap\n",
    "4. Calculate PV01:\\\n",
    "    a. change the value of each related zero rate by one bp an take note of PV change as partial derivative of PV for one bp change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payer_swap_10y(ls_df, swap_rate):\n",
    "    \"\"\"\n",
    "    Retun value of payer swap\n",
    "    parameters\n",
    "        ls_df: list of discount factors\n",
    "        swap_rate: strike of swap\n",
    "    fix_leg = sum of DF for 1y to 10 y\n",
    "    flt_leg = 1 - D(0,T), since flt leg = sum of D(0,0) - D(0,1y) + D(0,1y) - D(0,2y) ... D(0,T)\n",
    "    \"\"\"\n",
    "    fix_leg = sum(ls_df) * swap_rate * 1    # PVBP * Swap rate * day count fraction\n",
    "    flt_leg = 1-ls_df[-1]\n",
    "\n",
    "    return flt_leg - fix_leg\n",
    "# initial value of swap\n",
    "swap_rate = .042\n",
    "ls_zero_rates = list(sofr_curve.iloc[-1][sofr_curve.columns[1:]].astype('float')) # get zero rates for 10 year swap\n",
    "ls_df = [ np.exp(-r*(i+1)) for i, r in enumerate(ls_zero_rates) ] # calculate as discount factors\n",
    "S_0 = payer_swap_10y(ls_df, swap_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate PV01\n",
    "Create list of zero rates. For each year, add a bp, save list of resultant DF. Calculate new payer swap PV, and difference from previous day. Save results to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_pv01 = []\n",
    "\n",
    "for i in range(len(ls_zero_rates)):\n",
    "    ls_df = [r+.0001 if i==j else r for j, r in enumerate(ls_zero_rates)]\n",
    "    ls_df = [ np.exp(-df*(i+1)) for i, df in enumerate(ls_df) ]\n",
    "    # Calculate partial derivative for each payment date\n",
    "    PV01_partial = (payer_swap_10y(ls_df, swap_rate) - S_0) / .0001\n",
    "    ls_pv01.append(PV01_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mean and Covariance Matrix\n",
    "1. Use combined df to get mean return of each risk factor\n",
    "2. Set weight matrix w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ret = df_returns.mean().values\n",
    "cov_ret = df_returns.cov().values\n",
    "w = np.concatenate((np.array([1e6]*4),       # join weights for stocks and rates\n",
    "                  1e8*np.array(ls_pv01)))\n",
    "        # Notional * corrective to change PV01 from bp to pct * PV01\n",
    "mean_1d_ret = mean_ret @ w\n",
    "var_1d_ret = w @ cov_ret @ w.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric VaR\n",
    "Display possible loss as a positive number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Parametric VaR:\n",
      "Parametric VaR [1d, 95%]: 969,948\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Mean 13,663.25, Variance:  357,595,694,963.15, SD:597,993.06\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "var1d = stat.norm.ppf(.05, loc=mean_1d_ret, scale=np.sqrt(var_1d_ret))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Parametric VaR:\")\n",
    "print(f\"Parametric VaR [1d, 95%]: {abs(var1d):,.0f}\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Mean {mean_1d_ret:,.2f}, Variance:  {var_1d_ret:,.2f}, SD:{np.sqrt(var_1d_ret):,.2f}\")\n",
    "print(\"============================================================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Method\n",
    "Reuse mean and variance from parametric period to create samples\n",
    "## MC Full revaluation\n",
    "0. make function to calculate pnl\n",
    "1. generate samples\n",
    "2. calculate PnL full revaluation\\\n",
    "    a. calculate initial portfolio values\\\n",
    "    b. calculate stock P_1 values\\\n",
    "    c. calculate swap P_1 values\\\n",
    "    d. calculate P_1 - P_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculte P_1 for a sample of returns \n",
    "def P_1_calculate(samples):\n",
    "    \"\"\"\n",
    "    Return value of swap and stock\n",
    "    Parameters:\n",
    "        samples: Returns in fractional terms in NxM numpy array for M = 14 (4 stocks and 10 swap fixing DF). N is no. of samples\n",
    "    for stocks \n",
    "        P_1 = (1 + sample return) * P_0\n",
    "    for swap\n",
    "        calculate new zero rates: new zero rate = (1 + sample_return) * zero_rate_at_time_0 \n",
    "        recalculate payer swap value using new discount curve\n",
    "    \"\"\"\n",
    "    stock_P_1 = ((samples+1) * w.T)[:, :4]   # 1+R for each stock factor and multiply weight\n",
    "    swap_P_1 = []\n",
    "\n",
    "    for sample in samples:  # iterate through each sample\n",
    "        ls_df = np.array(ls_zero_rates).astype(float) + sample[4:]       # calculate P_1 zero rates\n",
    "        ls_df = [ np.exp(-r*(i+1)) for i, r in enumerate(ls_df) ]        # calculate P_1 DF\n",
    "        # calculate S_1 and append\n",
    "        swap_P_1.append(payer_swap_10y(ls_df, swap_rate))\n",
    "    swap_P_1 = 1e8 * np.array(swap_P_1)\n",
    "\n",
    "    return swap_P_1, stock_P_1\n",
    "\n",
    "# generate samples\n",
    "num_samples = 1_000_000\n",
    "samples = np.random.multivariate_normal(mean_ret, \n",
    "                                        cov_ret, \n",
    "                                        num_samples)\n",
    "\n",
    "\n",
    "# find P_0 initial portfolio value \n",
    "P_0 = S_0 * 1e8 + 1e6 * 4\n",
    "# find P_1 day 1 portfolio value\n",
    "swap_P_1, stock_P_1 = P_1_calculate(samples)\n",
    "P_1 = np.concatenate([stock_P_1, \n",
    "                      swap_P_1[:, np.newaxis]],\n",
    "                      axis=1)\\\n",
    "        .sum(axis=1)\n",
    "\n",
    "pnl1d_full_sample = P_1 - P_0\n",
    "var1d_full_mc = np.abs(np.percentile(pnl1d_full_sample, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Sensitiviy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Monte Carlo VaR:\n",
      "VaR [1d, 95%], Full Revaluation : 974,662\n",
      "\n",
      "VaR [1d, 95%], Sensitivity      : 968,939\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Full Reval  :: Mean 11,576.91, \t Variance:  358,045,578,046.39, SD:598,369.10\n",
      "Sensitivity :: Mean 13,625.51, \t Variance:  357,796,189,588.99, SD:598,160.67\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "pnl1d_sen_sample = samples@w.T\n",
    "var1d_sen_mc = np.abs(np.percentile(pnl1d_sen_sample, 5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Monte Carlo VaR:\")\n",
    "print(f\"VaR [1d, 95%], Full Revaluation : {var1d_full_mc:,.0f}\") \n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 95%], Sensitivity      : {var1d_sen_mc:,.0f}\") \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Full Reval  :: Mean {pnl1d_full_sample.mean():,.2f}, \\t Variance:  {pnl1d_full_sample.var():,.2f}, SD:{pnl1d_full_sample.std():,.2f}\")\n",
    "print(f\"Sensitivity :: Mean {pnl1d_sen_sample.mean():,.2f}, \\t Variance:  {pnl1d_sen_sample.var():,.2f}, SD:{pnl1d_sen_sample.std():,.2f}\")\n",
    "print(\"============================================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Historical VaR:\n",
      "VaR [1d, 95%], Full Revaluation : 990,135\n",
      "\n",
      "VaR [1d, 95%], Sensitivity      : 984,000\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Full Reval  :: Mean 11,620.23, \t Variance:  358,175,441,753.42, SD:598,477.60\n",
      "Sensitivity :: Mean 13,663.25, \t Variance:  356,176,664,427.58, SD:596,805.38\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "hist_samples = df_returns.values\n",
    "swap_P_1, stock_P_1 = P_1_calculate(hist_samples)\n",
    "P_1 = np.concatenate([stock_P_1, \n",
    "                      swap_P_1[:, np.newaxis]],\n",
    "                      axis=1)\\\n",
    "        .sum(axis=1)\n",
    "\n",
    "# Full revaluation for Historical Var\n",
    "pnl1d_full_hist_sample = P_1 - P_0\n",
    "var1d_full_hist = np.abs(np.percentile(pnl1d_full_hist_sample, 5))\n",
    "# Sensitivity impact for Historical Var\n",
    "pnl1d_sen_hist_sample = hist_samples@w.T\n",
    "var1d_sen_hist = np.abs(np.percentile(pnl1d_sen_hist_sample, 5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Historical VaR:\")\n",
    "print(f\"VaR [1d, 95%], Full Revaluation : {var1d_full_hist:,.0f}\") \n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 95%], Sensitivity      : {var1d_sen_hist:,.0f}\") \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Full Reval  :: Mean {pnl1d_full_hist_sample.mean():,.2f}, \\t Variance:  {pnl1d_full_hist_sample.var():,.2f}, SD:{pnl1d_full_hist_sample.std():,.2f}\")\n",
    "print(f\"Sensitivity :: Mean {pnl1d_sen_hist_sample.mean():,.2f}, \\t Variance:  {pnl1d_sen_hist_sample.var():,.2f}, SD:{pnl1d_sen_hist_sample.std():,.2f}\")\n",
    "print(\"============================================================================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
