{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**by Julian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python calculation for the example and exercise from Lecture 4 notes\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import scipy.interpolate\n",
    "import statistics\n",
    "from statistics import NormalDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'AAPL')\n",
    "msft = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'MSFT')\n",
    "f = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'F')\n",
    "bac = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'BAC')\n",
    "sofr_curve = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'SofrCurve')\n",
    "\n",
    "# Extract \"T\" as a separate array\n",
    "T_array = sofr_curve[\"T\"].values\n",
    "df_transposed = sofr_curve[sofr_curve.columns[2:]].T\n",
    "df_transposed.reset_index(inplace=True)\n",
    "col_names = ['Date'] + list(sofr_curve['Tenor'])\n",
    "df_transposed.columns = col_names\n",
    "\n",
    "sofr_curve = df_transposed[['Date'] + list(df_transposed.columns[7:17])]\n",
    "df_swap = pd.concat([df_transposed['Date'], sofr_curve[sofr_curve.columns[1:]].diff()],\n",
    "                    axis=1)\n",
    "df_stocks = pd.concat([aapl,\n",
    "                        msft['Adj Close'],\n",
    "                        f['Adj Close'],\n",
    "                        bac['Adj Close']],axis=1)\n",
    "df_stocks.columns = ['Date', 'aapl', 'msft', 'f', 'bac']\n",
    "df_stocks[df_stocks.columns[1:]] = df_stocks[df_stocks.columns[1:]].pct_change()\n",
    "\n",
    "\n",
    "df_returns = df_stocks.merge(df_swap,       \n",
    "                        on=['Date'],\n",
    "                        how='outer')\\\n",
    "                        .ffill()\\\n",
    "                        .drop(columns=['Date'])\\\n",
    "                        .dropna()\n",
    "\n",
    "df_returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>aapl</th>\n",
       "      <th>msft</th>\n",
       "      <th>f</th>\n",
       "      <th>bac</th>\n",
       "      <th>1Y</th>\n",
       "      <th>2Y</th>\n",
       "      <th>3Y</th>\n",
       "      <th>4Y</th>\n",
       "      <th>5Y</th>\n",
       "      <th>6Y</th>\n",
       "      <th>7Y</th>\n",
       "      <th>8Y</th>\n",
       "      <th>9Y</th>\n",
       "      <th>10Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date      aapl      msft         f       bac        1Y        2Y  \\\n",
       "0   2022-10-31       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "9   2022-11-11  0.019269  0.016997  0.022567  0.007343       NaN       NaN   \n",
       "109 2023-04-07       NaN       NaN       NaN       NaN  0.000956  0.001328   \n",
       "159 2023-06-19       NaN       NaN       NaN       NaN  0.000291  0.000363   \n",
       "237 2023-10-09  0.008451  0.007823  0.005833  0.009206       NaN       NaN   \n",
       "\n",
       "           3Y        4Y        5Y        6Y        7Y        8Y        9Y  \\\n",
       "0         NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "9         NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "109  0.001313  0.001209  0.001102  0.001050  0.001025  0.000971  0.000897   \n",
       "159  0.000451 -0.000129 -0.000165 -0.000092 -0.000098 -0.000084 -0.000056   \n",
       "237       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          10Y  \n",
       "0         NaN  \n",
       "9         NaN  \n",
       "109  0.000828  \n",
       "159 -0.000031  \n",
       "237       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_stocks.merge(df_swap,       \n",
    "                        on=['Date'],\n",
    "                        how='outer')\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Full Revaluation\n",
    "$$\\begin{aligned}\n",
    "P_0 &= 100mio P_swap_0 + 1mio AAPL_0 + 1mio MSFT_0 + 1mio F + 1mio BAC_0     \\\\\n",
    "P_1 &= 100mio P_swap_1 + 1mio AAPL_1 + 1mio MSFT_1 + 1mio F_1 + 1mio BAC_1   \\\\\n",
    "\n",
    "\\Delta_1 L &= P_1 - P_0  \\\\\n",
    "&=  \\left[ 1e8 S_{swap}(1) +  S_{aapl}(1)  +  S_{msft}(1)  +  S_{f}(1)  +  S_{bac}(1) \\right] \\\\\n",
    "    & \\, \\,- \\left[ 1e8 S_{swap}(0) +  S_{aapl}(0)  +  S_{msft}(0)  +  S_{f}(0)  +  S_{bac}(0)  \\right] \\\\\n",
    "    &= \\left[ 1e8 S_{swap}(1) - 1e8 S_{swap}(0) \\right] + \\left[  S_{aapl}(1) -  S_{aapl}(0) \\right] + \\left[  S_{msft}(1) -  S_{msft}(0) \\right] \\\\\n",
    "    & \\,\\, + \\left[  S_{f}(1) -  S_{f}(0) \\right]  + \\left[  S_{bac}(1) -  S_{bac}(0) \\right] \\\\         \\\\\n",
    "\n",
    "\\end{aligned}$$\n",
    "\n",
    "### Pricing swap for full eval\n",
    "compute changes in zero rate based on sample $(Z_{1} = Z_0 * (1+R_1))$ use new SOFT curve  to price swap at 4.2%\n",
    "\n",
    "\n",
    "## For Sensitivity Analysis\n",
    "$$\\begin{aligned}\n",
    "\\Delta_1 L    &= N \\left[ \\sum_{i=1}^T PV01_i \\times \\Delta R_i  \\right] +  S_{aapl}(0) R_{aapl}^1  + S_{msft}(0)  R_{msft}^1  + S_{f}(0)  R_{f}^1  + S_{bac}(0) R_{bac}^1 \\\\         \\\\\n",
    "\\Delta_1 L (\\mu , \\sigma^2) \\\\\n",
    "\\\\\n",
    "\\mu \\approx &100mio \\mathbb{E}[\\Delta_{swap}] + 1mio \\mathbb{E}[\\Delta_{aapl} + \\Delta_{msft}  + \\Delta_{f}  + \\Delta_{bac}]        \\\\\n",
    "\n",
    "\\sigma^2 \\approx &\\text{Var}(100mio\\Delta_{swap}) + \\text{Var}(1mio [\\Delta_{aapl} + \\Delta_{msft}  + \\Delta_{f}  + \\Delta_{bac}])\n",
    "\\end{aligned}$$\n",
    "\n",
    "### Pricing swap for sensitivity change \n",
    "get partial differential by changing one tenor by 1 bp then mark the change in PV.\n",
    "\n",
    "$$\n",
    "PV01_i = \\frac{S(0,r_i + \\Delta_{r_i}) - S(0,r_i)}{\\Delta_{r_i}}\n",
    "$$\n",
    "For our model, we use $\\Delta_{r_i} = 0.0001$\n",
    "$$\\begin{aligned}\n",
    "\\Delta PV &= N \\left[ \\sum_{i=1}^T PV01_i \\times \\Delta_{r_i} \\right]  \\\\ \n",
    "\n",
    "\\Delta PV &= N \\left[ \\sum_{i=1}^T PV01_i \\times  R_{r_i} PV_0^i \\right]  \n",
    "\n",
    "\\end{aligned}$$\n",
    "where N is the notional of swap and $\\Delta_{r_i} =  R_{r_i} PV_0^i$\n",
    "\n",
    "---\n",
    "\n",
    "# Useful functions and constants\n",
    "\n",
    "1. Make a function to calculate payer swap\n",
    "2. Get discount factors\n",
    "3. Calculate initial value of swap\n",
    "4. Calculate PV01:\\\n",
    "    a. change the value of each related zero rate by one bp an take note of PV change as partial derivative of PV for one bp change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>1Y</th>\n",
       "      <th>2Y</th>\n",
       "      <th>3Y</th>\n",
       "      <th>4Y</th>\n",
       "      <th>5Y</th>\n",
       "      <th>6Y</th>\n",
       "      <th>7Y</th>\n",
       "      <th>8Y</th>\n",
       "      <th>9Y</th>\n",
       "      <th>10Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>0.052503</td>\n",
       "      <td>0.048399</td>\n",
       "      <td>0.045999</td>\n",
       "      <td>0.044850</td>\n",
       "      <td>0.044305</td>\n",
       "      <td>0.044036</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>0.043816</td>\n",
       "      <td>0.043798</td>\n",
       "      <td>0.043826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-10-25</td>\n",
       "      <td>0.052653</td>\n",
       "      <td>0.048791</td>\n",
       "      <td>0.046595</td>\n",
       "      <td>0.045594</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.045017</td>\n",
       "      <td>0.044911</td>\n",
       "      <td>0.044867</td>\n",
       "      <td>0.044876</td>\n",
       "      <td>0.044926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>0.052243</td>\n",
       "      <td>0.048044</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>0.044538</td>\n",
       "      <td>0.044086</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.043808</td>\n",
       "      <td>0.043795</td>\n",
       "      <td>0.043829</td>\n",
       "      <td>0.043898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>0.052115</td>\n",
       "      <td>0.047758</td>\n",
       "      <td>0.045284</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.043762</td>\n",
       "      <td>0.043636</td>\n",
       "      <td>0.043643</td>\n",
       "      <td>0.043702</td>\n",
       "      <td>0.043793</td>\n",
       "      <td>0.043908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.045429</td>\n",
       "      <td>0.044345</td>\n",
       "      <td>0.043928</td>\n",
       "      <td>0.043794</td>\n",
       "      <td>0.043779</td>\n",
       "      <td>0.043828</td>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.044023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        1Y        2Y        3Y        4Y        5Y        6Y  \\\n",
       "246 2023-10-24  0.052503  0.048399  0.045999  0.044850  0.044305  0.044036   \n",
       "247 2023-10-25  0.052653  0.048791  0.046595  0.045594  0.045200  0.045017   \n",
       "248 2023-10-26  0.052243  0.048044  0.045645  0.044538  0.044086  0.043893   \n",
       "249 2023-10-27  0.052115  0.047758  0.045284  0.044200  0.043762  0.043636   \n",
       "250 2023-10-30  0.052245  0.047904  0.045429  0.044345  0.043928  0.043794   \n",
       "\n",
       "           7Y        8Y        9Y       10Y  \n",
       "246  0.043889  0.043816  0.043798  0.043826  \n",
       "247  0.044911  0.044867  0.044876  0.044926  \n",
       "248  0.043808  0.043795  0.043829  0.043898  \n",
       "249  0.043643  0.043702  0.043793  0.043908  \n",
       "250  0.043779  0.043828  0.043915  0.044023  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofr_curve.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payer_swap_10y(ls_df, swap_rate):\n",
    "    \"\"\"\n",
    "    Retun value of payer swap\n",
    "    parameters\n",
    "        ls_df: list of discount factors\n",
    "        swap_rate: strike of swap\n",
    "    fix_leg = sum of DF for 1y to 10 y\n",
    "    flt_leg = 1 - D(0,T), since flt leg = sum of D(0,0) - D(0,1y) + D(0,1y) - D(0,2y) ... D(0,T)\n",
    "    \"\"\"\n",
    "    fix_leg = np.sum(np.array(ls_df)) * swap_rate * 1    # PVBP * Swap rate * day count fraction\n",
    "    flt_leg = 1-ls_df[-1]\n",
    "\n",
    "    return flt_leg - fix_leg\n",
    "# initial value of swap\n",
    "swap_rate = .042\n",
    "ls_zero_rates = list(sofr_curve.iloc[-1][sofr_curve.columns[1:]].astype('float')) # get zero rates at T=0\n",
    "ls_df = [ np.exp(-r*(i+1)) for i, r in enumerate(ls_zero_rates) ] # calculate as discount factors\n",
    "S_0 = payer_swap_10y(ls_df, swap_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate PV01\n",
    "Create list of zero rates. For each year, add a bp, save list of resultant DF. Calculate new payer swap PV, and difference from previous day. Save results to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_pv01 = []\n",
    "\n",
    "for i in range(len(ls_zero_rates)):\n",
    "    ls_df = [r+.0001 if i==j else r for j, r in enumerate(ls_zero_rates)]\n",
    "    ls_df = [ np.exp(-r*(k+1)) for k, r in enumerate(ls_df) ]\n",
    "    # Calculate partial derivative for each payment date\n",
    "    PV01_partial = (payer_swap_10y(ls_df, swap_rate) - S_0) / .0001\n",
    "    ls_pv01.append(PV01_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mean and Covariance Matrix\n",
    "1. Use combined df to get mean return of each risk factor\n",
    "2. Set weight matrix w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ret = df_returns.mean().values\n",
    "cov_ret = df_returns.cov().values\n",
    "w = np.concatenate((np.array([1e6]*4),       # join weights for stocks and rates\n",
    "                  1e8*np.array(ls_pv01)))\n",
    "        # Notional * corrective to change PV01 from bp to pct * PV01\n",
    "mean_1d_ret = mean_ret @ w\n",
    "var_1d_ret = w @ cov_ret @ w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aapl    0.000562\n",
       "msft    0.001714\n",
       "f      -0.000654\n",
       "bac    -0.001092\n",
       "1Y      0.000019\n",
       "2Y      0.000005\n",
       "3Y      0.000004\n",
       "4Y      0.000006\n",
       "5Y      0.000008\n",
       "6Y      0.000011\n",
       "7Y      0.000013\n",
       "8Y      0.000015\n",
       "9Y      0.000016\n",
       "10Y     0.000017\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_returns.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric VaR\n",
    "Display possible loss as a positive number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Parametric VaR:\n",
      "Parametric VaR [1d, 95%]: 969,948\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Mean 13,663.25, Variance:  357,595,694,962.91, SD:597,993.06\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "var1d = stat.norm.ppf(.05, loc=mean_1d_ret, scale=np.sqrt(var_1d_ret))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Parametric VaR:\")\n",
    "print(f\"Parametric VaR [1d, 95%]: {abs(var1d):,.0f}\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Mean {mean_1d_ret:,.2f}, Variance:  {var_1d_ret:,.2f}, SD:{np.sqrt(var_1d_ret):,.2f}\")\n",
    "print(\"============================================================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Method\n",
    "Reuse mean and variance from parametric period to create samples\n",
    "## MC Full revaluation\n",
    "0. make function to calculate pnl\n",
    "1. generate samples\n",
    "2. calculate PnL full revaluation\\\n",
    "    a. calculate initial portfolio values\\\n",
    "    b. calculate stock P_1 values\\\n",
    "    c. calculate swap P_1 values\\\n",
    "    d. calculate P_1 - P_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculte P_1 for a sample of returns \n",
    "def P_1_calculate(samples):\n",
    "    \"\"\"\n",
    "    Return value of swap and stock\n",
    "    Parameters:\n",
    "        samples: Returns in fractional terms in NxM numpy array for M = 14 (4 stocks and 10 swap fixing DF). N is no. of samples\n",
    "    for stocks \n",
    "        P_1 = (1 + sample return) * P_0\n",
    "    for swap\n",
    "        calculate new zero rates: new zero rate = (1 + sample_return) * zero_rate_at_time_0 \n",
    "        recalculate payer swap value using new discount curve\n",
    "    \"\"\"\n",
    "    stock_P_1 = ((samples+1) * w.T)[:, :4]   # 1+R for each stock factor and multiply weight\n",
    "    swap_P_1 = []\n",
    "\n",
    "    for sample in samples:  # iterate through each sample\n",
    "        ls_df = np.array(ls_zero_rates).astype(float) + sample[4:]       # calculate P_1 zero rates\n",
    "        ls_df = [ np.exp(-r*(i+1)) for i, r in enumerate(ls_df) ]        # calculate P_1 DF\n",
    "        # calculate S_1 and append\n",
    "        swap_P_1.append(payer_swap_10y(ls_df, swap_rate))\n",
    "    swap_P_1 = 1e8 * np.array(swap_P_1)\n",
    "\n",
    "    return swap_P_1, stock_P_1\n",
    "\n",
    "# generate samples\n",
    "num_samples = 1_000_000\n",
    "samples = np.random.multivariate_normal(mean_ret, \n",
    "                                        cov_ret, \n",
    "                                        num_samples)\n",
    "\n",
    "\n",
    "# find P_0 initial portfolio value \n",
    "P_0 = S_0 * 1e8 + 1e6 * 4\n",
    "# find P_1 day 1 portfolio value\n",
    "swap_P_1, stock_P_1 = P_1_calculate(samples)\n",
    "P_1 = np.concatenate([stock_P_1, \n",
    "                      swap_P_1[:, np.newaxis]],\n",
    "                      axis=1)\\\n",
    "        .sum(axis=1)\n",
    "\n",
    "pnl1d_full_sample = P_1 - P_0\n",
    "var1d_full_mc = np.abs(np.percentile(pnl1d_full_sample, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Sensitiviy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Monte Carlo VaR:\n",
      "VaR [1d, 95%], Full Revaluation : 974,257\n",
      "\n",
      "VaR [1d, 95%], Sensitivity      : 968,551\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Full Reval  :: Sample Mean 11,325.70, \t Sample Variance:  357,366,647,854.27, SD:597,801.51\n",
      "Sensitivity :: Sample Mean 13,370.80, \t Sample Variance:  357,117,367,652.93, SD:597,592.98\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "pnl1d_sen_sample = samples@w.T\n",
    "var1d_sen_mc = np.abs(np.percentile(pnl1d_sen_sample, 5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Monte Carlo VaR:\")\n",
    "print(f\"VaR [1d, 95%], Full Revaluation : {var1d_full_mc:,.0f}\") \n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 95%], Sensitivity      : {var1d_sen_mc:,.0f}\") \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Full Reval  :: Sample Mean {pnl1d_full_sample.mean():,.2f}, \\t Sample Variance:  {pnl1d_full_sample.var():,.2f}, SD:{pnl1d_full_sample.std():,.2f}\")\n",
    "print(f\"Sensitivity :: Sample Mean {pnl1d_sen_sample.mean():,.2f}, \\t Sample Variance:  {pnl1d_sen_sample.var():,.2f}, SD:{pnl1d_sen_sample.std():,.2f}\")\n",
    "print(\"============================================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Historical VaR:\n",
      "VaR [1d, 95%], Full Revaluation : 990,135\n",
      "\n",
      "VaR [1d, 95%], Sensitivity      : 984,000\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Full Reval  :: Sample Mean 11,620.23, \t Sample Variance:  358,175,441,753.42, SD:598,477.60\n",
      "Sensitivity :: Sample Mean 13,663.25, \t Sample Variance:  356,176,664,427.35, SD:596,805.38\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "hist_samples = df_returns.values\n",
    "swap_P_1, stock_P_1 = P_1_calculate(hist_samples)\n",
    "P_1 = np.concatenate([stock_P_1, \n",
    "                      swap_P_1[:, np.newaxis]],\n",
    "                      axis=1)\\\n",
    "        .sum(axis=1)\n",
    "\n",
    "# Full revaluation for Historical Var\n",
    "pnl1d_full_hist_sample = P_1 - P_0\n",
    "var1d_full_hist = np.abs(np.percentile(pnl1d_full_hist_sample, 5))\n",
    "# Sensitivity impact for Historical Var\n",
    "pnl1d_sen_hist_sample = hist_samples@w.T\n",
    "var1d_sen_hist = np.abs(np.percentile(pnl1d_sen_hist_sample, 5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Historical VaR:\")\n",
    "print(f\"VaR [1d, 95%], Full Revaluation : {var1d_full_hist:,.0f}\") \n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 95%], Sensitivity      : {var1d_sen_hist:,.0f}\") \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Full Reval  :: Sample Mean {pnl1d_full_hist_sample.mean():,.2f}, \\t Sample Variance:  {pnl1d_full_hist_sample.var():,.2f}, SD:{pnl1d_full_hist_sample.std():,.2f}\")\n",
    "print(f\"Sensitivity :: Sample Mean {pnl1d_sen_hist_sample.mean():,.2f}, \\t Sample Variance:  {pnl1d_sen_hist_sample.var():,.2f}, SD:{pnl1d_sen_hist_sample.std():,.2f}\")\n",
    "print(\"============================================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- difference in sensitivity and full evaluation numbers are from higher order terms not considered in the sensitivity analysis which only use first order differences\n",
    "- dependence of risk factors:\n",
    "    - between assets there is dependence \n",
    "    - from day to day there is no auto-correlation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
