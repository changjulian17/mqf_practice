{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python calculation for the example and exercise from Lecture 4 notes\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import scipy.interpolate\n",
    "import statistics\n",
    "from statistics import NormalDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>msft</th>\n",
       "      <th>f</th>\n",
       "      <th>bac</th>\n",
       "      <th>1Y</th>\n",
       "      <th>2Y</th>\n",
       "      <th>3Y</th>\n",
       "      <th>4Y</th>\n",
       "      <th>5Y</th>\n",
       "      <th>6Y</th>\n",
       "      <th>7Y</th>\n",
       "      <th>8Y</th>\n",
       "      <th>9Y</th>\n",
       "      <th>10Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.017543</td>\n",
       "      <td>-0.017059</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>-0.001141</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>-0.003849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.037305</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>-0.025373</td>\n",
       "      <td>-0.003039</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.002457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.042405</td>\n",
       "      <td>-0.026579</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>-0.005542</td>\n",
       "      <td>0.014624</td>\n",
       "      <td>0.024133</td>\n",
       "      <td>0.025373</td>\n",
       "      <td>0.023414</td>\n",
       "      <td>0.020974</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>0.013280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001947</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>-0.008229</td>\n",
       "      <td>-0.010659</td>\n",
       "      <td>-0.010219</td>\n",
       "      <td>-0.007710</td>\n",
       "      <td>-0.005036</td>\n",
       "      <td>-0.002922</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.005084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.029270</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.008932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       aapl      msft         f       bac        1Y        2Y        3Y  \\\n",
       "1 -0.017543 -0.017059  0.002244  0.004439  0.011215  0.009846  0.008140   \n",
       "2 -0.037305 -0.035368 -0.025373 -0.003039  0.004977  0.010528  0.009553   \n",
       "3 -0.042405 -0.026579  0.015314 -0.005542  0.014624  0.024133  0.025373   \n",
       "4 -0.001947  0.033326  0.018854  0.025077 -0.008229 -0.010659 -0.010219   \n",
       "5  0.003902  0.029270  0.014064  0.005980  0.009036  0.011631  0.011503   \n",
       "\n",
       "         4Y        5Y        6Y        7Y        8Y        9Y       10Y  \n",
       "1  0.007351  0.005731  0.003218  0.000754 -0.001141 -0.002596 -0.003849  \n",
       "2  0.006256  0.003865  0.003057  0.002871  0.002624  0.002407  0.002457  \n",
       "3  0.023414  0.020974  0.019620  0.018464  0.016548  0.014541  0.013280  \n",
       "4 -0.007710 -0.005036 -0.002922 -0.000975  0.001187  0.003311  0.005084  \n",
       "5  0.009947  0.008235  0.007935  0.008467  0.008905  0.009056  0.008932  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'AAPL')\n",
    "msft = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'MSFT')\n",
    "f = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'F')\n",
    "bac = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'BAC')\n",
    "sofr_curve = pd.read_excel(\"./data/hist_data.xlsm\", sheet_name = 'SofrCurve')\n",
    "\n",
    "# Extract \"T\" as a separate array\n",
    "T_array = sofr_curve[\"T\"].values\n",
    "df_transposed = sofr_curve[sofr_curve.columns[2:]].T\n",
    "df_transposed.reset_index(inplace=True)\n",
    "col_names = ['Date'] + list(sofr_curve['Tenor'])\n",
    "df_transposed.columns = col_names\n",
    "\n",
    "sofr_curve = df_transposed[['Date'] + list(df_transposed.columns[7:17])]\n",
    "sofr_curve.head()\n",
    "df_stocks = pd.concat([aapl,\n",
    "                        msft['Adj Close'],\n",
    "                        f['Adj Close'],\n",
    "                        bac['Adj Close']],axis=1)\n",
    "df_stocks.columns = ['Date', 'aapl', 'msft', 'f', 'bac']\n",
    "\n",
    "df_returns = df_stocks.merge(sofr_curve,\n",
    "                        on=['Date'],\n",
    "                        how='outer')\\\n",
    "                        .ffill()\\\n",
    "                        .drop(columns=['Date'])\\\n",
    "                        .pct_change()\\\n",
    "                        .dropna()\n",
    "\n",
    "df_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Full Revaluation\n",
    "$$\\begin{aligned}\n",
    "P_0 &= 100mio P_swap_0 + 1mio AAPL_0 + 1mio MSFT_0 + 1mio F + 1mio BAC_0     \\\\\n",
    "P_1 &= 100mio P_swap_1 + 1mio AAPL_1 + 1mio MSFT_1 + 1mio F_1 + 1mio BAC_1   \\\\\n",
    "\n",
    "\\Delta_1 L &= P_1 - P_0  \\\\\n",
    "&=  \\left[ 1e8 S_{swap}(1) +  S_{aapl}(1)  +  S_{msft}(1)  +  S_{f}(1)  +  S_{bac}(1) \\right] \\\\\n",
    "    & \\, \\,- \\left[ 1e8 S_{swap}(0) +  S_{aapl}(0)  +  S_{msft}(0)  +  S_{f}(0)  +  S_{bac}(0)  \\right] \\\\\n",
    "    &= \\left[ 1e8 S_{swap}(1) - 1e8 S_{swap}(0) \\right] + \\left[  S_{aapl}(1) -  S_{aapl}(0) \\right] + \\left[  S_{msft}(1) -  S_{msft}(0) \\right] \\\\\n",
    "    & \\,\\, + \\left[  S_{f}(1) -  S_{f}(0) \\right]  + \\left[  S_{bac}(1) -  S_{bac}(0) \\right] \\\\         \\\\\n",
    "\\Delta_1 L    &= N \\left[ \\sum_{i=1}^T PV01_i \\times \\Delta R_i  \\right] +  S_{aapl}(0) R_{aapl}^1  + S_{msft}(0)  R_{msft}^1  + S_{f}(0)  R_{f}^1  + S_{bac}(0) R_{bac}^1 \\\\         \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "### Pricing swap for full eval\n",
    "compute changes in zero rate based on sample $(Z_{1} = Z_0 * (1+R_1))$ use new SOFT curve  to price swap at 4.2%\n",
    "\n",
    "\n",
    "## For Sensitivity Analysis\n",
    "$$\\begin{aligned}\n",
    "\\Delta_1 L (\\mu , \\sigma^2) \\\\\n",
    "\\\\\n",
    "\\mu \\approx &100mio \\mathbb{E}[\\Delta_{swap}] + 1mio \\mathbb{E}[\\Delta_{aapl} + \\Delta_{msft}  + \\Delta_{f}  + \\Delta_{bac}]        \\\\\n",
    "\n",
    "\\sigma^2 \\approx &\\text{Var}(100mio\\Delta_{swap}) + \\text{Var}(1mio [\\Delta_{aapl} + \\Delta_{msft}  + \\Delta_{f}  + \\Delta_{bac}])\n",
    "\\end{aligned}$$\n",
    "\n",
    "### Pricing swap for sensitivity change \n",
    "get partial differential by changing one tenor by 1 bp then mark the change in PV \\\n",
    "$$\n",
    "\\Delta PV = N \\left[ \\sum_{i=1}^T PV01_i \\times \\Delta R_i * PV_0^i \\right]\n",
    "$$\n",
    "where N is the notional of swap\n",
    "\n",
    "---\n",
    "\n",
    "# Useful functions and constants\n",
    "\n",
    "1. Make a function to calculate payer swap\n",
    "2. Get discount factors\n",
    "3. Calculate initial value of swap\n",
    "4. Calculate PV01:\\\n",
    "    a. change the value of each related zero rate by one bp an take note of PV change as partial derivative of PV for one bp change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payer_swap_10y(ls_df, swap_rate):\n",
    "    \"\"\"\n",
    "    Retun value of payer swap\n",
    "    parameters\n",
    "        ls_df: list of discount factors\n",
    "        swap_rate: strike of swap\n",
    "    fix_leg = sum of DF for 1y to 10 y\n",
    "    flt_leg = 1 - D(0,T), since flt leg = sum of D(0,0) - D(0,1y) + D(0,1y) - D(0,2y) ... D(0,T)\n",
    "    \"\"\"\n",
    "    fix_leg = sum(ls_df) * swap_rate * 1    # PVBP * Swap rate * day count fraction\n",
    "    flt_leg = 1-ls_df[-1]\n",
    "\n",
    "    return flt_leg - fix_leg\n",
    "# initial value of swap\n",
    "swap_rate = .042\n",
    "ls_zero_rates = list(sofr_curve.iloc[-1][sofr_curve.columns[1:]].astype('float')) # get zero rates for 10 year swap\n",
    "ls_df = [ np.exp(-df*(i+1)) for i, df in enumerate(ls_zero_rates) ] # calculate as discount factors\n",
    "S_0 = payer_swap_10y(ls_df, swap_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate PV01\n",
    "Create list of zero rates. For each year, add a bp, save list of resultant DF. Calculate new payer swap PV, and difference from previous day. Save results to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_pv01 = []\n",
    "\n",
    "for i in range(len(ls_zero_rates)):\n",
    "    ls_df = [r+.0001 if i==j else r for j, r in enumerate(ls_zero_rates)]\n",
    "    ls_df = [ np.exp(-df*(i+1)) for i, df in enumerate(ls_df) ]\n",
    "    # Calculate partial derivative for each payment date\n",
    "    PV01_partial = payer_swap_10y(ls_df, swap_rate) - S_0\n",
    "    ls_pv01.append(PV01_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mean and Covariance Matrix\n",
    "1. Use combined df to get mean return of each risk factor\n",
    "2. Set weight matrix w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ret = df_returns.mean().values\n",
    "cov_ret = df_returns.cov().values\n",
    "w = np.concatenate((np.array([1e6]*4),       # join weights for stocks and rates\n",
    "                  1e8*1e4*np.array(ls_pv01)*np.array(ls_zero_rates)))\n",
    "        # Notional * corrective to change PV01 from bp to pct * PV01 * PV_0, initial zero rate \n",
    "mean_1d_ret = mean_ret @ w\n",
    "var_1d_ret = w @ cov_ret @ w.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric VaR\n",
    "Display possible loss as a positive number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Parametric VaR:\n",
      "Parametric VaR [1d, 95%]: 1,180,186\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Mean 30,701.13, Variance:  541,941,674,080.96, SD:736,166.88\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "var1d = stat.norm.ppf(.05, loc=mean_1d_ret, scale=np.sqrt(var_1d_ret))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Parametric VaR:\")\n",
    "print(f\"Parametric VaR [1d, 95%]: {abs(var1d):,.0f}\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Mean {mean_1d_ret:,.2f}, Variance:  {var_1d_ret:,.2f}, SD:{np.sqrt(var_1d_ret):,.2f}\")\n",
    "print(\"============================================================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Method\n",
    "Reuse mean and variance from parametric period to create samples\n",
    "## MC Full revaluation\n",
    "0. make function to calculate pnl\n",
    "1. generate samples\n",
    "2. calculate PnL full revaluation\\\n",
    "    a. calculate initial portfolio values\\\n",
    "    b. calculate stock P_1 values\\\n",
    "    c. calculate swap P_1 values\\\n",
    "    d. calculate P_1 - P_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculte P_1 for a sample of returns \n",
    "def P_1_calculate(samples):\n",
    "    \"\"\"\n",
    "    Return value of swap and stock\n",
    "    Parameters:\n",
    "        samples: Returns in fractional terms in NxM numpy array for M = 14 (4 stocks and 10 swap fixing DF). N is no. of samples\n",
    "    for stocks \n",
    "        P_1 = (1 + sample return) * P_0 = \n",
    "    for swap\n",
    "        calculate new zero rates: new zero rate = (1 + sample_return) * zero_rate_at_time_0 \n",
    "        recalculate payer swap value using new discount curve\n",
    "    \"\"\"\n",
    "    stock_P_1 = ((samples+1) * w.T)[:, :4]   # 1+R for each stock factor and multiply weight\n",
    "    swap_P_1 = []\n",
    "\n",
    "    for sample in samples:  # iterate through each sample\n",
    "        ls_df = np.array(ls_zero_rates).astype(float) * (sample[4:] + 1)  # calculate P_1 zero rates\n",
    "        ls_df = [ np.exp(-df*(i+1)) for i, df in enumerate(ls_df) ]        # calculate P_1 DF\n",
    "        # calculate S_1 and append\n",
    "        swap_P_1.append(payer_swap_10y(ls_df, swap_rate))\n",
    "    swap_P_1 = 1e8 * np.array(swap_P_1)\n",
    "\n",
    "    return swap_P_1, stock_P_1\n",
    "\n",
    "# generate samples\n",
    "num_samples = 1_000_000\n",
    "samples = np.random.multivariate_normal(mean_ret, \n",
    "                                        cov_ret, \n",
    "                                        num_samples)\n",
    "\n",
    "\n",
    "# find P_0 initial portfolio value \n",
    "P_0 = S_0 * 1e8 + 1e6 * 4\n",
    "# find P_1 day 1 portfolio value\n",
    "swap_P_1, stock_P_1 = P_1_calculate(samples)\n",
    "P_1 = np.concatenate([stock_P_1, \n",
    "                      swap_P_1[:, np.newaxis]],\n",
    "                      axis=1)\\\n",
    "        .sum(axis=1)\n",
    "\n",
    "pnl1d_full_sample = P_1 - P_0\n",
    "var1d_full_mc = np.abs(np.percentile(pnl1d_full_sample, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Sensitiviy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Monte Carlo VaR:\n",
      "VaR [1d, 95%], Full Revaluation : 1,189,900\n",
      "\n",
      "VaR [1d, 95%], Sensitivity      : 1,181,309\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Full Reval  :: Mean 28,021.53, \t Variance:  542,248,697,294.11, SD:736,375.38\n",
      "Sensitivity :: Mean 31,130.58, \t Variance:  542,059,807,925.10, SD:736,247.11\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "pnl1d_sen_sample = samples@w.T\n",
    "var1d_sen_mc = np.abs(np.percentile(pnl1d_sen_sample, 5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Monte Carlo VaR:\")\n",
    "print(f\"VaR [1d, 95%], Full Revaluation : {var1d_full_mc:,.0f}\") \n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 95%], Sensitivity      : {var1d_sen_mc:,.0f}\") \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Full Reval  :: Mean {pnl1d_full_sample.mean():,.2f}, \\t Variance:  {pnl1d_full_sample.var():,.2f}, SD:{pnl1d_full_sample.std():,.2f}\")\n",
    "print(f\"Sensitivity :: Mean {pnl1d_sen_sample.mean():,.2f}, \\t Variance:  {pnl1d_sen_sample.var():,.2f}, SD:{pnl1d_sen_sample.std():,.2f}\")\n",
    "print(\"============================================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Historical VaR:\n",
      "VaR [1d, 95%], Full Revaluation : 1,272,763\n",
      "\n",
      "VaR [1d, 95%], Sensitivity      : 1,263,232\n",
      "\n",
      "\n",
      "============================================================================================================================\n",
      "Full Reval  :: Mean 27,600.76, \t Variance:  542,190,276,192.71, SD:736,335.71\n",
      "Sensitivity :: Mean 30,701.13, \t Variance:  539,791,111,882.23, SD:734,704.78\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "hist_samples = df_returns.values\n",
    "swap_P_1, stock_P_1 = P_1_calculate(hist_samples)\n",
    "P_1 = np.concatenate([stock_P_1, \n",
    "                      swap_P_1[:, np.newaxis]],\n",
    "                      axis=1)\\\n",
    "        .sum(axis=1)\n",
    "\n",
    "# Full revaluation for Historical Var\n",
    "pnl1d_full_hist_sample = P_1 - P_0\n",
    "var1d_full_hist = np.abs(np.percentile(pnl1d_full_hist_sample, 5))\n",
    "# Sensitivity impact for Historical Var\n",
    "pnl1d_sen_hist_sample = hist_samples@w.T\n",
    "var1d_sen_hist = np.abs(np.percentile(pnl1d_sen_hist_sample, 5))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(\"Historical VaR:\")\n",
    "print(f\"VaR [1d, 95%], Full Revaluation : {var1d_full_hist:,.0f}\") \n",
    "print(\"\")\n",
    "print(f\"VaR [1d, 95%], Sensitivity      : {var1d_sen_hist:,.0f}\") \n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============================================================================================================================\")\n",
    "print(f\"Full Reval  :: Mean {pnl1d_full_hist_sample.mean():,.2f}, \\t Variance:  {pnl1d_full_hist_sample.var():,.2f}, SD:{pnl1d_full_hist_sample.std():,.2f}\")\n",
    "print(f\"Sensitivity :: Mean {pnl1d_sen_hist_sample.mean():,.2f}, \\t Variance:  {pnl1d_sen_hist_sample.var():,.2f}, SD:{pnl1d_sen_hist_sample.std():,.2f}\")\n",
    "print(\"============================================================================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
